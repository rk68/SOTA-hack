{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3fc7c2f7f57347388955c24c7a325d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd56f5d258814fd49de6384f2abb50ef",
              "IPY_MODEL_a9e03c1031ca485db6728da74b3d2be5",
              "IPY_MODEL_b9d7d68bbeae436ca701f33fe58655e2"
            ],
            "layout": "IPY_MODEL_316837e0500d48f29cf1547bfae20108"
          }
        },
        "dd56f5d258814fd49de6384f2abb50ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c2a22a60a9445d989cd2331ac3dd827",
            "placeholder": "​",
            "style": "IPY_MODEL_9b24f3ab188649769a826753a1b2c241",
            "value": "config.json: 100%"
          }
        },
        "a9e03c1031ca485db6728da74b3d2be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09c122eeb95459bb505b1ffc69ef618",
            "max": 767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c374124746e424e9b335ca74ad69ef7",
            "value": 767
          }
        },
        "b9d7d68bbeae436ca701f33fe58655e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_015889455d1649938a73c4fb62b5c9d6",
            "placeholder": "​",
            "style": "IPY_MODEL_1a14f132d95849219260dbcddf411dee",
            "value": " 767/767 [00:00&lt;00:00, 53.5kB/s]"
          }
        },
        "316837e0500d48f29cf1547bfae20108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c2a22a60a9445d989cd2331ac3dd827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b24f3ab188649769a826753a1b2c241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c09c122eeb95459bb505b1ffc69ef618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c374124746e424e9b335ca74ad69ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "015889455d1649938a73c4fb62b5c9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a14f132d95849219260dbcddf411dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ca8885158dc41bba698762a802dd3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dca24b8e7fe5493e811e416adee35f44",
              "IPY_MODEL_7152d27c339243548b221bc7ccf5a143",
              "IPY_MODEL_005778e8b70248ba96bd63d853cc7057"
            ],
            "layout": "IPY_MODEL_40f00ab14f7b487cb74dece844b93a0d"
          }
        },
        "dca24b8e7fe5493e811e416adee35f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b15b26e1553415c8919515648428bc7",
            "placeholder": "​",
            "style": "IPY_MODEL_9073d0d385774e9e8db5fd44ddc65bf1",
            "value": "SoLU_8L_v21_final.pth: 100%"
          }
        },
        "7152d27c339243548b221bc7ccf5a143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10116970ed364b8c8f41d10abb2f53f4",
            "max": 827868535,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5464534df3d4235af4053f9ff7c44a7",
            "value": 827868535
          }
        },
        "005778e8b70248ba96bd63d853cc7057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a482ef6d8a9b4590a9e8137b82d4ef2a",
            "placeholder": "​",
            "style": "IPY_MODEL_a83c25ae4ca44dc383da5fce68e31c02",
            "value": " 828M/828M [00:05&lt;00:00, 180MB/s]"
          }
        },
        "40f00ab14f7b487cb74dece844b93a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b15b26e1553415c8919515648428bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9073d0d385774e9e8db5fd44ddc65bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10116970ed364b8c8f41d10abb2f53f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5464534df3d4235af4053f9ff7c44a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a482ef6d8a9b4590a9e8137b82d4ef2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a83c25ae4ca44dc383da5fce68e31c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47b5b7eb646d4f0dbed62e1271de5beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd1d667222f242f48c1d6dcbc15a5b85",
              "IPY_MODEL_497ded5ddba14db3978fb84dfc8dc4e2",
              "IPY_MODEL_0534e688f4594d359a7951b68ed51caf"
            ],
            "layout": "IPY_MODEL_9051055ca6064f12addf61d337bf7fb0"
          }
        },
        "cd1d667222f242f48c1d6dcbc15a5b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb48917bee7d4436bf69827bd26ff97b",
            "placeholder": "​",
            "style": "IPY_MODEL_0a1c6bddc47d4719bfb6c89bf61273f7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "497ded5ddba14db3978fb84dfc8dc4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030f09c8b13341d4901a7825aee20833",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8cad0eb30af49a3a7af580e3fa4af06",
            "value": 156
          }
        },
        "0534e688f4594d359a7951b68ed51caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ced0ede2a2f246e7a1227412a3e3d5c5",
            "placeholder": "​",
            "style": "IPY_MODEL_1aae66447fde4a1f8f1c77f08ee963dc",
            "value": " 156/156 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "9051055ca6064f12addf61d337bf7fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb48917bee7d4436bf69827bd26ff97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1c6bddc47d4719bfb6c89bf61273f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "030f09c8b13341d4901a7825aee20833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cad0eb30af49a3a7af580e3fa4af06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ced0ede2a2f246e7a1227412a3e3d5c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aae66447fde4a1f8f1c77f08ee963dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "098343889fba4dd28521d703cc90da92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d9c479ec2a4495597b0059b50823f36",
              "IPY_MODEL_c78f017ec2c34e3fb6988a6fbefd1d73",
              "IPY_MODEL_53ab09eaa9d14c9494cc1aad2a8dcd0f"
            ],
            "layout": "IPY_MODEL_8ac759daf57c4091851b85bb1a50328a"
          }
        },
        "5d9c479ec2a4495597b0059b50823f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6740bddd1445476abff8f89a75589c02",
            "placeholder": "​",
            "style": "IPY_MODEL_c33c13bf2534408cafd5f8085aecdfa1",
            "value": "vocab.json: 100%"
          }
        },
        "c78f017ec2c34e3fb6988a6fbefd1d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ade9644577854664a5584c7e2b220e03",
            "max": 1077392,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e89d93313f34b688ac882088959edb4",
            "value": 1077392
          }
        },
        "53ab09eaa9d14c9494cc1aad2a8dcd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1320055d50224d749dfe54ef3ec59bb7",
            "placeholder": "​",
            "style": "IPY_MODEL_bb7317742e1c4f56b152598fdf090488",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 4.19MB/s]"
          }
        },
        "8ac759daf57c4091851b85bb1a50328a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6740bddd1445476abff8f89a75589c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33c13bf2534408cafd5f8085aecdfa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ade9644577854664a5584c7e2b220e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e89d93313f34b688ac882088959edb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1320055d50224d749dfe54ef3ec59bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7317742e1c4f56b152598fdf090488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf33038945449c3a8bc37c3c093ab06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4236725a12a041bba5f924e9bd4ca28e",
              "IPY_MODEL_ba6e1e36c1a24a56b23b9f85b9df5332",
              "IPY_MODEL_4608f7e5549f4bd9b6ce5756ee69daa3"
            ],
            "layout": "IPY_MODEL_7ae0330f8f0749c9afddf10b8b6dbd88"
          }
        },
        "4236725a12a041bba5f924e9bd4ca28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0a4a417b8d7499fbf523b09c98f3387",
            "placeholder": "​",
            "style": "IPY_MODEL_0d1c85cb984341b89502854fd84451ba",
            "value": "merges.txt: 100%"
          }
        },
        "ba6e1e36c1a24a56b23b9f85b9df5332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef51151c5304d6a93d8f51b2b9399e0",
            "max": 456583,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_585a38560c814c6591403a505710df48",
            "value": 456583
          }
        },
        "4608f7e5549f4bd9b6ce5756ee69daa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb39594cfe845f7866d3f42208b92c4",
            "placeholder": "​",
            "style": "IPY_MODEL_9d4a2a1784fc4623b8204676fb8bdd0d",
            "value": " 457k/457k [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "7ae0330f8f0749c9afddf10b8b6dbd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a4a417b8d7499fbf523b09c98f3387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d1c85cb984341b89502854fd84451ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef51151c5304d6a93d8f51b2b9399e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "585a38560c814c6591403a505710df48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acb39594cfe845f7866d3f42208b92c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4a2a1784fc4623b8204676fb8bdd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51ddc309ff934c2186004a7f410e99cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21c989bb69cd4241b6f460502f9c5400",
              "IPY_MODEL_4b5bc788eba8455d90974d457fe48b6c",
              "IPY_MODEL_0990589dead74cbc82bdc6f022f5e314"
            ],
            "layout": "IPY_MODEL_95716fd51c144e2c93501250b88d6e0c"
          }
        },
        "21c989bb69cd4241b6f460502f9c5400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d95dcca057c4e6c9a8a6a4a7e14f49c",
            "placeholder": "​",
            "style": "IPY_MODEL_070c32a452fe4bf5934ec9ceb15f8a05",
            "value": "tokenizer.json: 100%"
          }
        },
        "4b5bc788eba8455d90974d457fe48b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a266859c9ba4c58bc32f68ab2233f00",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32b854d7445c49749d6bdbdb8eb5ede9",
            "value": 2113710
          }
        },
        "0990589dead74cbc82bdc6f022f5e314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6635c254529460ba8c7df798f08a98e",
            "placeholder": "​",
            "style": "IPY_MODEL_bea3e3baed89427ab8d226ad59ba7a4d",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 8.02MB/s]"
          }
        },
        "95716fd51c144e2c93501250b88d6e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d95dcca057c4e6c9a8a6a4a7e14f49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070c32a452fe4bf5934ec9ceb15f8a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a266859c9ba4c58bc32f68ab2233f00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b854d7445c49749d6bdbdb8eb5ede9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6635c254529460ba8c7df798f08a98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea3e3baed89427ab8d226ad59ba7a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3355b3be6990492c918163cf7a8b24ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_817f3069cff54823adbb61da855eac59",
              "IPY_MODEL_03297489f56f434380de661fe7adbf20",
              "IPY_MODEL_1e747c43a4bb4f208d29e00c5a4b6517"
            ],
            "layout": "IPY_MODEL_57538bb0ca134197a6e121eed7fdacb0"
          }
        },
        "817f3069cff54823adbb61da855eac59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d78e6a27e9734e5e8beb9fedfd25a751",
            "placeholder": "​",
            "style": "IPY_MODEL_753d1662901640d8b3a14b2d41fc1ed6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "03297489f56f434380de661fe7adbf20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec86a9ebb0b4ee2a5962ca2ce870d9e",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4c08f6b96a54a5db02f332eac77782a",
            "value": 90
          }
        },
        "1e747c43a4bb4f208d29e00c5a4b6517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b2046b6df7344bfb177c606ff1bf20d",
            "placeholder": "​",
            "style": "IPY_MODEL_2750b880978342a48cc6f45f062cb474",
            "value": " 90.0/90.0 [00:00&lt;00:00, 6.79kB/s]"
          }
        },
        "57538bb0ca134197a6e121eed7fdacb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78e6a27e9734e5e8beb9fedfd25a751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753d1662901640d8b3a14b2d41fc1ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec86a9ebb0b4ee2a5962ca2ce870d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c08f6b96a54a5db02f332eac77782a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b2046b6df7344bfb177c606ff1bf20d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2750b880978342a48cc6f45f062cb474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18416c90728642ecabd985dc82c046a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd0f57269774474b84cee6dc6df70e38",
              "IPY_MODEL_9c5eb7afc6c643e392f05cd619dff015",
              "IPY_MODEL_9c9c5881187f494f835f82ee99feb9c9"
            ],
            "layout": "IPY_MODEL_91eb55e784504a5bb6586875669f348f"
          }
        },
        "dd0f57269774474b84cee6dc6df70e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddae7becf22b4399b889aab04883b73a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb78e98011b24ba1923d85ace563bdda",
            "value": "config.json: 100%"
          }
        },
        "9c5eb7afc6c643e392f05cd619dff015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2bd047c795248439d4898f28aa74224",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12266bfb40534f62861c99b78573c5ac",
            "value": 483
          }
        },
        "9c9c5881187f494f835f82ee99feb9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57854357c01d49b4b7ff3ad286f522da",
            "placeholder": "​",
            "style": "IPY_MODEL_197b389ccde342fea6a8c1aabeb2d387",
            "value": " 483/483 [00:00&lt;00:00, 35.9kB/s]"
          }
        },
        "91eb55e784504a5bb6586875669f348f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddae7becf22b4399b889aab04883b73a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb78e98011b24ba1923d85ace563bdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2bd047c795248439d4898f28aa74224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12266bfb40534f62861c99b78573c5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57854357c01d49b4b7ff3ad286f522da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "197b389ccde342fea6a8c1aabeb2d387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7eb184604ce46639ed086963200bac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0499764b718b4b83acca8a1d86341b70",
              "IPY_MODEL_843f350564d14558b6f685d824b902bc",
              "IPY_MODEL_661101be9aec4e3f9067e669f5119465"
            ],
            "layout": "IPY_MODEL_6c24d0ff2ba84b5da2fa165ae6bd0de3"
          }
        },
        "0499764b718b4b83acca8a1d86341b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_485bf4685b644ed4bbd2b6f9d413f351",
            "placeholder": "​",
            "style": "IPY_MODEL_a00e8a01e2f443ef9faa3f96c2509c55",
            "value": "model.safetensors: 100%"
          }
        },
        "843f350564d14558b6f685d824b902bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87c2dcd58444bb08c01585586a21098",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8135d9ea73f4cfc94dd6b9a4e48317e",
            "value": 267954768
          }
        },
        "661101be9aec4e3f9067e669f5119465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6823f175942540108f815673daa16610",
            "placeholder": "​",
            "style": "IPY_MODEL_042809b2c68542f0aeafc6d96a940373",
            "value": " 268M/268M [00:01&lt;00:00, 228MB/s]"
          }
        },
        "6c24d0ff2ba84b5da2fa165ae6bd0de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "485bf4685b644ed4bbd2b6f9d413f351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00e8a01e2f443ef9faa3f96c2509c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e87c2dcd58444bb08c01585586a21098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8135d9ea73f4cfc94dd6b9a4e48317e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6823f175942540108f815673daa16610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "042809b2c68542f0aeafc6d96a940373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e267a41dd6d1487c89a1675a4a88f1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6859e05b43e2416e9aa87e5e8442c123",
              "IPY_MODEL_4ac890beec8b4e32b904736409a6cde3",
              "IPY_MODEL_9c93ebeb236648e888392992dc58e360"
            ],
            "layout": "IPY_MODEL_2c92625698c642d69529399207992f18"
          }
        },
        "6859e05b43e2416e9aa87e5e8442c123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ce3f445239440c790980fe4474c978b",
            "placeholder": "​",
            "style": "IPY_MODEL_6ada85319d214ea881264d61b6e1d5e2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4ac890beec8b4e32b904736409a6cde3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_255f1a45502347398c5f8a04394553fb",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d41ea3ac61d47c39f504ac68b1a9e36",
            "value": 48
          }
        },
        "9c93ebeb236648e888392992dc58e360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15dd50213ad6484591ae5820237e0ce4",
            "placeholder": "​",
            "style": "IPY_MODEL_63302a05d0e14326a403bc7e33f3a3cb",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.16kB/s]"
          }
        },
        "2c92625698c642d69529399207992f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce3f445239440c790980fe4474c978b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ada85319d214ea881264d61b6e1d5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "255f1a45502347398c5f8a04394553fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d41ea3ac61d47c39f504ac68b1a9e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15dd50213ad6484591ae5820237e0ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63302a05d0e14326a403bc7e33f3a3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abd81981e0994edaa0ab2f020874f291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa43b924aadf4b2ab286009128576ed2",
              "IPY_MODEL_013683c0affb40218051c15dbfdab802",
              "IPY_MODEL_955801bab27f45f786ff3abf2f93d7c2"
            ],
            "layout": "IPY_MODEL_ad56e7a301604c2e982ca90afb77ab13"
          }
        },
        "fa43b924aadf4b2ab286009128576ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eba5224d2e404fdba935b40a1f637651",
            "placeholder": "​",
            "style": "IPY_MODEL_2ce6b9f810d14e69a5a4b6408568a15f",
            "value": "vocab.txt: 100%"
          }
        },
        "013683c0affb40218051c15dbfdab802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7542e68a56554a0a95b72c91dc8f9f4a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff27eb0ddabb49e6a6dee39b60bad902",
            "value": 231508
          }
        },
        "955801bab27f45f786ff3abf2f93d7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08294cfa823141e49ead637d87297a7a",
            "placeholder": "​",
            "style": "IPY_MODEL_911b15aa72f94208ba0bb6346cf18674",
            "value": " 232k/232k [00:00&lt;00:00, 1.80MB/s]"
          }
        },
        "ad56e7a301604c2e982ca90afb77ab13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba5224d2e404fdba935b40a1f637651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce6b9f810d14e69a5a4b6408568a15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7542e68a56554a0a95b72c91dc8f9f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff27eb0ddabb49e6a6dee39b60bad902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08294cfa823141e49ead637d87297a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911b15aa72f94208ba0bb6346cf18674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90ada44a797d4195a8366988fde5c35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e2d5bbc74354063ae48b15d0dac5046",
              "IPY_MODEL_5a2cac4cf61540bd8b4d71e332b40602",
              "IPY_MODEL_dfd4249c40d243818d9d45eb7722f190"
            ],
            "layout": "IPY_MODEL_d057513e4b9e41f2903a80b8f4771fdd"
          }
        },
        "5e2d5bbc74354063ae48b15d0dac5046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff57901a6e2488b8634448e87636600",
            "placeholder": "​",
            "style": "IPY_MODEL_6815edc9275f45139a02dbb1a276185d",
            "value": "tokenizer.json: 100%"
          }
        },
        "5a2cac4cf61540bd8b4d71e332b40602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5c096f03ab47c5acb3a3846d26caff",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f61bb95981944f948a56c62a2266a2cb",
            "value": 466062
          }
        },
        "dfd4249c40d243818d9d45eb7722f190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3644c08ccee242839b69b28749836757",
            "placeholder": "​",
            "style": "IPY_MODEL_57e43d251dfb4e7983997c886cefd7c3",
            "value": " 466k/466k [00:00&lt;00:00, 3.32MB/s]"
          }
        },
        "d057513e4b9e41f2903a80b8f4771fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff57901a6e2488b8634448e87636600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6815edc9275f45139a02dbb1a276185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5c096f03ab47c5acb3a3846d26caff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61bb95981944f948a56c62a2266a2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3644c08ccee242839b69b28749836757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e43d251dfb4e7983997c886cefd7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Og88PwkTXo-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/neelnanda-io/Easy-Transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5RFUEgxSO-A",
        "outputId": "0083799c-a6e2-4448-b1a7-53a6114ba5c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer to /tmp/pip-req-build-sj1u_2m5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer /tmp/pip-req-build-sj1u_2m5\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer to commit f103debd1084cd79969164ac98ed9059a86354bc\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (1.2.1)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (0.8.0)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n",
            "  Downloading jaxtyping-0.2.36-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (4.47.1)\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (4.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer-lens==0.0.0) (0.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.11.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer-lens==0.0.0) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (4.25.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (2.10.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens==0.0.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens==0.0.0) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.2)\n",
            "Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.2.36-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformer-lens\n",
            "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=177601 sha256=6349507d14ee0e9b217b2726c7f64d87af8fbefc43b30fab63466ffb4c005a24\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mazeq4b_/wheels/cc/a9/28/32d08ec11f70ba435beadc5b78c481a9fe0afaec537a37ea27\n",
            "Successfully built transformer-lens\n",
            "Installing collected packages: better-abc, xxhash, jaxtyping, fsspec, fancy-einsum, dill, beartype, multiprocess, datasets, transformer-lens\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.2.0 dill-0.3.8 fancy-einsum-0.0.3 fsspec-2024.9.0 jaxtyping-0.2.36 multiprocess-0.70.16 transformer-lens-0.0.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformer_lens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khMzKnDkaBB8",
        "outputId": "63729bc6-d72e-4a56-ed20-b14b0649991f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformer_lens in /usr/local/lib/python3.11/dist-packages (0.0.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.2.1)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.8.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.2.36)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.47.1)\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.11.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer_lens) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer_lens) (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.25.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.10.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "2velp8LwOg3N",
        "outputId": "ae110eae-61bc-4ee7-be6c-78f2257a0304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "mX2W_chfOlRU",
        "outputId": "121a3e11-695c-4a7d-bf47-7aa994737bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "# from google.colab import drive\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from functools import *\n",
        "import pandas as pd\n",
        "import gc\n",
        "import collections\n",
        "import copy\n",
        "\n",
        "# import comet_ml\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets"
      ],
      "metadata": {
        "id": "q8XmZlmOUtoJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pv-WbMWZxXw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformer_lens.utils import (\n",
        "    gelu_new,\n",
        "    to_numpy,\n",
        "    get_corner,\n",
        "    lm_cross_entropy_loss,\n",
        ")  # Helper functions\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import EasyTransformer, EasyTransformerConfig\n",
        "import transformer_lens\n",
        "# from transformer_lens.experiments import (\n",
        "#     ExperimentMetric,\n",
        "#     AblationConfig,\n",
        "#     EasyAblation,\n",
        "#     EasyPatching,\n",
        "#     PatchingConfig,\n",
        "# )"
      ],
      "metadata": {
        "id": "_DZmDwTSUjwS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "wG5dKXVyVExr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model_name = \"solu-8l-old\"\n",
        "model = EasyTransformer.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "3fc7c2f7f57347388955c24c7a325d0f",
            "dd56f5d258814fd49de6384f2abb50ef",
            "a9e03c1031ca485db6728da74b3d2be5",
            "b9d7d68bbeae436ca701f33fe58655e2",
            "316837e0500d48f29cf1547bfae20108",
            "1c2a22a60a9445d989cd2331ac3dd827",
            "9b24f3ab188649769a826753a1b2c241",
            "c09c122eeb95459bb505b1ffc69ef618",
            "8c374124746e424e9b335ca74ad69ef7",
            "015889455d1649938a73c4fb62b5c9d6",
            "1a14f132d95849219260dbcddf411dee",
            "5ca8885158dc41bba698762a802dd3d5",
            "dca24b8e7fe5493e811e416adee35f44",
            "7152d27c339243548b221bc7ccf5a143",
            "005778e8b70248ba96bd63d853cc7057",
            "40f00ab14f7b487cb74dece844b93a0d",
            "4b15b26e1553415c8919515648428bc7",
            "9073d0d385774e9e8db5fd44ddc65bf1",
            "10116970ed364b8c8f41d10abb2f53f4",
            "a5464534df3d4235af4053f9ff7c44a7",
            "a482ef6d8a9b4590a9e8137b82d4ef2a",
            "a83c25ae4ca44dc383da5fce68e31c02",
            "47b5b7eb646d4f0dbed62e1271de5beb",
            "cd1d667222f242f48c1d6dcbc15a5b85",
            "497ded5ddba14db3978fb84dfc8dc4e2",
            "0534e688f4594d359a7951b68ed51caf",
            "9051055ca6064f12addf61d337bf7fb0",
            "cb48917bee7d4436bf69827bd26ff97b",
            "0a1c6bddc47d4719bfb6c89bf61273f7",
            "030f09c8b13341d4901a7825aee20833",
            "a8cad0eb30af49a3a7af580e3fa4af06",
            "ced0ede2a2f246e7a1227412a3e3d5c5",
            "1aae66447fde4a1f8f1c77f08ee963dc",
            "098343889fba4dd28521d703cc90da92",
            "5d9c479ec2a4495597b0059b50823f36",
            "c78f017ec2c34e3fb6988a6fbefd1d73",
            "53ab09eaa9d14c9494cc1aad2a8dcd0f",
            "8ac759daf57c4091851b85bb1a50328a",
            "6740bddd1445476abff8f89a75589c02",
            "c33c13bf2534408cafd5f8085aecdfa1",
            "ade9644577854664a5584c7e2b220e03",
            "2e89d93313f34b688ac882088959edb4",
            "1320055d50224d749dfe54ef3ec59bb7",
            "bb7317742e1c4f56b152598fdf090488",
            "4cf33038945449c3a8bc37c3c093ab06",
            "4236725a12a041bba5f924e9bd4ca28e",
            "ba6e1e36c1a24a56b23b9f85b9df5332",
            "4608f7e5549f4bd9b6ce5756ee69daa3",
            "7ae0330f8f0749c9afddf10b8b6dbd88",
            "c0a4a417b8d7499fbf523b09c98f3387",
            "0d1c85cb984341b89502854fd84451ba",
            "6ef51151c5304d6a93d8f51b2b9399e0",
            "585a38560c814c6591403a505710df48",
            "acb39594cfe845f7866d3f42208b92c4",
            "9d4a2a1784fc4623b8204676fb8bdd0d",
            "51ddc309ff934c2186004a7f410e99cd",
            "21c989bb69cd4241b6f460502f9c5400",
            "4b5bc788eba8455d90974d457fe48b6c",
            "0990589dead74cbc82bdc6f022f5e314",
            "95716fd51c144e2c93501250b88d6e0c",
            "0d95dcca057c4e6c9a8a6a4a7e14f49c",
            "070c32a452fe4bf5934ec9ceb15f8a05",
            "2a266859c9ba4c58bc32f68ab2233f00",
            "32b854d7445c49749d6bdbdb8eb5ede9",
            "f6635c254529460ba8c7df798f08a98e",
            "bea3e3baed89427ab8d226ad59ba7a4d",
            "3355b3be6990492c918163cf7a8b24ae",
            "817f3069cff54823adbb61da855eac59",
            "03297489f56f434380de661fe7adbf20",
            "1e747c43a4bb4f208d29e00c5a4b6517",
            "57538bb0ca134197a6e121eed7fdacb0",
            "d78e6a27e9734e5e8beb9fedfd25a751",
            "753d1662901640d8b3a14b2d41fc1ed6",
            "3ec86a9ebb0b4ee2a5962ca2ce870d9e",
            "c4c08f6b96a54a5db02f332eac77782a",
            "6b2046b6df7344bfb177c606ff1bf20d",
            "2750b880978342a48cc6f45f062cb474"
          ]
        },
        "id": "W416JfwYVEzx",
        "outputId": "493de85a-0f55-4576-f40c-77a30e88f735"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/767 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fc7c2f7f57347388955c24c7a325d0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SoLU_8L_v21_final.pth:   0%|          | 0.00/828M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ca8885158dc41bba698762a802dd3d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47b5b7eb646d4f0dbed62e1271de5beb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "098343889fba4dd28521d703cc90da92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/457k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cf33038945449c3a8bc37c3c093ab06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51ddc309ff934c2186004a7f410e99cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3355b3be6990492c918163cf7a8b24ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model solu-8l-old into HookedTransformer\n",
            "Moving model to device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning"
      ],
      "metadata": {
        "id": "ox_8QsnsYkIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_3_1 = [\n",
        "    \"\"\"\n",
        "\"I will. Same to you.\"\n",
        "\n",
        "He tells me that he loves me, and then I hang up just as I arrive at Wes's house.\n",
        "\n",
        "I park in the driveway next to his bike, not bothering to hide my Jeep down the road like usual. I know all about our past, and frankly, now that Wes knows too, his mother's threats are useless. She can't bully me out of Wes's life.\n",
        "\n",
        "I've made mistakes, not all of them completely my fault, but I can try not to make any more. I'm not sure where we stand relationship-wise, but we'll figure it out. We might even make the right decisions this time. For now, we just have to save the world. No pressure.\n",
        "\n",
        "I quickly dial Nathan, but he doesn't answer, making me nervous. I tell him to call me back, and that I'm at Wes's house. I push the phone into my pocket and climb out of the Jeep.\n",
        "\n",
        "Wes waits for me at his door, smiling and looking a little nervous. I wonder if he thought I was going to turn onto the freeway and drive away instead of coming here. The thought didn't even cross my mind. I would have followed him anywhere.\n",
        "\n",
        "\"Parents aren't home,\" he says, watching my approach. \"In case you were worried.\"\n",
        "\n",
        "\"Now you won't have to lock the door,\" I say, and stop in front of him.\n",
        "\n",
        "Wes's smile fades. \"I always lock the door,\" he replies, and turns to push inside his basement apartment.\n",
        "\n",
        "I realize that I'm nervous too. Beyond the life-altering shit that's about to go down with The Program—I'm here with Wes. And I'm still not entirely sure how to act.\n",
        "\n",
        "I understand what Michael Realm meant now, how remembering can be a curse. Because I remember things that Wes doesn't. I remember how much he loved me. How much I loved him. The stuff they couldn't take. The stuff that crashed back. So much history, and now it's only mine.\n",
        "\n",
        "I walk inside his room and close the door behind me. It's dimly lit, the high-set window not enough on a darkened, stormy day. But Wes doesn't flip on the lights as he leads us into the living room area.\n",
        "\n",
        "I sit on the couch, and Wes comes to the coffee table and turns his laptop in my direction before telling me he'll be right back. He jogs up the stairs and disappears inside his house.\n",
        "\n",
        "I smile at the wallpaper on his computer, a vintage motorcycle, mid-repair. It's simple, honest. I click open the browser, and his last page pulls up. It's a board called Survivor Rate, and the quick description says it's a forum for survivors of the epidemic. It has over ten thousand members.\n",
        "\n",
        "I click on the first thread and start to read through, when I hear Wes close the door and lock it before bounding down the stairs. I look up, and he holds out a bag of frozen peas.\n",
        "\n",
        "\"For your head,\" he says. \"I tried to find an aspirin, but my mom won't keep any pills in the house.\"\n",
        "\n",
        "\"Oh,\" I say, taking the icy bag from him. \"Thank you.\" It's kind of sweet of him to do that without me asking. I move my legs aside as he scoots past me and drops down onto the couch in his usual spot. I gently press the peas to my head, groaning at the pressure.\n",
        "\n",
        "\"This is the one,\" Wes starts, turning the screen so he can see it too, \"where the guy had the picture of Michael.\"\n",
        "\n",
        "\"He goes by Realm,\" I say, and feel Wes turn to me. I point at the screen to move forward. \"Can I see the picture?\"\n",
        "\n",
        "\"Sure,\" Wes replies, and clicks into a different thread, scrolling through posts. He double-clicks one. \"Here you go. That's him, right?\"\n",
        "\n",
        "And it is. There's a picture of Realm, not looking at the camera. He's partially turned away, his scar prominent on his neck. He doesn't seem to know his picture is being taken, and I'm reminded of Melody and how she never wanted to be in any photos. She always found an excuse. It was probably because she was a handler, a closer, and she didn't want to be recognized. She didn't want a record of being Jana Simms.\n",
        "\n",
        "\"That's definitely him,\" I say. Under the picture, the post reads: Anyone know this guy?\n",
        "\n",
        "Wes goes into the private messages and shows me his exchange with the original poster. It doesn't give us any information on locating Realm,\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "to the human analyte enzyme in its native matrix (eg serum); iii) and the inter-method ratio should be constant (within the limits of experimental error) for the enzyme calibrator and for all patients' samples.<|endoftext|>Q:\n",
        "\n",
        "Render named children in React component?\n",
        "\n",
        "I have a modal component which take a trigger to open the modal, and the content to go inside the modal.\n",
        "<Modal>\n",
        "  <button className=\"btn btn--primary\">Open modalbutton>\n",
        "  <div>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  div>\n",
        "Modal>\n",
        "\n",
        "And in the Modal component:\n",
        "  return (\n",
        "    <div className=\"Modal\">\n",
        "      {props.children[0]}\n",
        "      <div className=\"Modal__container\">\n",
        "        <div className=\"Modal__header\">\n",
        "          <button className=\"Modal__close btn btn--secondary btn--small\">\n",
        "            Close\n",
        "          button>\n",
        "          <h1 className=\"Modal__heading\">Here is my modalh1>\n",
        "        div>\n",
        "        <div className=\"Modal__content\">{props.children[1]}div>\n",
        "      div>\n",
        "    div>\n",
        "  );\n",
        "\n",
        "This is working but very fragile as Im using an index on props.children. Can I instead name the components I pass to Modal? So something like:\n",
        "<Modal>\n",
        "  <Modal.Trigger>\n",
        "    <button className=\"btn btn--primary\">Open modalbutton>\n",
        "  Modal.Trigger>\n",
        "  <Modal.Content>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  Modal.Content>\n",
        "Modal>\n",
        "\n",
        "A:\n",
        "\n",
        "I suggest you use props instead:\n",
        "declare your Modal like so:\n",
        "<Modal action={<button className=\"btn btn--primary\">Open modalbutton>}>\n",
        "  <div>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  div>\n",
        "Modal>\n",
        "\n",
        "and your render method will then look something like\n",
        "return (\n",
        "  <div className=\"Modal\">\n",
        "    {props.action}\n",
        "    <div className=\"Modal__container\">\n",
        "      <div className=\"Modal__header\">\n",
        "        <button className=\"Modal__close btn btn--secondary btn--small\">\n",
        "          Close\n",
        "        button>\n",
        "        <h1 className=\"Modal__heading\">Here is my modalh1>\n",
        "      div>\n",
        "      <div className=\"Modal__content\">{props.children[1]}div>\n",
        "    div>\n",
        "  div>\n",
        ");\n",
        "\n",
        "<|endoftext|>A man told Dr. Phil on his show yesterday that he might have to kill his own child to protect his wife. His 12-year-old son, Jack, has exhibited traits of “demon possession” since he was two and needed an exorcism, according to the father John.\n",
        "\n",
        "John, a Christian, went on to say that the demon controlled his son and told him to kill people in the family.\n",
        "\n",
        "He says he’s so concerned, he has plans for Jack to have an exorcism because he fears that if he doesn’t, one day, he may have to kill his son to protect his wife and children.\n",
        "\n",
        "I don’t know about you, but this is never a thought that would cross my mind. I would protect my child at all costs, but I guess that’s just what false beliefs do to people. It’s much easier to kill your son if you think he’s an evil devil creature.\n",
        "\n",
        "Fortunately, Dr. Phil didn’t allow John’s baseless assertion to go unchallenged. He questioned how he could know that Jack is possessed by demons and followed up several times.\n",
        "\n",
        "“Tell me how you’ve come to the conclusion that it’s demonic possession,” Dr. Phil says to John on Monday’s episode. “At 2 ½-years old, he began exhibiting traits,” John says. “There was the stacking glass around his mother’s neck, point side up, and if she would’ve turned — I mean, I caught him in the middle of it. I felt the energy shift, and I woke up.” “But how is that behavior demonic? “Dr. Phil presses.\n",
        "\n",
        "It turned out most of the behavior John thought was caused by the devil was pretty typical. The young boy did stack glass around his mother’s neck, and when asked why he did it, he said he was “making mommy pretty.” That’s… normal. Not demonic.\n",
        "\n",
        "Here are some other reasons John said his son was possessed:\n",
        "\n",
        "Eyes glazed over, fil\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "latest lakeshore news & sports for WOMT/WCUB/WQTC/WLKN/WLTU/WEMP\n",
        "\n",
        "Opening Weekend of Sturgeon Spearing\n",
        "\n",
        "This past weekend marked the opening weekend for sturgeon spearing on the Winnebago System. Day one was by far the better day, with 219 fish collected. Lake Winnebago saw decent numbers with 83 fish caught, but the Upriver Lakes saw much better success, with 136 fish reeled in. Day 2 was not quite as fruitful, with a total of 124 sturgeon captured. The split was much closer as well, with 56 fish coming from Lake Winnebago, and 68 fish being pulled from the Upriver Lakes. Joseph Orlando has the distinction of catching the largest sturgeon of the weekend, measuring at 77.5” long, and weighing a whopping 147.3 LBS. Congratulations to Joseph, and good luck to those braving the winter cold.<|endoftext|>I am a 44 yr. old french Canadian PHP developper who has been freelancing and offering consulting services for the past 15 years. I have had the opportunity to cater to a diverse range of clients: manufacturers, pharmaceutical companies and media corporations among others.\n",
        "\n",
        "I am interested in anything related to Open-Source Web developpment.\n",
        "\n",
        "I am curious on many subjects and aspects of programming: frameworks, design methodologies, testing methodologies, security, analysis and requirement coding tools, and any computer or stat related math.<|endoftext|>Sevoflurane and isoflurane impair edrophonium reversal of vecuronium-induced neuromuscular block.\n",
        "A dose-response relationship study for edrophonium to examine the modification of volatile anaesthetics on reversal of vecuronium block. One hundred and twenty ASA (I-II) patients were anaesthetized with sevoflurane, isoflurane (1 minimum alveolar anaesthetic concentration [MAC] end-tidal concentration), or fentanyl-diazepam anaesthesia, in combination with 66% nitrous oxide (n = 40 for each group). The evoked electromyogram (EMG) response of the abductor digiti minimi was monitored at 20 sec intervals following train-of-four (TOF) stimulation of the ulnar nerve. The initial neuromuscular block was produced by vecuronium 100 micrograms.kg-1. When the amplitude of the first response (T1) had spontaneously recovered to 10% of the control, edrophonium (0, 125, 400, 700 or 1000 micrograms.kg-1; eight patients each) was randomly administered, and the ratio of the fourth TOF to the first response (TOFR) was monitored at one minute intervals for 10 min. Sevoflurane and isoflurane impaired the edrophonium-assisted TOFR recovery in an edrophonium dose and time dependent manner. The dose-response curves at 10 min exhibited a greater shift to the right in the sevoflurane and isoflurane groups than in the fentanyl-diazepam-nitrous oxide group (P < 0.05). Higher ED50 values (the edrophonium dose required to obtain TOFR value of 50%) in the sevoflurane (> 1000 micrograms.kg-1) and isoflurane groups (851 micrograms.kg-1) were observed than in the fentanyl-diazepam-nitrous oxide group (339 micrograms.kg-1) (P < 0.05). One MAC sevoflurane and isoflurane anaesthesia impair edrophonium reversal of vecuronium block to a similar degree.<|endoftext|>Last weekend, Super Smash Bros. Melee's top talent traveled to Salt Lake City's Vivint Smart Home Arena for three days of high-level competition. Although Game Tyrant Expo (GT-X) had a bracket chock-full of potential winners, nobody could have predicted the extreme upsets that rocked Utah's first major.\n",
        "\n",
        "It's only fitting that a tournament defined by upsets would finish with one. At the end of the day, Adam \"Armada\" Lindgren, undoubtedly the favorite to win, was not the player standing atop the podium. Instead, Juan \"Hungrybox\" Debiedma slugged his way through a grueling 10-game grand finals to claim the largest share of the event's unprecedented $30,000 prize pool.\n",
        "\n",
        "By capturing back-to-back major titles, Hungrybox has definitively set himself apart from the group of contenders trying to take the number one ranking from Armada. But while the thought of playing further probably didn't cross Hungrybox's mind as he celebrated with a sea of fans, the season is far from over. In less than a week, Melee's pros will pick up their controllers once more to see who can fight their way to the top at The Big House 7. And despite his recent losses, Armada will still b\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "goodness my boss valued me and my job was safe, but my gut instincts had landed me in more than a little trouble that day and I was left wondering if I was right. The thought did briefly cross my mind that maybe I was over-analysing the situation and perhaps I was just a judgemental meanie!\n",
        "\n",
        "I had accepted that I'd never know if my intuition was right or if I was way out of line, when several months later Jim wandered into the lounge one afternoon, grinning at me.\n",
        "\n",
        "'There you go, you can put yourself out of your misery.' As he tossed me the paper he exclaimed, 'You were right!'\n",
        "\n",
        "As I started to read the article headed 'These little piggies have roast beef ', my jaw dropped. The sweet animal-hugging vegetarian, who had condemned me so harshly for not adopting out our animals to her, had started a free-range home-kill meat business and breeding facility. There she was with her husband, proudly cuddling one of their pigs. The article went into detail about how much they loved their lifestyle, their animals and their new wonderful service to the community.\n",
        "\n",
        "While I agree that free-range pig farming can be a momentous improvement on the cruel practice of factory farming, I think it's important for people to be honest and ethical in their intentions—a vegetarian pig farmer is somewhat hypocritical in my view!\n",
        "\n",
        "'Hey Carolyn, I just drove past the circus and there were a whole lot of protesters picketing it.'\n",
        "\n",
        "Jim was calling me from his cell phone. He made a great roving reporter, and could have had a job as the eye in the sky for the local radio station.\n",
        "\n",
        "'Is it the elephant do you think?'\n",
        "\n",
        "We had heard about the controversy surrounding this particular circus and its exploitation of exotic animals. A year had passed since our sneak peek behind the scenes of this very circus, and the animals we had seen had not stopped preying on our minds. As Jim continued to talk, all the unpleasant memories came flooding back.\n",
        "\n",
        "'What do you think, should we protest with them?' Jim had pulled over to watch the chaos as the big top was being erected in a local park.\n",
        "\n",
        "'I don't know. I wonder if anyone has actually just talked to him . . . maybe we should try?'\n",
        "\n",
        "As we sat with the ringmaster, we just listened at first. It was obvious he still loved an audience and he loved to tell his story. His was a classic; he had joined the circus as a boy and 50-odd years later it was all he knew. We asked him what his plans were and he admitted that he was tired and would love to slow down as his health was deteriorating. 'But with the bloody protesters on his back' he was too proud and stubborn to make the move.\n",
        "\n",
        "Over the next week Jim and I went to the river and foraged for willow branches for the elephant, loaded up Jim's ute and drove our offerings to the circus. We became familiar faces and the team of roadies were always grateful for our help. Before long we were able to talk to the ringmaster about retiring the animals. There was the elephant, the monkeys, the donkeys and pony as well as the lions, poodles and doves. He agreed it was time to let all of them go, except for the poodles and doves which were his wife's much-loved pets. After doing the sums and assessing our land we gave ourselves a reality check; lions and an elephant were probably too much for us to handle and after talking with the ringmaster we knew he had other good offers on the table from established wildlife sanctuaries. No one, however, wanted the monkeys. There were no sensible solutions in the pipeline, so we decided we would put our hands up. We also agreed to take Pablo the pony and Jenny and Wee One the donkeys back to HUHA.\n",
        "\n",
        "The day we were going to pick up the monkeys came along in a bit of a hurry. The ringmaster wasn't well and needed to move them on faster than agreed. It was winter and the tricky thing was that we didn't have anywhere to put them yet, let alone have an official sign-off from the Ministry of Agriculture and Fisheries (MAF). The ringmaster insisted that they needed to be gone immediately. He also insisted that we pay for the monkeys' caravan and temporary enclosure as part of the deal for which he would accept no less than $20,000. We tried to reason with him but his final words were always, 'Well you can bugger off then, and they can stay here.'\n",
        "\n",
        "We didn't want to lose the opportunity to get them out of the circus. We knew there was an opportunity for the ringmaster to sell them to another circus, so we weighed up our options and organised a second mortgage on our\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "&= \\iiiint_{\\mathbb{R}^{4}}\\left(-4\\pi \\delta(\\bar{r} -\\bar{r}')\\delta(t -t'))\\right) f(\\bar{r}',t') \\,dx'dy'dz'dt'=\\\\\n",
        "&= -4\\pi \\iiiint_{\\mathbb{R}^{4}}\\delta(\\bar{r} -\\bar{r}')\\delta(t -t') f(\\bar{r}',t') \\,dx'dy'dz'dt'=\\\\\n",
        "&=-4\\pi f(\\bar{r},t)\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\\end{mybox}\n",
        "\\begin{tikzpicture}[remember picture, overlay]\n",
        "\\draw[->] (pic cs:start) -- ++(0,-0.5) -- ++(-13,0) |- (pic cs:stop);\n",
        "\\end{tikzpicture}\n",
        "\\end{document}\n",
        "\n",
        "<|endoftext|>Ultra storage-efficient time digitizer for pseudorandom single photon counter implemented on a field-programmable gate array.\n",
        "Pseudorandom single photon counting is a novel time-resolved optical measurement method, which is advantageous over convention techniques in terms of data-acquisition speed and system cost. As a critical component of the pseudorandom single photon counter, the photon arriving time digitizer should be storage efficient for a high photon counting rate, while maintaining good time accuracy. We report an ultra storage-efficient time digitizer for a pseudorandom single photon counter in this paper, which is based on the asynchronous serial communication and can store the arriving time of every photon in 1-b memory space. In addition, a novel comb-wave modulator is proposed to achieve the dc balance required for asynchronous serial communication. Our prototype implemented on field-programmable gate arrays provides a time resolution of 400 ps. It can register up to 4.2-Giga photon arriving time tags with 1024 × 32-b memory space.<|endoftext|>I didn't wear my Veronica Mars T-shirt to interview Jason Dohring, but the thought did briefly cross my mind. After all, I was one of the few (well, 2.5 million) viewers who obsessively watched the teen sleuth drama from 2004 to 2007, first on UPN and then The CW.\n",
        "\n",
        "I integrated Veronica's vernacular into my vocabulary, purchased Mars memorabilia, asked my parents to buy me a T-Mobile Sidekick (Veronica's cellular weapon of choice), and when series creator Rob Thomas asked for my money in 2013 to help fund a feature film, I happily donated.\n",
        "\n",
        "And I was not alone.\n",
        "\n",
        "By now, the story of how Veronica Mars became 2013's most talked-about social media event is the stuff of legend. Heck, my father even asked if I donated to \"that Pluto movie\" (he's trying, guys) when I was home for Thanksgiving. But for those of you who just emerged from underneath a rock, here's the quick version:\n",
        "\n",
        "On March 12, 2013, Rob Thomas launched a Kickstarter campaign to turn his beloved neo-noir series about a teenage private eye into a movie. He gave himself two days to raise $2 million. That goal was met in 10 hours. But the Kickstarter clock kept counting and the donations continued to pour in, eventually topping out at $5,702,153 (a new Kickstarter record). So, the film was funded, the movie was made, the T-shirts were silkscreened, and that brings us to the present day, when I'm sitting cross-legged on the floor of a Los Angeles office with Jason Dohring — who played Logan Echolls, the show's bad boy with a heart of 24-karat gold — talking about the March 14 release of Veronica Mars' feature film.<|endoftext|><script>\n",
        "\texport let foo = '\">div><script>alert(42)' + 'script>';\n",
        "script>\n",
        "\n",
        "<div foo={foo}>div><|endoftext|>Q:\n",
        "\n",
        "Why do Maps have slower lookup property than Records in Erlang?\n",
        "\n",
        "I'm reading Programming Erlang, in Chapter 5 of the book it says:\n",
        "\n",
        "Records are just tuples in disguise, so they have the same storage and performance\n",
        "  characteristics as tuples. Maps use more storage than tuples and have\n",
        "  slower lookup properties.\n",
        "\n",
        "In languages I've learned before, this is not the case. Maps are usually implemented as a Hash Table, so the lookup time complexity is O(1); Records (Tuples with names) are usually implemented as an immutable List, and the lookup time complexity is O(N).\n",
        "What's different in the implementation of these data structures in Erlang?\n",
        "\n",
        "A:\n",
        "\n",
        "There's no real practical performance difference between record lookup and map lookup for small numbers of fields. For\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "though people recognize that smoking can lead to adverse health consequences, they do not have even a basic understanding of the nature and severity of these consequences.<|endoftext|>Digital Speech Standard\n",
        "\n",
        "Digital Speech Standard (DSS) is a proprietary compressed digital audio file format defined by the International Voice Association, a co-operative venture by Olympus, Philips and Grundig Business Systems.\n",
        "\n",
        "DSS was originally developed in 1994 by Grundig with the University of Nuremberg. In 1997, the digital speech standard was released, which was based on the previous codec. It is commonly used on digital dictation recorders. Modern psychoacoustical codecs that perform nearly as well at only slightly higher bitrates have led to this speech coding standard being less used in modern voice recording equipment.\n",
        "\n",
        "Operation\n",
        "The DSS file format stores voice audio data in a highly compressed format that allows basic recording functionality (such as recording, playing, rewinding, etc.) as well as the ability to record in either insert or overwrite mode making it ideal for dictation. This along with ability to include additional information in the file header for the transcriptionist including priority mark, author, job type, etc.\n",
        "\n",
        "DSS is a format designed specifically for speech, equivalent to MP3 for music. In contrast with MP3, however, the quality usually is as low as possible, to minimize the size of the file.\n",
        "\n",
        "External links\n",
        "Philips Dictation Systems- Website of Philips Dictation Systems\n",
        "Olympus Professional Dictation- Website of Olympus Professional Dictation\n",
        "Olympus.\n",
        "Grundig Business Systems - Website of Grundig Business Systems\n",
        "Express Scribe DSS player and transcription assistant from NCH Software\n",
        "\n",
        "See also\n",
        "Speech Processing Solutions\n",
        "Philips\n",
        "Olympus\n",
        "Grundig Business Systems\n",
        "\n",
        "\n",
        "Category:Digital dictation\n",
        "Category:Speech codecs<|endoftext|>House Speaker Mark Ferrandino, D-Denver, right, says goodbye to partner Greg Wertsch following the passage of Senate Bill 11, which will allow gay couples to form civil unions in Colorado. (Craig F. Walker, The Denver Post)\n",
        "\n",
        "A bill allowing same-sex couples to form civil unions is on its way to the governor for his signature, but gay-rights activists say they won't stop until they get true equality, which is marriage.\n",
        "\n",
        "The Colorado House on Tuesday passed the bill 39-26 despite protests from Republicans that the bill faces legal challenges because it doesn't offer religious exemptions.\n",
        "\n",
        "\"We won't get to debate this again here, but we will debate this in a court of law,\" said Rep. Lori Saine, R-Dacono.\n",
        "\n",
        "The passage marks the first time in three years the bill has made it through the House, which was controlled by Republicans in the two previous sessions.\n",
        "\n",
        "Reps. Paul Rosenthal, D-Denver; Joann Ginal, D-Fort Collins; and Dominick Moreno, D-Commerce City hold hands while listening to comments before a vote on civil unions. The three lawmakers are gay. (Craig F. Walker, The Denver Post)\n",
        "\n",
        "Speaker Mark Ferrandino, a gay Denver Democrat who has carried the bill each year, said Senate Bill 11 is about love, family and equality under the law.\n",
        "\n",
        "\"This wasn't a choice. This is who I am. This is who we are,\" he said of being gay. \"We need to make laws in our society that respect everyone equally.\"\n",
        "\n",
        "After the vote, the five gay lawmakers in the House and the three gay lawmakers in the Senate lauded those who decades ago took up the fight for equality or were forced to live in the shadows.\n",
        "\n",
        "\"Today is really a memorial, remembering those who were shamed because they were gay or had AIDS,\" said Sen. Lucia Guzman, D-Denver.\n",
        "\n",
        "Sen. Pat Steadman, D-Denver, who has sponsored the civil-unions bill for three years, said its passage is the high point of a decades-long struggle.\n",
        "\n",
        "\"Yet we're not there yet. I don't want anyone to think that we somehow reached the peak,\" Steadman said. \"Civil unions are not marriage. They are something that are separate and distinct and lesser and unequal, and that really is not good enough.\"\n",
        "\n",
        "But both he and Ferrandino pointed out that civil unions offer important protections for children and families, and they were thrilled to see the bill finally pass.\n",
        "\n",
        "Gays cannot marry in Colorado because of a 2006 constitutional amendment that defined marriage as between one man and one woman. Voters passed it 55 percent to 45 percent while defeating a civil-unions-type measure.\n",
        "\n",
        "Gov. John Hickenlooper, a Democrat and a longtime supporter of gay rights, is expected to sign the bill later this month. The bill becomes law May 1.\n",
        "\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "5dncann6Ympb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_3_2 = [\n",
        "    r\"\"\"\n",
        "     xmllint only uses the reader interface when passed the --stream option:\n",
        "$ xmllint --stream --pattern /foo/bar test.xml\n",
        "Node /foo/bar[1] matches pattern /foo/bar\n",
        "Node /foo/bar matches pattern /foo/bar\n",
        "\n",
        "A:\n",
        "\n",
        "From the xmllint(1) man page:\n",
        "   --pattern PATTERNVALUE\n",
        "          Used to exercise the pattern recognition engine, which can be\n",
        "          used with the reader interface to the parser. It allows to\n",
        "          select some nodes in the document based on an XPath (subset)\n",
        "          expression. Used for debugging.\n",
        "\n",
        "It only understands a subset of XPath and its intention is to aid debugging. The library that does understand XPath fully is libxslt(3) and its command-line tool xsltproc(1).\n",
        "The ``pattern'' module in libxml \"allows to compile and test pattern expressions for nodes either in a tree or based on a parser state\" and its documentation lives here: http://xmlsoft.org/html/libxml-pattern.html\n",
        "Ari.\n",
        "\n",
        "<|endoftext|>Q:\n",
        "\n",
        "Choosing the best fit sentence to mail prospective PhD supervisor\n",
        "\n",
        "I am applying for a PhD scholarship which was posted on the university website and for that, I am writing mail to the professor. I have written about my background, academics, interests and experience. I want to ask him the procedure for applying for the scholarship. I am not a native English speaker so I am not sure that which of the following sentence would be best for that:\n",
        "Plese let me know about the application procedure\n",
        "Please let me know how can I apply for the position\n",
        "Or if there is another way to ask, kindly suggest.\n",
        "\n",
        "A:\n",
        "\n",
        "The wording probably doesn't matter too much. You can simply say \"I am interested in applying for X scholarship. How does the application procedure work?\".\n",
        "However, before you send the email, make sure you check the details aren't already online somewhere. Also consider if your email would be better addressed to the department administrator rather than the professor, as an administrator is more likely to know all the necessary technical details.\n",
        "\n",
        "<|endoftext|>Bone marrow microvessel density in chronic myeloproliferative disorders: a study of 115 patients with clinicopathological and molecular correlations.\n",
        "Philadelphia-negative chronic myeloproliferative disorders (CMD) include polycythemia vera (PV), essential thrombocythemia (ET) and primary myelofibrosis (PMF). Angiogenesis is critical in the pathogenesis of PMF. We studied angiogenesis in 115 patients with CMD (23 PV, 24 ET, 46 PMF, 12 post-PV and 10 post-ET myelofibrosis) by assessment of microvessel density (MVD) in bone marrow (BM). Kruskall-Wallis analysis of variance showed that patients with PMF had significantly higher values of MVD than those with PV (P < 0.001), ET (P < 0.001) and controls (P < 0.001). Mann-Whitney U-test demonstrated that patients with PMF at the prefibrotic stage had significantly higher MVD values than those with ET (P = 0.02). Patients with post-PV myelofibrosis showed significantly higher MVD values than those with PV (P < 0.001), as did patients with post-ET myelofibrosis compared with ET (P < 0.001). In patients with CMD, the multivariate generalized linear regression model showed that the JAK2 (V617F) mutational burden (P = 0.01), serum lactate dehydrogenase level (P = 0.003), and anaemia (P < 0.001) independently correlated with MVD. In summary, this study indicates that assessment of BM angiogenesis, as measured by MVD, may be a useful additional tool in the histopathological definition of CMD.<|endoftext|>Microfabrication conventionally uses photolithography or optical lithography processes for selectively removing parts of a substrate, or parts of a material layer on the substrate. For example, photolithography uses a directed light (radiation) source to transfer a pattern from a photomask (also referred to as a mask or reticle) to a light-sensitive resist material formed on the substrate or material layer, thereby generating an exposure pattern in the resist material. Chemical treatments may then be used to etch or otherwise transfer the exposure pattern in the resist material to the substrate or material layer. More recently, microfabrication has implemented other lithography types, such as charged particle beam lithography, that do not necessitate the intermediary step of creating the mask to transfer or generate an exposure pattern in a resist material. For example, electron beam (e-beam) lithography uses a focused beam of electrons to expose the resist material. Instead of using a mask, e-beam lithography “writes” a pattern directly into an energy-sensitive resist material\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "     before).\n",
        "What I don't know is how can I have 32 inputs, since the Raspberry Pi board has less than 32 I/O pins.\n",
        "I have the impression I need another component for that (like a converter... or something), but again, I don't know what I need to build the electronic part of this project.\n",
        "How can I connect more inputs to the Raspberry Pi? What would be the best way to build this?\n",
        "\n",
        "The pedals should work simultaneously as well.\n",
        "\n",
        "A:\n",
        "\n",
        "The best way depends on factors only you can determine.\n",
        "I give a couple of ways.\n",
        "\n",
        "use two MCP23017, each of which supply 16 digital IO.  They use the I2C bus (pins 3/5, GPIO 2/3) and up to 8 can be used on the bus.\n",
        "use 4 8-bit input shift registers.  They provide 8 digital inputs each.  They can use the SPI bus and you can daisy chain as many as you want.  If needed you could instead bit bang reading the devices from any GPIO.\n",
        "\n",
        "The shift registers are probably better for your application.  They are likely to be more responsive as you can drive the SPI bus much faster than the I2C bus.\n",
        "\n",
        "<|endoftext|>Vadym Karatayev\n",
        "\n",
        "Vadym Karatayev or Vadim Karataev (born 15 January 1964) is an association footballer from the former Soviet Union.\n",
        "\n",
        "In 1983 Karatayev took part in the Summer Spartakiad of the Peoples of the USSR in the team of Ukrainian SSR. He also participated in the 1983 FIFA World Youth Championship for the Soviet team.\n",
        "\n",
        "References\n",
        "\n",
        "External links\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Category:1964 births\n",
        "Category:Living people\n",
        "Category:People from Alchevsk\n",
        "Category:Soviet footballers\n",
        "Category:Ukrainian footballers\n",
        "Category:Soviet Top League players\n",
        "Category:FC Dynamo Kyiv players\n",
        "Category:FC Chornomorets Odesa players\n",
        "Category:FC Shakhtar Stakhanov players\n",
        "Category:FC Krystal Kherson players\n",
        "Category:FC Zimbru Chișinău players\n",
        "Category:Wisła Płock players\n",
        "Category:Hapoel Ashkelon F.C. players\n",
        "Category:Ukrainian expatriate footballers\n",
        "Category:Expatriate footballers in Israel\n",
        "Category:Expatriate footballers in Poland\n",
        "Category:Association football defenders\n",
        "Category:Neftçi PFK players<|endoftext|>Q:\n",
        "\n",
        "Choosing the best fit sentence to mail prospective PhD supervisor\n",
        "\n",
        "I am applying for a PhD scholarship which was posted on the university website and for that, I am writing mail to the professor. I have written about my background, academics, interests and experience. I want to ask him the procedure for applying for the scholarship. I am not a native English speaker so I am not sure that which of the following sentence would be best for that:\n",
        "Plese let me know about the application procedure\n",
        "Please let me know how can I apply for the position\n",
        "Or if there is another way to ask, kindly suggest.\n",
        "\n",
        "A:\n",
        "\n",
        "The wording probably doesn't matter too much. You can simply say \"I am interested in applying for X scholarship. How does the application procedure work?\".\n",
        "However, before you send the email, make sure you check the details aren't already online somewhere. Also consider if your email would be better addressed to the department administrator rather than the professor, as an administrator is more likely to know all the necessary technical details.\n",
        "\n",
        "<|endoftext|>Our first glimpse at components that could be destined for the much-rumored 5.8-inch \"iPhone 8\" and its 4.7 and 5.5-inch companion devices surfaced this morning in a post on reddit. The images are said to be sourced from a case manufacturer who received them from a glass supplier in China.\n",
        "\n",
        "The first photo depicts what is said to be the front and back panel of the iPhone 8, with the front panel featuring a super thin bezel around all sides along with a top bar that could perhaps house a front-facing camera, microphone, and speaker. There's been some question on how Apple will handle the front-facing camera and mockup devices and renderings haven't offered a clear picture.\n",
        "\n",
        "\n",
        "\n",
        "Some design renderings have shown a section at the top of the device similar to the front panel in this image, while others seem to feature a bar that extends fully across the top of the device.\n",
        "\n",
        "The rear panel features a vertical dual-lens camera and a separate protruding lens component, with no rear Touch ID in sight, in line with rumors suggesting Apple has indeed figured out how to build Touch ID into the display of the device.\n",
        "\n",
        "A second photo depicts the two alleged iPhone 8 components next to alleged components for the 4.7-inch iPhone 7s and the 5.5-inch iPhone 7s Plus, two devices that are rumored\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    correlate these alterations with histological damage. Wistar rats were treated with methotrexate (1.5-3.5 mg/kg) for 3 days to induce mucositis. Intestinal permeability was measured by the urinary excretion rate of lactulose and mannitol following administration by gavage. Intestinal perfusion was performed in vivo for evaluation of water and electrolyte transports. Methotrexate-treated rats lost a significant amount of weight and presented a marked reduction in food intake. Methotrexate induced significant and dose-dependent villous atrophy and elongation of crypts in duodenum, jejunum, and ileum. Methotrexate also induced an increase in sodium and potassium secretion and an important reduction of the mucosa absorptive surface area, shown by the decrease in the mannitol excretion ratio. In conclusion, methotrexate caused major changes in small bowel function by disrupting intestinal permeability and inducing electrolyte secretion in parallel with substantial histological damage.<|endoftext|>Buhay OFW\n",
        "\n",
        "Buhay OFW (English translation: Life of an OFW) is a weekly public service program aired on 5 Plus catered for the Overseas Filipino Workers or OFWs based in different countries outside the Philippines. The program also featured government and non-government organizations who are charged in taking care the concerns of OFWs such as labor and recruitment issues. Buhay OFW also highlighted untold and successful stories of OFWs who are survived from adversities and sufferings while working outside the country but have also given inspiration to their fellow Kababayans. The program also successfully organized several projects for the OFW community such as the Mr. and Ms. Citizens of the World, which was launched In 2012, in time for the program's 1st anniversary.\n",
        "\n",
        "The program was premiered on September 10, 2011, and it currently aired as the blocktime program of AksyonTV (5 Plus since 2019) every Saturday evenings at 9-10pm (PST). It is also aired worldwide via AksyonTV International. The program currently hosted by Marissa del Mar, a one-time PMPC Star Awards Best Public Service Program Host awardee and former host of Up Close and Personal on IBC-13, which was awarded as the Best Public Service Program, also from the PMPC Star Awards. Buhay OFW is produced by Millicent Productions, del Mar's own production house.\n",
        "\n",
        "On October 2016, Buhay OFW was awarded as the Best Public Service Program, together with Mission: Possible of ABS-CBN, in the recently concluded 30th PMPC Star Awards for Television.\n",
        "\n",
        "References\n",
        "\n",
        "External links\n",
        "Official Website\n",
        "\n",
        "Category:AksyonTV shows\n",
        "Category:Philippine documentary television series\n",
        "Category:News5 programs\n",
        "Category:2011 Philippine television series debuts\n",
        "Category:2019 Philippine television series endings<|endoftext|>Comparative viability of expanded and unexpanded axial pattern skin flaps in pigs.\n",
        "A comparison of viable areas of axial pattern flaps post inset was made between expanded and non-expanded pig buttock island flaps. The deep circumflex iliac artery and vein supply approximately the proximal 14 x 10 cm area of this flap. Larger flaps were raised on expanded and control sides of eight pigs to determine if expansion increased the area of survival. In six of eight pigs whose initial tissue expansion did not create more than approximately a 50% increase in skin area, the expanded flaps had a statistically significant increase in viable skin area (proportionally) 10 days post inset than their control flaps (p less than 0.05). Two other pigs did not conform to this pattern. Their initial tissue expansion was greater than 50%, and the resulting area of flap viability was proportionally less in expanded flaps than the control flaps.<|endoftext|>Q:\n",
        "\n",
        "Question about recommendation letter\n",
        "\n",
        "I am applying my MA program in October, there is a professor agree to write a recommendation letter for me. But I couldn't find another professor who is willing to write a recommendation letter for me. So I have to apply the mater program next year. I want to email to that professor to tell her I decide not to apply for the MA program this year and ask if she can still help me with the recommendation letter next year (I don't know if she finish it or not). I am not a native English speaker, so I want to ask what should I say to the professor in the email? In a polite way. Thanks!\n",
        "\n",
        "Can anyone help me to check if this email is polite? Can I say like this?\n",
        "\n",
        "Hi professor,  I am writing to tell you that unfortunately I met some\n",
        "  problems with my application for the graduate program, and now I do\n",
        "  not have enough time for applying my dream school this year.\n",
        "  Therefore, I decide to take a gap year to participate in some\n",
        "  internships and prepare for the IELTS test. I will apply the graduate\n",
        "  program again in September\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "     that right? If so, then is it safe to assume that the draft introduction is essentially the \"pitch\" for the substance of the book? Thanks!\n",
        "\n",
        "David, I know you've stated the royalty rate hasn't yet been determined, but are there any reasonable assumptions that might be made. For example, will the royalty rate run any higher than it might have in the past to make up for the lack of advance? Is there any sort of ballpark range to help writers determine whether writing a book — or even a proposal — is worth the time spent on the gamble?\n",
        "\n",
        "Also, what are the terms of copyright/ownership Bloomsbury is purchasing?\n",
        "\n",
        "What guarantee is there that, once contracted, the book written will ever be published? It seems like without any financial investment in the author, Bloomsbury doesn't have much skin in the game, so to speak... How are you ensuring good-faith with the selected writers?\n",
        "\n",
        "Mike: Yes, that's a fair assumption, about the draft Intro. Ideally we'd ask for more but it doesn't seem fair to ask people for more when it's entirely possible that we'll receive 200-300 proposals and will only be able to publish 15-20 of them. If we're intrigued by a proposal and want to find out more, we may get back to individual authors at that point.\n",
        "\n",
        "Anon #1: I can't see that the royalty rate will go any higher than what it's always been on these, which is 10% of net receipts. I'll try to build in some kind of staggered royalty so that the rate goes up after a certain number of sales. Copyright: our contracts all contain, before Clause 1, the phrase \"Author is the author of, and owner of the copyright in, the work provisionally entitled...\" Good faith: we're nice people. If we sign a contract to work together, we assume that the author will deliver his/her side of the deal, we'll absolutely do the same. Works a treat, every time.\n",
        "\n",
        "i am not a native speaker, my english is quite good though (i believe). i'm sure i could write a great text for the series. would the possible need for extra proof reading / editing on your end be a problem?\n",
        "\n",
        "and also: what is the situation with foreign rights? since some of my research for the porposed text would be german language interviews and german is my first language, it would be a reasonably modest job for me to produce a german version of the text. would i be able to sell that directly to a german publisher or would bloomsbury's contract extend to the german version as well?\n",
        "\n",
        "I got some very positive feedback on a proposal I submitted in the last round (thanks Dave!) but was told the \"marketing guys\" (okay maybe that was not the term used) were not sold on it because they thought it might not sell enough copies. Should I try again, re-tweaking to suggest why it is in fact a viable idea?\n",
        "\n",
        "David, My agent believes she should submit my proposal (as she does my work with other publishers), but I don't see how to do that given the carefully choreographed submission procedures. Can an agent submit on behalf of a client?\n",
        "\n",
        "From the same anonymous: hi again! I should clarify that the \"reissue\" here is not a reissue of a previously issued compilation but, rather, the first time that three hard-to-find albums were issued as a set. Thanks for any light you can shed on this!\n",
        "\n",
        "1. Is there any way for you to elaborate on how the royalties work? My understanding is that since there's no advance to recoup, the writer would get royalties starting with the very first copy that sells, correct? Also, does \"10% net receipts\" mean the author will receive 10% of all sales? Just trying to get an idea. Say the author sold 5,000 copies. How much money would that give them in royalties?\n",
        "\n",
        "2. Will oral histories be considered for publication? My apologies if there's already been a 33 1/3 oral history published that I haven't read.\n",
        "\n",
        "Lunt435: No, that would not be a problem, if the proposal is good enough. Foreign rights: Bloomsbury would want to keep these if at all possible, although such matters can be sometimes negotiated at contract stage.\n",
        "\n",
        "Peg: it's a question we're asked often and there's no easy answer to it! If the project is one you're passionate about, and you feel confident you can persuade us of its viability then yes, please do submit a revised version of it.\n",
        "\n",
        "Anon #1: yes, an agent can submit your proposal on your behalf, as long as it conforms to the guidelines we've set out.\n",
        "\n",
        "Anon #2: A collection of short albums\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "uiTBismrOobo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_3_912 = [\n",
        "    r\"\"\"\n",
        "                super(columns);\n",
        "            if (type == null || number == null) {\n",
        "                throw new IllegalArgumentException(\n",
        "                    \"type and number must be non-null\");\n",
        "            }\n",
        "            this.type = type;\n",
        "            this.number = number;\n",
        "            isComparable = (number instanceof Comparable);\n",
        "        }\n",
        "\n",
        "        @Override\n",
        "        @SuppressWarnings(\"unchecked\")\n",
        "        protected boolean include(\n",
        "                Entry extends M, ? extends I> value, int index) {\n",
        "            Object v = value.getValue(index);\n",
        "\n",
        "            if (v instanceof Number) {\n",
        "                boolean compared = true;\n",
        "                int compareResult;\n",
        "                Class> vClass = v.getClass();\n",
        "                if (number.getClass() == vClass && isComparable) {\n",
        "                    compareResult = ((Comparable)number).compareTo(v);\n",
        "                }\n",
        "                else {\n",
        "                    compareResult = longCompare((Number)v);\n",
        "                }\n",
        "                switch(type) {\n",
        "                case BEFORE:\n",
        "                    return (compareResult > 0);\n",
        "                case AFTER:\n",
        "                    return (compareResult < 0);\n",
        "                case EQUAL:\n",
        "                    return (compareResult == 0);\n",
        "                case NOT_EQUAL:\n",
        "                    return (compareResult != 0);\n",
        "                default:\n",
        "                    break;\n",
        "                }\n",
        "            }\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        private int longCompare(Number o) {\n",
        "            long diff = number.longValue() - o.longValue();\n",
        "\n",
        "            if (diff < 0) {\n",
        "                return -1;\n",
        "            }\n",
        "            else if (diff > 0) {\n",
        "                return 1;\n",
        "            }\n",
        "            return 0;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    private static class OrFilter<M,I> extends RowFilter<M,I> {\n",
        "        List<RowFilter super M,? super I>> filters;\n",
        "\n",
        "        OrFilter(Iterable extends RowFilter super M, ? super I>> filters) {\n",
        "            this.filters = new ArrayList<RowFilter super M,? super I>>();\n",
        "            for (RowFilter super M, ? super I> filter : filters) {\n",
        "                if (filter == null) {\n",
        "                    throw new IllegalArgumentException(\n",
        "                        \"Filter must be non-null\");\n",
        "                }\n",
        "                this.filters.add(filter);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        public boolean include(Entry extends M, ? extends I> value) {\n",
        "            for (RowFilter super M,? super I> filter : filters) {\n",
        "                if (filter.include(value)) {\n",
        "                    return true;\n",
        "                }\n",
        "            }\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    private static class AndFilter<M,I> extends OrFilter<M,I> {\n",
        "        AndFilter(Iterable extends RowFilter super M,? super I>> filters) {\n",
        "            super(filters);\n",
        "        }\n",
        "\n",
        "        public boolean include(Entry extends M, ? extends I> value) {\n",
        "            for (RowFilter super M,? super I> filter : filters) {\n",
        "                if (!filter.include(value)) {\n",
        "                    return false;\n",
        "                }\n",
        "            }\n",
        "            return true;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    private static class NotFilter<M,I> extends RowFilter<M,I> {\n",
        "        private RowFilter<M,I> filter;\n",
        "\n",
        "        NotFilter(RowFilter<M,I> filter) {\n",
        "            if (filter == null) {\n",
        "                throw new IllegalArgumentException(\n",
        "                    \"filter must be non-null\");\n",
        "            }\n",
        "            this.filter = filter;\n",
        "        }\n",
        "\n",
        "        public boolean include(Entry extends M, ? extends I> value) {\n",
        "            return !filter.include(value);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "<|endoftext|>Mesonerilla prospera\n",
        "\n",
        "Mesonerilla prospera is a species of invertebrate in the Nerillidae family endemic to Bermuda.\n",
        "In 2000, M. prospera was put on the IUCN Red List under the critically endangered category. The IUCN states that \"there are problems with the Order name and the correct placement of the family.\"\n",
        "\n",
        "References\n",
        "\n",
        "Category:Polychaetes\n",
        "Category:Endemic fauna of Bermuda\n",
        "Category:Animals described in 1982\n",
        "Category:Taxonomy articles created by Polbot<|endoftext|>We have to prepare ourselves for a second referendum\n",
        "\n",
        "It is hard to think of any phrase in 21st-century Britain that is more Orwellian than ‘People’s Vote’.\n",
        "\n",
        "The bruised elites, still reeling from the vote for Brexit, say ‘People’s Vote’ when what they really mean is second\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "     Between 1994 and now, one other person was infected and survived. Though, confusingly, the US Centers for Disease Control reports that two out of three human infections prior to this year were fatal.\n",
        "\n",
        "Julia Whitty is Mother Jones’ environmental correspondent, lecturer, and 2008 winner of the Kiriyama Prize and the John Burroughs Medal Award.<|endoftext|>Old Hamilton County Jail\n",
        "\n",
        "The Old Hamilton County Jail is a historic building at 501 Northeast 1st Avenue, Jasper, Florida, United States. It was added to the National Register of Historic Places in 1983.  The Old Hamilton County Jail now serves as the Hamilton County Historical Museum.\n",
        "\n",
        "Hamilton County Historical Museum\n",
        "\n",
        "The Hamilton County Historical Museum consists of a jail.\n",
        "\n",
        "See also\n",
        "Jails and prisons listed on the National Register of Historic Places\n",
        "\n",
        "References\n",
        "\n",
        "External links\n",
        " Hamilton County Historical Museum - official site\n",
        " Hamilton County listings, Florida's Office of Cultural and Historical Programs\n",
        "\n",
        "Hamilton County Jail\n",
        "Category:Museums in Hamilton County, Florida\n",
        "Hamilton County Jail\n",
        "Category:Prison museums in Florida\n",
        "Category:History museums in Florida\n",
        "Category:Jails in Florida\n",
        "Category:National Register of Historic Places in Hamilton County, Florida\n",
        "Category:1893 establishments in Florida<|endoftext|>Q:\n",
        "\n",
        "Убрать у всех class=\"active\"\n",
        "\n",
        "Как на js можно у всех li которые в ul убрать класс active, есть идея реализации в цикле пройтись и проверить наличие класса и убрать, но не думаю что лучшее решение, как правильнее сделать?\n",
        "<ul class=\"nav navbar-nav\">\n",
        "  <li class=\"active\" id=\"1\" ><a href=\"/\" >9a>li>\n",
        "  <li class=\"active\" id=\"2\" ><a href=\"/\" >8a>li>\n",
        "  <li class=\"active\" id=\"3\" ><a href=\"/\" >7a>li>\n",
        "  <li id=\"4\" ><a href=\"/\" >6a>li>\n",
        "  <li class=\"active\" id=\"5\" ><a href=\"/\">5a>li>\n",
        "  <li id=\"6\" ><a href=\"/\" >4a>li>\n",
        "  <li class=\"active\" id=\"7\"  ><a href=\"/\" >3a>li>\n",
        "  <li id=\"8\" ><a href=\"/\" >2 a>li>\n",
        "  <li class=\"active\" id=\"9\" ><a href=\"/\" >1a>li>\n",
        " ul>\n",
        "\n",
        "P.s. active может отсутствовать у некоторых элементов как выше в 8, 6, 4\n",
        "\n",
        "A:\n",
        "\n",
        "Проще всего это сделать вот так:\n",
        "$('ul li.active').removeClass('active');\n",
        "\n",
        "<|endoftext|>More Like This\n",
        "\n",
        "Quick Reference\n",
        "\n",
        "The subphylum chelicerata, of which horseshoe crabs form a small part, is more commonly represented by its terrestrial members – the arachnids (spiders, scorpions, and their relatives). The horseshoe crabs'primordial ...<|endoftext|>Q:\n",
        "\n",
        "How apply a bitmask to an integer in MySQL?\n",
        "\n",
        "Here is the problem:\n",
        "The database Rx30 stores the status of a prescription in a field called 'Rxstatus.' The number they store there is an integer that is never higher than 255. The bits that are set determine whether or not a script is filled.\n",
        "A representative told us that if 16, 32, or 128 is set, the script is deemed 'unfilled.'\n",
        "So now what we need to do is take an integer, say '49', and see which bits are set. This needs to be done through MySQL for speed's sake. I understand that 49 is:\n",
        "32+16+1 = 49\n",
        "\n",
        "So 16 is set in this field, therefore the script is unfilled.\n",
        "How (in MySQL) can I take an integer, say 152 for example, and determine which bits of it are set?\n",
        "Once we determine what's set, if 16, 32, or 128 is set we can deem the script unfilled and produce the correct results.\n",
        "\n",
        "A:\n",
        "\n",
        "If you have a test bit mask, e.g. 32+16+1 = 49, and you want to know if any of these are set in Rxstatus, you use:\n",
        "SELECT Rxstatus & 49 != 0\n",
        "\n",
        "If you want to know if all of them are set, you use:\n",
        "SELECT Rxstatus & 49 = 49\n",
        "\n",
        "To set all the bits from\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    plan for the duration of the work.\n",
        "\n",
        "April, 2005: Proceedings are instituted in the High Court to prevent residents obstructing the construction of the gas pipeline at Rossport. The High Court grants Shell the right to access private lands in the village for the installation of the pipeline. Meanwhile, it is revealed that Shell employed a company of which it is a substantial shareholder to conduct an ‘independent’ audit of the pipeline’s safety.\n",
        "\n",
        "June, 2005: Five residents from Rossport are jailed for contempt of court for refusing to obey the High Court order not to interfere with the construction of the Corrib gas pipeline. The men vow to stay in prison until they get justice.\n",
        "\n",
        "Families and supporters of the Rossport Five commence round the clock picketing at Rossport, Bellinaboy and Glengad: Shell pipeline sites in Mayo.\n",
        "\n",
        "July, 2005: National rallies held in support of the Rossport Five in Castlebar, Belmullet, Ballina, Dublin.\n",
        "\n",
        "Natural Resources Minister Noel Dempsey orders a further safety review of the Corrib Gas pipeline with a view to ending the standoff between Shell and local residents in Co Mayo.\n",
        "\n",
        "Minister Dempsey said Marine and Natural Resources Dept officials had carried out an inspection at the Shell onshore site and subject to further legal advice, it was his view that a serious breach of the consents given to Shell in relation to the pipeline had occurred. He ordered Shell to dismantle three kilometres of gas pipeline that it had assembled in north Mayo.\n",
        "\n",
        "August, 2005: Marine and Natural Resources Minister, Noel Dempsey, granted Shell permission to lay the 75 kilometres of pipeline from the Corrib Field to the North Mayo coastline.\n",
        "\n",
        "Shell E&P Ireland defers laying the offshore pipeline for the Corrib gas project until 2006. Shell said the temporary suspension ''will not materially affect the project's completion schedule'', and will ''allow for a period of discussion and dialogue''.\n",
        "\n",
        "Shell announces that it is to lay off 128 workers at the Corrib gas pipeline in Co Mayo. National rally in support of the Rossport 5 held in Galway. Minister for Communications, Marine and Natural Resources Noel Dempsey announces a further safety review.\n",
        "\n",
        "September, 2005: Family and supporters visit Norway and meet Statoil and public representatives. Rossport Five appear before Mr Justice Finnegan in the High Court.\n",
        "\n",
        "1 October, 2005: Thousands rally in support of Rossport Five in Dublin.\n",
        "\n",
        "12 October, 2005: A two-day public consultation organised by the Department of the Marine is held in Geesala, Co. Mayo\n",
        "\n",
        "25 October, 2005: Rossport Five appear before Mr Justice Finnegan in the High Court\n",
        "\n",
        "31 October, 2005: The Minister announced that he had appointed Mr Peter Cassells, a former general secretary of the Irish Congress of Trade Unions, to mediate between Shell E&P and the Rossport residents\n",
        "\n",
        "11th September - Solitaire forced to withdraw from Broadhaven bay after its pipe laying appartus became damaged. The previousday several people had been arrested while blocking roads and Pat O'Donell and his son had been arrested again to prevent them fishing the bay.\n",
        "\n",
        "Search\n",
        "\n",
        "Blast from the Past\n",
        "\n",
        "Garda whistleblower Maurice McCabe’s first contact with a TD came about because he saw Clare Daly TD on ‘Tonight with Vincent Browne’ talking about policing of Corrib Gas protests, writes William Hederman\n",
        "\n",
        "The repercussions for Garda whistleblowers Maurice McCabe and John Wilson will be familiar to others who have publicly embarrassed An Garda Síochána. They were clearly acting in the public interest, but their revelations brought the force into disrepute, and the two men suffered as a result. Revenge was exacted – not only by colleagues, but also by way of public denunciation by the Garda Commissioner (“disgusting”), the Minister for Justice (“not co-operating”) and by various other parties loyal to the force.<|endoftext|>Allendale County Courthouse\n",
        "\n",
        "Allendale County Courthouse is a historic county courthouse in Allendale, Allendale County, South Carolina. It was added to the National Register of Historic Places in 2007.\n",
        "\n",
        "Description and history\n",
        "It was built in 1921-1922, and is a two-story yellow brick and limestone-accented building with a central block with pedestaled pediment dominated by a monumental, unengaged, flat-roofed Neoclassical Revival portico. The portico features four massive limestone columns and responding pilasters of the Tuscan order, a classical entablature, and a brick-and-limestone parapet.\n",
        "\n",
        "Immediately to the rear and connected to the historic courthouse by a narrow two-story hyphen is a large office and courtroom building that was completed and occupied in 2004\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    <|endoftext|>TimerEventDefinition.class);\n",
        "    timerDefinition.setTimeDate(timeDate);\n",
        "    return timerDefinition;\n",
        "  }\n",
        "\n",
        "  protected TimerEventDefinition createTimeDuration(String timerDuration) {\n",
        "    TimeDuration timeDuration = createInstance(TimeDuration.class);\n",
        "    timeDuration.setTextContent(timerDuration);\n",
        "    TimerEventDefinition timerDefinition = createInstance(TimerEventDefinition.class);\n",
        "    timerDefinition.setTimeDuration(timeDuration);\n",
        "    return timerDefinition;\n",
        "  }\n",
        "}\n",
        "<|endoftext|>China Grove (Gardner, Louisiana)\n",
        "\n",
        "China Grove is a historic house located in Gardner, Louisiana. It was added to the National Register of Historic Places on December 5, 1984. The house is considered to be an outstanding example of neo-classical and Greek Revival architecture; its Greek Revival woodwork in particular stands out among houses in the region.\n",
        "\n",
        "It was listed as one result of a study of 10 Neo-Classical farm-plantation houses along Bayou Rapides.  As for several of the others (Eden, Geneva, Hope, Island Home, Longview), China Grove was modified by addition of hood along its original gallery, termed a false gallery, which provides additional protection from the rain, detracting somewhat but not greatly from its original appearance.\n",
        "\n",
        "References\n",
        "\n",
        "Category:Houses on the National Register of Historic Places in Louisiana\n",
        "Category:Houses completed in 1857\n",
        "Category:Houses in Rapides Parish, Louisiana\n",
        "Category:Neoclassical architecture in Louisiana\n",
        "Category:National Register of Historic Places in Rapides Parish, Louisiana\n",
        "Category:1857 establishments in Louisiana<|endoftext|>Travis Dyson is the 30-year-old Florida man who was found in a hotel room with Democratic politician Andrew Gillum on March 13. Police said Dyson appeared to have suffered a drug overdose. He is conscious and in stable condition in a Miami-area hospital.\n",
        "\n",
        "Dyson maintains a profile on a website for male escorts and is studying at a nurse practitioner school. Gillum has been married to R. Jai Gillum since 2009. The couple have three children together.\n",
        "\n",
        "In 2018, Gillum, 40, was the surprise winner of the Democratic primary for governor in Florida. Gillum lost the general election narrowly to Ron De Santis. Since then, Gillum has been a rising star in the Democratic party. Between 2014 and 2018, Gillum served as the mayor of Tallahassee.\n",
        "\n",
        "Here’s what you need to know:\n",
        "\n",
        "1. Gillum Said He Was in Miami to Celebrate a Wedding but Dyson Said the Former Mayor Never Mentioned it\n",
        "\n",
        "Former Gubernatorial Candidate Andrew Gillum Found In Room With Possible Crystal MethAndrew Gillum said he was in town for a wedding and had too much to drink but never used methamphetamines 2020-03-13T16:44:08.000Z\n",
        "\n",
        "Gillum has said that he was in Miami for a wedding. The former Tallahassee mayor admitted to “drinking too much” but denied that he had taken any drugs. Gillum was too drunk to speak to the police when they arrived at the scene, documents say. Speaking to the Miami New Times, Dyson said that Gillum did not mention attending a wedding. In his statement, Gillum referred to Dyson as a “friend.” Dyson said that he and Gillum had been friends since last spring. Dyson told the website, “I personally was not celebrating a wedding. I don’t know if [Gillum] was in town for a wedding. He did not mention that.”\n",
        "\n",
        "Former Florida governor candidate Andrew Gillum involved in Miami meth overdose 2020-03-13T16:41:12.000Z\n",
        "\n",
        "The man who rented the room, Aldo Mejias, 53, said he went to the room before midnight on March 12. Mejias said that he found Dyson and Gillum “under the influence of an unknown substance.” Mejias said that Gillum had been vomiting into the toilet and that Dyson was unconscious. Mejias performed CPR on Dyson until the paramedics arrived. The incident occurred at the Mondrian South Beach Hotel in Miami Beach, Florida.\n",
        "\n",
        "The drug in question was crystal meth. Those narcotics were impounded. It’s not clear if Gillum or Dyson will be facing any charges. Gillum was allowed to leave the scene and return home by officers.\n",
        "\n",
        "2. Dyson Was Last in Trouble With the Law in August 2019\n",
        "\n",
        "Dyson was arrested in August 2019 and accused of resisting officer without violence to his person reckless driving.\n",
        "\n",
        "On his Instagram page, which was set to private in the fallout from the Gillum scandal, Dyson referred to himself as “still young,” “sometimes professional,” “very taken” and a “grad student.” Dyson says that he studying at nurse\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    , audio equipment, tripods, batteries, etc. Works in all kinds of weather conditions.\n",
        "Statement about Other Duties:\n",
        "The foregoing is not necessarily an exhaustive list of all functions essential to the job for which the employee is responsible, nor an exhaustive list of the minimum requirements and specifications necessary to perform the essential functions, including all responsibilities, skills, duties, requirements, efforts, or working conditions associated with the job. While this is intended to be an accurate reflection of the current job, management reserves the right to revise the job or to require that other or different functions be performed when circumstances change or exigencies require it.\n",
        "Interested parties should submit resume, reel (links) and references to Robby Ferguson, Chief Photographer, KFSM-TV via e-mail (preferred method) to robby.ferguson@kfsm.com or by mail to 4201 North Shiloh Dr. Suite 169, Fayetteville, AR 72703<|endoftext|>J.H. Haag House\n",
        "\n",
        "J.H. Haag House is a historic home located at Garrett, DeKalb County, Indiana.  It was built about 1875, and is a two-story, Italianate-style brick dwelling. It has a cross gable roof and two-story gabled wing.\n",
        "\n",
        "It was added to the National Register of Historic Places in 1983.\n",
        "\n",
        "References\n",
        "\n",
        "Category:Houses on the National Register of Historic Places in Indiana\n",
        "Category:Italianate architecture in Indiana\n",
        "Category:Houses completed in 1875\n",
        "Category:Houses in DeKalb County, Indiana\n",
        "Category:National Register of Historic Places in DeKalb County, Indiana<|endoftext|>B.C. Premier Christy Clark says 2012 has been a challenging year but she's confident of the road ahead, including her party's chances in the coming provincial election.\n",
        "\n",
        "Clark said despite trailing the opposition by more than a dozen points in the polls for most of the year and a number of high-profile resignations in her cabinet, she feels good about what she has accomplished in 2012.\n",
        "\n",
        "\"It's been busy. It's been challenging. Probably in many ways it's been the best year of my life,\" Clark told CBC News Vancouver host Gloria Macarenko during a year-end interview.\n",
        "\n",
        "The premier said a big part of that confidence has come from focusing on her own agenda with her jobs plan, as opposed to continuing what was started by her predecessor.\n",
        "\n",
        "\"We've really been living that plan and so that has been something of my making, of my government's making.\"\n",
        "\n",
        "As for 2013 and the upcoming May provincial election, Clark isn't making any bold predictions but says she is optimistic about her party's chances.\n",
        "\n",
        "\"I'm confident when people sit down and really ask themselves the question about where they want their economy to go, that they'll look at the plan that we've delivered and say, 'You know what? It wasn't perfect, but they got the big things right.'\"\n",
        "\n",
        "Clark was elected as the leader of the B.C. Liberal Party in February 2011. The upcoming May 14 provincial election will be her first as the party's leader.\n",
        "\n",
        "Also on HuffPost:\n",
        "\n",
        "Close\n",
        "\n",
        "���\n",
        "\n",
        "Who Is Canada's Least Popular Premier?\n",
        "\n",
        "of\n",
        "\n",
        "���\n",
        "\n",
        "���\n",
        "\n",
        "Angus Reid Public Opinion surveyed 6,657 Canadian adults from August 21 to August 27, 2012. The margin of error is +/- 1.2 per cent, 19 times out of 20.<|endoftext|>Spatial cognition in children. II. Visuospatial and constructional skills in developmental reading disability.\n",
        "Cognitive models for developmental dyslexia are nowadays centered on the hypothesis of a specific deficit within the phonologic module of the language system. To ascertain whether defects of spatial cognition are associated with developmental reading disability, we investigated a sample of 43 school children (aged 8-9 years) found to be reading impaired during a wide screening survey for developmental dyslexia in the province of Naples, Italy. After one year all children were tested again and only 9/43 still presented reading impairment, while the remaining had achieved a variable range of spontaneous recovery. A detailed analysis was performed on all children to characterize their cognitive performances using on one hand classical conventional tests for constructional praxis, visuospatial cognition, and visuospatial memory and on the other a specific neuropsychological battery for constructional disorders. The results of our study demonstrated that children with long-lasting reading impairment exhibited normal performances on spatial cognition tasks. Moreover, one single child was found with relevant visuospatial deficits pointing to the possible existence of a visuospatial subtype for developmental dyslexia.<|endoftext|>Venice, Day 2\n",
        "\n",
        "We had spend a lot of time people watching and gelato eating in Piazza San Marco, but this morning we decided to head up the Campanile Bell Tower (thankfully there was\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "m-RePlDutkmU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_4_912 = [\n",
        "    r\"\"\"\n",
        "    Conclusion\n",
        "==========\n",
        "\n",
        "Phenformin significantly inhibited both the development and growth of established MCF7 and MDAMB231 tumours without murine toxicity. The potential for phenformin should be considered further as an antineoplastic agent of greater *in vivo* efficacy than metformin for the treatment of breast cancer.\n",
        "\n",
        "We would like to thank the Breast Cancer Research, Scotland, for financial support.\n",
        "\n",
        "This work is published under the standard license to publish agreement. After 12 months the work will become freely available and the license terms will switch to a Creative Commons Attribution-NonCommercial-Share Alike 3.0 Unported License.\n",
        "\n",
        "![Effect of 300 mg kg^−1^ phenformin on human breast MCF7 (**A**) and MDAMB231 (**B**), and 300 mg kg^−1^ metformin on MDAMB231 (**C**) tumour xenografts. For the phenformin experiment, mice were divided into three groups. Controls received no phenformin. Pre-treatment mice were given phenformin (300 mg kg^−1^) in 5% sucrose instead of normal drinking water for 2 weeks prior to injection of MCF7 or MDAMB231 cells. The phenformin group received normal drinking water until tumours reached ���30 mm^3^, after which drinking water was replaced with 5% sucrose containing phenformin (300 mg kg^−1^). Control group also had water replaced with 5% sucrose. For the metformin experiment, mice were divided into two groups. Controls received no metformin and mice with established tumours received metformin (300 mg kg^−1^) in water. MCF7 tumours pre-treated or treated with phenformin had statistically significant inhibition of tumour growth of 88% relative to the control group (*P*\\<0.05). Animals injected with MDAMB231 cells and treated prophylactically with phenformin showed small lumps 6 weeks after inoculation, which remained static for the rest of the experiment. Established MDAMB231 tumours treated with phenformin demonstrated statistically significant inhibition of tumour growth of 60% relative to the control group (*P*\\<0.05). There were no statistically significant differences between control mice and mice treated with metformin.](bjc201256f1){#fig1}\n",
        "\n",
        "![Connective tissue histological analysis of MCF7 and MDAMB231 xenografts treated with phenformin using Van Gieson stain. MCF7 tumours treated with phenformin showed substantial increase of connective tissue, demonstrated as red/pink staining, which replaces epithelial tumour cells (**A** and **B**). No differences were observed in MDAMB231 tumours (**C** and **D**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies, Vista, CA, USA.](bjc201256f2){#fig2}\n",
        "\n",
        "![Phospho-histone H3 immunohistochemistry analysis of MCF7 and MDAMB231 xenografts treated with phenformin. Tumours were harvested and immunohistochemistry analysis performed as described in Materials and methods. No significant differences were observed for phenformin (**B** and **D**) compared with untreated MCF7 and MDAMB231 tumours (**A** and **C**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies.](bjc201256f3){#fig3}\n",
        "\n",
        "![Cleaved PARP analysis of MCF7 and MDAMB231 xenografts treated with phenformin. Tumours were harvested and immunohistochemistry analysis performed as described in Materials and methods. No significant differences were observed for phenformin (**B** and **D**) compared with untreated MCF7 and MDAMB231 tumours (**A** and **C**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies.](bjc201256f4){#fig4}\n",
        "\n",
        "![Ki67 immunohistochemistry analysis of MCF7 and MDAMB231 xenografts treated with phenformin. Tumours were harvested and immunohistochemistry analysis performed as described in Materials and methods. No significant differences were observed for MCF7 tumour treated with phenformin compared with control (**A** and **B**). Similar results were found for MDAMB231 tumours (**C** and **D**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies.](bjc201256f5){#fig5}\n",
        "\n",
        "![AMPK activation in liver and spleen of mice. Liver and spleen of control mice and mice that were pre-treated or treated after xenograft establishment with 300 mg kg^−1^ phenformin were processed and western blots produced as described in Materials and methods. Lanes 1--4 show the results for control mice, lanes 5--9 show the results for mice pre-treated with phenformin and lanes 10--13 show the results for mice treated with phenformin. Phosphorylation of the activation loop of AMPK (T172) was enhanced in liver and spleen from mice pre-treated or treated (lanes 10--13) with phenformin\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    10 days in increasing doses of MMC. Average and s.d. of at least three repeats is shown. (**B**) Survival as measured by MTT assay of short-term primary UM cells after 14 days in 50 n MMC. Cells were extracted from short-term primary UM cultures and tested before passage 5. Survival fraction is the OD value in MMC/the OD value seen in the same cell line grown for 14 days without treatment. Average and s.d. of three repeats are shown, except for two primary cultures where limited passages meant that one repeat was completed, in this case the value obtained from one repeat is shown without error bars.](bjc201156f1){#fig1}\n",
        "\n",
        "![Mitomycin C induces fewer DNA ICLs in UM. (**A**) Average TM in UM (SOM 157d, SOM 196b) and control cell lines untreated, treated with 10 Gy IR or pretreated with 150 *μ* MMC for 1 h before being treated with IR. The average TM was calculated using CometScore software where at least 50 cells were analysed on each of three occasions and the s.d. is shown. Significance was determined using the Student\\'s *t*-test where *n*=3 and *P*\\<0.01 is indicated by ^\\*\\*^. (**B**) MMC-induced percentage decrease in migration calculated for each cell line. The decrease is directly proportional to the amount of ICLs formed. Average and s.d. are shown for at least two repeats. (**C**) Representative COMET assay images for each of the treatments. Images were obtained using the full spectrum function of the CometScore computer software. Cells were originally stained with SYBR Safe DNA gel stain.](bjc201156f2){#fig2}\n",
        "\n",
        "![Mitomycin C induces fewer *γ-*H2AX foci and less cell cycle arrest in UM. (**A**) Quantification of *γ-*H2AX foci formation in UM (SOM 157d, SOM 196b) and control cell lines with and without incubation in 90 n MMC for 1 h. Average and s.d. of three repeats is shown. Significance was calculated using the Student\\'s *t*-test where *n*=3 and *P*\\<0.001 is indicated by ^\\*\\*\\*^. (**B**) Percentage of cells in G2-phase of the cell cycle with or without incubation in 90 n MMC for 24 h as measured by PI staining. Average and s.d. of three repeats is shown. Significance was calculated using the Student\\'s *t*-test where *n*=3 and ^\\*^*P*\\<0.05.](bjc201156f3){#fig3}\n",
        "\n",
        "![Uveal melanoma exhibit reduced expression of CYP450R. (**A**) Western blot for cytochrome p450 reductase (CYP450R), DTD (NQO1) and *β*-ACTIN protein expression in UM (SOM 157d, SOM 196b) and control cell lines. (**B**) Western blot for CYP450R and *β*-ACTIN protein expression in cells extracted from primary UM short-term cultures and tested before passage 5.](bjc201156f4){#fig4}\n",
        "\n",
        "![Complementation of UM cell lines with CYP450R increases sensitivity to MMC. Western blot for cytochrome p450 reductase (CYP450R) and *β*-ACTIN protein expression in (**A**) control (WM793) and (**C**) UM (SOM 196b) cell lines 48 h after transfection with or without a plasmid expressing CYP450R. (**B** and **D**) Clonogenic survival of cell lines shown above after 10 days in increasing doses of MMC. Average and s.d. of at least three repeats is shown.](bjc201156f5){#fig5}\n",
        "\n",
        "![Uveal melanoma is resistant to cisplatin but not to HU. Clonogenic survival of UM (SOM 157d, SOM 196b) and control cell lines after 10 days in increasing doses of (**A**) cisplatin and (**B**) HU. Average and s.d. of at least three repeats is shown.](bjc201156f6){#fig6}\n",
        "\n",
        "###### Clinicopathological details for patients with primary uveal melanoma, and correlation with genetic markers of poor prognosis\n",
        "\n",
        "  **SOM**    **Sex**  **Cell type**          **Tumour location**   **Copy number for chromosomes 3 and 8 respectively, as determined by FISH[a](#t1-fn2){ref-type=\"fn\"}**\n",
        "  --------- --------- ---------------------- --------------------- --------------------------------------------------------------------------------------------------------\n",
        "  SOM520        F     Cilary body            Spindle               2 : 2 Good prognosis\n",
        "  SOM524        F     Ciliary body           Mixed                 2 : 3 Poor prognosis\n",
        "  SOM526        F     Ciliary body           Mixed                 2 :\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "K5oEFD2i1Fa9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdT54W_fwTNw",
        "outputId": "bcc21f6b-6975-4e7d-bf94-b9d5d5d6e2f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForMaskedLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "aug_model_checkpoint = \"distilbert-base-uncased\"\n",
        "aug_model = TFAutoModelForMaskedLM.from_pretrained(aug_model_checkpoint)\n",
        "aug_tokenizer = AutoTokenizer.from_pretrained(aug_model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268,
          "referenced_widgets": [
            "18416c90728642ecabd985dc82c046a6",
            "dd0f57269774474b84cee6dc6df70e38",
            "9c5eb7afc6c643e392f05cd619dff015",
            "9c9c5881187f494f835f82ee99feb9c9",
            "91eb55e784504a5bb6586875669f348f",
            "ddae7becf22b4399b889aab04883b73a",
            "bb78e98011b24ba1923d85ace563bdda",
            "f2bd047c795248439d4898f28aa74224",
            "12266bfb40534f62861c99b78573c5ac",
            "57854357c01d49b4b7ff3ad286f522da",
            "197b389ccde342fea6a8c1aabeb2d387",
            "a7eb184604ce46639ed086963200bac0",
            "0499764b718b4b83acca8a1d86341b70",
            "843f350564d14558b6f685d824b902bc",
            "661101be9aec4e3f9067e669f5119465",
            "6c24d0ff2ba84b5da2fa165ae6bd0de3",
            "485bf4685b644ed4bbd2b6f9d413f351",
            "a00e8a01e2f443ef9faa3f96c2509c55",
            "e87c2dcd58444bb08c01585586a21098",
            "c8135d9ea73f4cfc94dd6b9a4e48317e",
            "6823f175942540108f815673daa16610",
            "042809b2c68542f0aeafc6d96a940373",
            "e267a41dd6d1487c89a1675a4a88f1f5",
            "6859e05b43e2416e9aa87e5e8442c123",
            "4ac890beec8b4e32b904736409a6cde3",
            "9c93ebeb236648e888392992dc58e360",
            "2c92625698c642d69529399207992f18",
            "0ce3f445239440c790980fe4474c978b",
            "6ada85319d214ea881264d61b6e1d5e2",
            "255f1a45502347398c5f8a04394553fb",
            "7d41ea3ac61d47c39f504ac68b1a9e36",
            "15dd50213ad6484591ae5820237e0ce4",
            "63302a05d0e14326a403bc7e33f3a3cb",
            "abd81981e0994edaa0ab2f020874f291",
            "fa43b924aadf4b2ab286009128576ed2",
            "013683c0affb40218051c15dbfdab802",
            "955801bab27f45f786ff3abf2f93d7c2",
            "ad56e7a301604c2e982ca90afb77ab13",
            "eba5224d2e404fdba935b40a1f637651",
            "2ce6b9f810d14e69a5a4b6408568a15f",
            "7542e68a56554a0a95b72c91dc8f9f4a",
            "ff27eb0ddabb49e6a6dee39b60bad902",
            "08294cfa823141e49ead637d87297a7a",
            "911b15aa72f94208ba0bb6346cf18674",
            "90ada44a797d4195a8366988fde5c35a",
            "5e2d5bbc74354063ae48b15d0dac5046",
            "5a2cac4cf61540bd8b4d71e332b40602",
            "dfd4249c40d243818d9d45eb7722f190",
            "d057513e4b9e41f2903a80b8f4771fdd",
            "6ff57901a6e2488b8634448e87636600",
            "6815edc9275f45139a02dbb1a276185d",
            "cb5c096f03ab47c5acb3a3846d26caff",
            "f61bb95981944f948a56c62a2266a2cb",
            "3644c08ccee242839b69b28749836757",
            "57e43d251dfb4e7983997c886cefd7c3"
          ]
        },
        "id": "WthFIEKnpf6B",
        "outputId": "19aafddb-960b-4af8-fc6f-a34fe1955d30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18416c90728642ecabd985dc82c046a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7eb184604ce46639ed086963200bac0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForMaskedLM.\n",
            "\n",
            "All the weights of TFDistilBertForMaskedLM were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e267a41dd6d1487c89a1675a4a88f1f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abd81981e0994edaa0ab2f020874f291"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90ada44a797d4195a8366988fde5c35a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import re\n",
        "\n",
        "class ContextualAugmenter:\n",
        "  def __init__(self, model, tokenizer, neuron_model):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.neuron_model = neuron_model\n",
        "    self.stops = set(stopwords.words('english'))\n",
        "    self.punctuation_set = set(punctuation)\n",
        "    self.to_strip = \" \" + punctuation\n",
        "    # self.word_tokenizer = re.compile(\"[ \\[\\]\\(\\)]\")\n",
        "    self.word_tokenizer = re.compile(r\"\\b\")\n",
        "\n",
        "\n",
        "  def augment(self, text, n=5):\n",
        "    tokens = self.word_tokenizer.split(text)\n",
        "    # tokens = text.split(\" \")\n",
        "    # print(tokens)\n",
        "    masked_tokens = copy.deepcopy(tokens)\n",
        "    all_new_texts = []\n",
        "    all_positions = []\n",
        "\n",
        "    neuron_tokens = self.neuron_model.to_str_tokens(text)\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "      if token in {\"\", \" \"} or token.strip(self.to_strip).lower() in self.stops:\n",
        "        continue\n",
        "      masked_tokens[i] = \"[MASK]\"\n",
        "      before = tokens[:i]\n",
        "      before_text = \"\".join(before)\n",
        "      position = len(before_text)\n",
        "      # print(masked_tokens)\n",
        "      masked_text = \"\".join(masked_tokens)\n",
        "      inputs = self.tokenizer(masked_text, return_tensors=\"np\")\n",
        "      token_logits = self.model(**inputs).logits\n",
        "      # Find the location of [MASK] and extract its logits\n",
        "      mask_token_index = np.argwhere(inputs[\"input_ids\"] == self.tokenizer.mask_token_id)[0, 1]\n",
        "      mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "      # Pick the [MASK] candidates with the highest logits\n",
        "      # We negate the array before argsort to get the largest, not the smallest, logits\n",
        "      top_tokens = np.argsort(-mask_token_logits).tolist()\n",
        "\n",
        "      new_texts = []\n",
        "      positions = []\n",
        "      for j, top_token in enumerate(top_tokens):\n",
        "        candidate_token = self.tokenizer.decode([top_token])\n",
        "        normalised_candidate = candidate_token.strip(self.to_strip).lower() if candidate_token not in self.punctuation_set else candidate_token\n",
        "        normalised_token = token.strip(self.to_strip).lower() if token not in self.punctuation_set else token\n",
        "        # print(\"token, top_token\", [normalised_token], [normalised_candidate])\n",
        "\n",
        "        if normalised_candidate == normalised_token:\n",
        "          continue\n",
        "        new_text = masked_text.replace(self.tokenizer.mask_token, candidate_token)\n",
        "        new_texts.append(new_text)\n",
        "        positions.append(position)\n",
        "        # print(len(new_texts), j, n)\n",
        "        if len(new_texts) >= n or j >= n + 5:\n",
        "          break\n",
        "\n",
        "      all_new_texts.extend(new_texts)\n",
        "      all_positions.extend(positions)\n",
        "      masked_tokens[i] = token\n",
        "\n",
        "    return all_new_texts, all_positions"
      ],
      "metadata": {
        "id": "OyHgzc3bmGWJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contextual_aug = ContextualAugmenter(aug_model, aug_tokenizer, model)"
      ],
      "metadata": {
        "id": "3mtGC3yeqG_8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contextual_aug.augment(\"This is a test.\", n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak8NfDHzpxhr",
        "outputId": "c2d4c15e-22cb-4988-8425-7cdcbd061f80"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['This is a list.',\n",
              "  'This is a timeline.',\n",
              "  'This is a test:',\n",
              "  'This is a test!'],\n",
              " [10, 10, 14, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augs = [\n",
        "    contextual_aug\n",
        "]"
      ],
      "metadata": {
        "id": "qJATNug8WlzM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from collections import defaultdict\n",
        "from string import punctuation\n",
        "import re\n",
        "import copy\n",
        "\n",
        "splitter = re.compile(\"[\\.!\\\\n]\")\n",
        "\n",
        "def sentence_tokenizer(str_tokens):\n",
        "  sentences = []\n",
        "  sentence = []\n",
        "  sentence_to_token_indices = defaultdict(list)\n",
        "  token_to_sentence_indices = {}\n",
        "\n",
        "  for i, str_token in enumerate(str_tokens):\n",
        "    sentence.append(str_token)\n",
        "    sentence_to_token_indices[len(sentences)].append(i)\n",
        "    token_to_sentence_indices[i] = len(sentences)\n",
        "    # if splitter.search(str_token) is not None or i + 1 == len(str_tokens):\n",
        "    if str_token in {\".\", \"\\n\"} or i + 1 == len(str_tokens):\n",
        "      sentences.append(sentence)\n",
        "      sentence = []\n",
        "\n",
        "  return sentences, sentence_to_token_indices, token_to_sentence_indices\n",
        "\n",
        "\n",
        "def prune(model, layer, neuron, prompt, max_length=1024, proportion_threshold=-0.5, window=4):\n",
        "  prepend_bos = True\n",
        "  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n",
        "  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n",
        "\n",
        "  # print(tokens)\n",
        "  # print(str_tokens)\n",
        "  # print(tokens.shape)\n",
        "\n",
        "  if len(tokens[0]) > max_length:\n",
        "    tokens = tokens[0, :max_length].unsqueeze(0)\n",
        "\n",
        "  # print(tokens.shape)\n",
        "  # print(prompt)\n",
        "  # print(\"tokens\", tokens)\n",
        "  # print(\"str_tokens\", str_tokens)\n",
        "\n",
        "  logits, cache = model.run_with_cache(tokens)\n",
        "  activations = cache[layer][0, :, neuron]\n",
        "\n",
        "  initial_max = torch.max(activations).cpu().item()\n",
        "  initial_argmax = torch.argmax(activations).cpu().item()\n",
        "\n",
        "  # print(\"initial_max\", initial_max)\n",
        "  # print(\"initial_argmax\", initial_argmax)\n",
        "\n",
        "  sentences, sentence_to_token_indices, token_to_sentence_indices = sentence_tokenizer(str_tokens)\n",
        "\n",
        "  max_sentence_index = token_to_sentence_indices[initial_argmax]\n",
        "  sentence = sentences[max_sentence_index]\n",
        "\n",
        "  offset = sentence_to_token_indices[max_sentence_index][0]\n",
        "  max_token_index = initial_argmax - offset\n",
        "\n",
        "  shortest_prompt = sentence\n",
        "  shortest_successful_prompt = None\n",
        "  for i, index in enumerate([len(sentence) - min((max_token_index + window), len(sentence)), max(0, max_token_index - window)]):\n",
        "    sentence = shortest_prompt\n",
        "    for j in range(index):\n",
        "      if i == 0:\n",
        "        truncated_prompt = shortest_prompt[:-1]\n",
        "      else:\n",
        "        truncated_prompt = shortest_prompt[1:]\n",
        "\n",
        "      # print(\"shortest_prompt\", shortest_prompt)\n",
        "      # print(j)\n",
        "      # print(\"truncated_prompt\", truncated_prompt)\n",
        "\n",
        "      joined = \"\".join(truncated_prompt)\n",
        "      # joined = \"\".join(sentence)\n",
        "\n",
        "      # print(\"\\n\")\n",
        "      # print([joined])\n",
        "      # print(model.to_str_tokens(joined, prepend_bos=prepend_bos))\n",
        "\n",
        "      sentence_tokens = model.to_tokens(joined, prepend_bos=prepend_bos)\n",
        "      logits, cache = model.run_with_cache(sentence_tokens)\n",
        "      activations = cache[layer][0, :, neuron]\n",
        "      sentence_argmax = torch.argmax(activations).cpu().item() + offset\n",
        "      if prepend_bos:\n",
        "        sentence_argmax -= 1\n",
        "      if i == 1:\n",
        "        sentence_argmax += j + 1\n",
        "      sentence_max = torch.max(activations).cpu().item()\n",
        "\n",
        "      # print(sentence_max)\n",
        "      # print(sentence_argmax)\n",
        "      shortest_prompt = truncated_prompt\n",
        "\n",
        "      if sentence_argmax == initial_argmax and (sentence_max - initial_max) / initial_max > proportion_threshold:\n",
        "        shortest_successful_prompt = copy.deepcopy(truncated_prompt)\n",
        "\n",
        "  return \"\".join(shortest_successful_prompt) if shortest_successful_prompt is not None else None\n",
        "\n",
        "def augment(model, layer, index, prompt, augs, max_length=1024, inclusion_threshold=-0.5, exclusion_threshold=-0.8, n=1):\n",
        "  prepend_bos = True\n",
        "  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n",
        "  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n",
        "\n",
        "  if len(tokens[0]) > max_length:\n",
        "    tokens = tokens[0, :max_length].unsqueeze(0)\n",
        "\n",
        "  # print(tokens)\n",
        "  # print(str_tokens)\n",
        "\n",
        "  logits, cache = model.run_with_cache(tokens)\n",
        "  activations = cache[layer][0, :, index]\n",
        "\n",
        "  initial_max = torch.max(activations).cpu().item()\n",
        "  initial_argmax = torch.argmax(activations).cpu().item()\n",
        "  max_char_position = len(\"\".join(str_tokens[int(prepend_bos):initial_argmax]))\n",
        "  # print(\"initial_max\", initial_max)\n",
        "  # print(\"initial_argmax\", initial_argmax)\n",
        "\n",
        "  positive_prompts = [(prompt, initial_max)]\n",
        "  negative_prompts = []\n",
        "  # print(\"starting prompt\", prompt)\n",
        "  for aug in augs:\n",
        "    aug_prompts, aug_positions = aug.augment(prompt, n=n)\n",
        "    aug_tokens = model.to_tokens(aug_prompts, prepend_bos=prepend_bos)\n",
        "    aug_logits, aug_cache = model.run_with_cache(aug_tokens)\n",
        "    all_aug_activations = aug_cache[layer][:, :, index]\n",
        "\n",
        "    for aug_prompt, char_position, aug_activations in zip(aug_prompts, aug_positions, all_aug_activations):\n",
        "      aug_max = torch.max(aug_activations).cpu().item()\n",
        "      aug_argmax = torch.argmax(aug_activations).cpu().item()\n",
        "      # print(aug_max)\n",
        "      # print(\"actual aug_argmax\", aug_argmax)\n",
        "\n",
        "      # print(str_tokens)\n",
        "      # print(model.to_str_tokens(aug_prompt, prepend_bos=prepend_bos))\n",
        "      # print(char_position, max_char_position, aug_argmax)\n",
        "      if char_position < max_char_position:\n",
        "        new_str_tokens = model.to_str_tokens(aug_prompt, prepend_bos=prepend_bos)\n",
        "        aug_argmax += len(new_str_tokens) - len(str_tokens)\n",
        "        # print(\"len(new_str_tokens)\", len(new_str_tokens))\n",
        "        # print(\"len(str_tokens)\", len(str_tokens))\n",
        "        # print(\"adjusted aug_argmax\", aug_argmax)\n",
        "\n",
        "      proportion_drop = (aug_max - initial_max) / initial_max\n",
        "\n",
        "      if proportion_drop > inclusion_threshold:\n",
        "        positive_prompts.append((aug_prompt, aug_max, proportion_drop))\n",
        "      elif proportion_drop < exclusion_threshold:\n",
        "        negative_prompts.append((aug_prompt, aug_max, proportion_drop))\n",
        "\n",
        "  return positive_prompts, negative_prompts"
      ],
      "metadata": {
        "id": "4lVq8zY1ZNNd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_3_1:\n",
        "  pruned_prompt = prune(model, \"blocks.3.mlp.hook_mid\", 1, snippet, window=3)\n",
        "  print([pruned_prompt])\n",
        "  if pruned_prompt is None:\n",
        "    continue\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.3.mlp.hook_mid\", 1, pruned_prompt, augs, n=4)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWd4qY6VM9kk",
        "outputId": "5e018a3e-abd4-4151-abff-529ab9f3aa1c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" The thought didn't even cross my mind\"]\n",
            "positive [(\" The thought didn't even cross my mind\", 0.5641515254974365), (\" The words didn't even cross my mind\", 0.2852242887020111, -0.4944190065771485), (\" The question didn't even cross my mind\", 0.3628471791744232, -0.3568267339975987), (\" The idea didn't even cross my mind\", 0.40326568484306335, -0.2851819650979641), (' The thought didn’t even cross my mind', 0.5588911771774292, -0.009324353621784591), (' The thought didn`t even cross my mind', 0.44737204909324646, -0.20700019609309858), (' The thought didn=t even cross my mind', 0.3544992208480835, -0.37162410305368515), (' The thought didn′t even cross my mind', 0.37674030661582947, -0.332200145548412), (\" The thought didn't immediately cross my mind\", 0.4713054895401001, -0.16457641566327433), (\" The thought didn't completely cross my mind\", 0.48807698488235474, -0.13484770877470129), (\" The thought didn't quite cross my mind\", 0.5182166695594788, -0.08142290477271162), (\" The thought didn't exactly cross my mind\", 0.4073655307292938, -0.27791468724629925), (\" The thought didn't even cross my .\", 0.5641502141952515, -2.3243794012652232e-06), (\" The thought didn't even cross my heart\", 0.5641502141952515, -2.3243794012652232e-06), (\" The thought didn't even cross my skin\", 0.5641502141952515, -2.3243794012652232e-06), (\" The thought didn't even cross my stomach\", 0.5641502141952515, -2.3243794012652232e-06)]\n",
            "negative [(\" The thought didn't even touch my mind\", 0.08117489516735077, -0.8561115383038708), (\" The thought didn't even occupy my mind\", 0.10757308453321457, -0.8093188094486445)]\n",
            "\n",
            "\n",
            "[' a thought that would cross my mind']\n",
            "positive [(' a thought that would cross my mind', 0.320724219083786), (' a question that would cross my mind', 0.1747054159641266, -0.45527838071222637), (' a dream that would cross my mind', 0.2059972882270813, -0.35771209041975544), (' a feeling that would cross my mind', 0.23293401300907135, -0.2737249039860639), (' a thought that might cross my mind', 0.28260600566864014, -0.11885043644049803), (' a thought that could cross my mind', 0.21652525663375854, -0.32488647956706546), (' a thought that will cross my mind', 0.290579229593277, -0.09399037458606753), (' a thought that can cross my mind', 0.18536068499088287, -0.42205585371630683), (' a thought that would cross my heart', 0.320723295211792, -2.880580695333153e-06), (' a thought that would cross my .', 0.320723295211792, -2.880580695333153e-06), (' a thought that would cross my soul', 0.320723295211792, -2.880580695333153e-06), (' a thought that would cross my veins', 0.320723295211792, -2.880580695333153e-06)]\n",
            "negative [(' a thought that would haunt my mind', 0.036510907113552094, -0.8861610538242078), (' a thought that would fill my mind', 0.019201764836907387, -0.9401299817900839), (' a thought that would occupy my mind', 0.06379415839910507, -0.8010934173248716)]\n",
            "\n",
            "\n",
            "[\" the thought of playing further probably didn't cross Hungry\"]\n",
            "positive [(\" the thought of playing further probably didn't cross Hungry\", 0.49252697825431824), (\" the thought of going further probably didn't cross Hungry\", 0.5491651892662048, 0.11499514445407949), (\" the thought of moving further probably didn't cross Hungry\", 0.4141473174095154, -0.15913780220244345), (\" the thought of getting further probably didn't cross Hungry\", 0.4121725559234619, -0.16314725056414067), (\" the thought of it further probably didn't cross Hungry\", 0.4501343071460724, -0.08607177470460557), (\" the thought of playing further out didn't cross Hungry\", 0.4554455578327179, -0.07528810006109596), (\" the thought of playing further games didn't cross Hungry\", 0.33870983123779297, -0.3123019729024898), (\" the thought of playing further along didn't cross Hungry\", 0.32974594831466675, -0.33050175346049543), (' the thought of playing further probably didn’t cross Hungry', 0.47831490635871887, -0.028855418125463387), (' the thought of playing further probably didn`t cross Hungry', 0.38208556175231934, -0.22423424782423196), (' the thought of playing further probably didn\"t cross Hungry', 0.3166884183883667, -0.35701305233914843), (\" the thought of playing further probably didn't cross .\", 0.4925276041030884, 1.270689318095469e-06), (\" the thought of playing further probably didn't cross ;\", 0.4925276041030884, 1.270689318095469e-06), (\" the thought of playing further probably didn't cross :\", 0.4925276041030884, 1.270689318095469e-06), (\" the thought of playing further probably didn't cross ?\", 0.4925276041030884, 1.270689318095469e-06)]\n",
            "negative [(\" the thought of playing further probably didn't seem Hungry\", 0.015294218435883522, -0.9689474503709596), (\" the thought of playing further probably didn't sound Hungry\", 0.04927123710513115, -0.8999623588544022), (\" the thought of playing further probably didn't help Hungry\", 0.03668774291872978, -0.9255112013381206), (\" the thought of playing further probably didn't hurt Hungry\", 0.04214758053421974, -0.9144258438723398)]\n",
            "\n",
            "\n",
            "[' The thought did briefly cross my mind']\n",
            "positive [(' The thought did briefly cross my mind', 0.35407841205596924), (' The thought did not cross my mind', 0.4487135112285614, 0.2672715871693222), (' The thought did indeed cross my mind', 0.31471899151802063, -0.11116018146773393), (' The thought did eventually cross my mind', 0.35643821954727173, 0.006664646617680479), (' The thought did finally cross my mind', 0.43078893423080444, 0.21664840205708322), (' The thought did briefly cross my .', 0.354079931974411, 4.29260409564932e-06), (' The thought did briefly cross my heart', 0.354079931974411, 4.29260409564932e-06), (' The thought did briefly cross my skin', 0.354079931974411, 4.29260409564932e-06), (' The thought did briefly cross my eyes', 0.354079931974411, 4.29260409564932e-06)]\n",
            "negative [(' The memory did briefly cross my mind', 0.06387177109718323, -0.8196112247388666), (' The image did briefly cross my mind', 0.06579779833555222, -0.8141716747047782), (' The thought did briefly occupy my mind', 0.06400415301322937, -0.8192373473390063), (' The thought did briefly touch my mind', 0.06507359445095062, -0.8162169953454704), (' The thought did briefly haunt my mind', 0.040349580347537994, -0.886043376343543)]\n",
            "\n",
            "\n",
            "[' the thought did briefly cross my mind']\n",
            "positive [(' the thought did briefly cross my mind', 0.3433554470539093), (' the words did briefly cross my mind', 0.18898463249206543, -0.4495947738309989), (' the thought did not cross my mind', 0.4154026210308075, 0.20983262270945205), (' the thought did indeed cross my mind', 0.29423192143440247, -0.143069015042578), (' the thought did eventually cross my mind', 0.3496297001838684, 0.018273346713424947), (' the thought did finally cross my mind', 0.4276284873485565, 0.2454396486723443), (' the thought did briefly cross my .', 0.3433549106121063, -1.5623512240197265e-06), (' the thought did briefly cross my heart', 0.3433549106121063, -1.5623512240197265e-06), (' the thought did briefly cross my skin', 0.3433549106121063, -1.5623512240197265e-06), (' the thought did briefly cross my eyes', 0.3433549106121063, -1.5623512240197265e-06)]\n",
            "negative [(' the memory did briefly cross my mind', 0.05730023235082626, -0.8331168681246239), (' the image did briefly cross my mind', 0.056559525430202484, -0.8352741279758342), (' the thought did briefly occupy my mind', 0.06129879131913185, -0.8214713299436677), (' the thought did briefly touch my mind', 0.06607715040445328, -0.8075546755660507), (' the thought did briefly haunt my mind', 0.038574643433094025, -0.8876539057001256)]\n",
            "\n",
            "\n",
            "[' to see the bill finally pass.']\n",
            "positive [(' to see the bill finally pass.', 0.21282054483890533), (' to let the bill finally pass.', 0.1821446418762207, -0.14413976331986547), (' to make the bill finally pass.', 0.11506329476833344, -0.4593412264054174), (' to help the bill finally pass.', 0.13688915967941284, -0.35678597297534786), (' to watch the bill finally pass.', 0.15941859781742096, -0.25092477355467263), (' to see the bill now pass.', 0.2706461548805237, 0.27171065690762836), (' to see the bill would pass.', 0.1940775215625763, -0.08806961419310615), (' to see the bill eventually pass.', 0.25635215640068054, 0.20454609584204614), (' to see the bill finally passed.', 0.13392673432826996, -0.37070580084434096), (' to see the bill finally passes.', 0.12354642152786255, -0.4194807572672032), (' to see the bill finally passing.', 0.13641861081123352, -0.3589969853968014), (' to see the bill finally pass:', 0.21282044053077698, -4.901224570959054e-07), (' to see the bill finally pass;', 0.21282044053077698, -4.901224570959054e-07), (' to see the bill finally pass!', 0.21282044053077698, -4.901224570959054e-07), (' to see the bill finally pass?', 0.21282044053077698, -4.901224570959054e-07)]\n",
            "negative [(' to see the day finally pass.', 0.013326006010174751, -0.9373838366015749), (' to see the clouds finally pass.', 0.004157498013228178, -0.9804647713106119), (' to see the night finally pass.', 0.014814150519669056, -0.9303913514041483), (' to see the days finally pass.', 0.010212196037173271, -0.9520149896951753), (' to see the bill finally enacted.', 0.021258024498820305, -0.9001129119610535)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_3_2:\n",
        "  pruned_prompt = prune(model, \"blocks.3.mlp.hook_mid\", 2, snippet, window=3)\n",
        "  print([pruned_prompt])\n",
        "  print(\"\\n\")\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.3.mlp.hook_mid\", 2, pruned_prompt, augs, n=4)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN_H8t7QPBt2",
        "outputId": "8a24841b-58c5-4b47-f6d8-139714069b04"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' am not a native English speaker']\n",
            "\n",
            "\n",
            "positive [(' am not a native English speaker', 0.2899046838283539), (' am not a native american speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native hawaiian speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native indian speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native language speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English ?', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English .', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English language', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English ;', 0.2899050712585449, 1.3364054209949497e-06)]\n",
            "negative [(' am not a fluent English speaker', 0.019566616043448448, -0.9325067267452863), (' am not a proper English speaker', 0.023074381053447723, -0.920407008438989), (' am not a true English speaker', 0.021251268684864044, -0.9266956697483147), (' am not a good English speaker', 0.0231549721211195, -0.9201290168363438)]\n",
            "\n",
            "\n",
            "[' am not a native English speaker']\n",
            "\n",
            "\n",
            "positive [(' am not a native English speaker', 0.2899046838283539), (' am not a native american speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native hawaiian speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native indian speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native language speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English ?', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English .', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English language', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English ;', 0.2899050712585449, 1.3364054209949497e-06)]\n",
            "negative [(' am not a fluent English speaker', 0.019566616043448448, -0.9325067267452863), (' am not a proper English speaker', 0.023074381053447723, -0.920407008438989), (' am not a true English speaker', 0.021251268684864044, -0.9266956697483147), (' am not a good English speaker', 0.0231549721211195, -0.9201290168363438)]\n",
            "\n",
            "\n",
            "[' am not a native English speaker']\n",
            "\n",
            "\n",
            "positive [(' am not a native English speaker', 0.2899046838283539), (' am not a native american speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native hawaiian speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native indian speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native language speaker', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English ?', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English .', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English language', 0.2899050712585449, 1.3364054209949497e-06), (' am not a native English ;', 0.2899050712585449, 1.3364054209949497e-06)]\n",
            "negative [(' am not a fluent English speaker', 0.019566616043448448, -0.9325067267452863), (' am not a proper English speaker', 0.023074381053447723, -0.920407008438989), (' am not a true English speaker', 0.021251268684864044, -0.9266956697483147), (' am not a good English speaker', 0.0231549721211195, -0.9201290168363438)]\n",
            "\n",
            "\n",
            "[' am not a native speaker,']\n",
            "\n",
            "\n",
            "positive [(' am not a native speaker,', 0.2899046838283539), (' am not a native american,', 0.28990495204925537, 9.252037529965037e-07), (' am not a native tribe,', 0.28990495204925537, 9.252037529965037e-07), (' am not a native tongue,', 0.28990495204925537, 9.252037529965037e-07), (' am not a native language,', 0.28990495204925537, 9.252037529965037e-07), (' am not a native speaker?', 0.28990495204925537, 9.252037529965037e-07), (' am not a native speaker.', 0.28990495204925537, 9.252037529965037e-07), (' am not a native speaker…', 0.28990495204925537, 9.252037529965037e-07), (' am not a native speaker!', 0.28990495204925537, 9.252037529965037e-07)]\n",
            "negative [(' am not a good speaker,', 0.0008040692773647606, -0.9972264357141576), (' am not a passive speaker,', 0.0029820632189512253, -0.9897136424994194), (' am not a true speaker,', 0.0022088869009166956, -0.9923806443147206), (' am not a wise speaker,', 0.001080492278560996, -0.996272939559677)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_3_912:\n",
        "  pruned_prompt = prune(model, \"blocks.3.mlp.hook_mid\", 912, snippet, window=2, proportion_threshold=-0.6)\n",
        "  print([pruned_prompt])\n",
        "  if pruned_prompt is None:\n",
        "    continue\n",
        "  print(\"\\n\")\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.3.mlp.hook_mid\", 912, pruned_prompt, augs, n=2, inclusion_threshold=-0.4, exclusion_threshold=-0.7)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg1fEczXuH3u",
        "outputId": "a94e90e3-69d7-4a5b-c591-d9a20301dda9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' was put on the IUCN Red List under']\n",
            "\n",
            "\n",
            "positive [(' was put on the IUCN Red List under', 0.7422022223472595), (' was placed on the IUCN Red List under', 0.6806859970092773, -0.08288337529283243), (' was listed on the IUCN Red List under', 0.709409773349762, -0.04418263380267099)]\n",
            "negative [(' was put on the iaaf Red List under', 0.21633531153202057, -0.7085224147566589), (' was put on the nhl Red List under', 0.20250342786312103, -0.72715868833875), (' was put on the IUCN threatened List under', 0.1870194971561432, -0.7480208337766995), (' was put on the IUCN Red ##lists under', 0.04687357693910599, -0.9368452754144747)]\n",
            "\n",
            "\n",
            "[' It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [(' It was added to the National Register of', 0.5029285550117493), (' It was add to the National Register of', 0.4071325361728668, -0.19047639646677944), (' It was named to the National Register of', 0.33700183033943176, -0.32992106536571814), (' It was added to the National list of', 0.44478359818458557, -0.11561275701636256)]\n",
            "negative [(' It was added to the state Register of', 0.12866081297397614, -0.7441767589216118), (' It was added to the National inventory of', 0.07945741713047028, -0.8420105274622675)]\n",
            "\n",
            "\n",
            "[' It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [(' It was added to the National Register of', 0.5029285550117493), (' It was add to the National Register of', 0.4071325361728668, -0.19047639646677944), (' It was named to the National Register of', 0.33700183033943176, -0.32992106536571814), (' It was added to the National list of', 0.44478359818458557, -0.11561275701636256)]\n",
            "negative [(' It was added to the state Register of', 0.12866081297397614, -0.7441767589216118), (' It was added to the National inventory of', 0.07945741713047028, -0.8420105274622675)]\n",
            "\n",
            "\n",
            "[' It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [(' It was added to the National Register of', 0.5029285550117493), (' It was add to the National Register of', 0.4071325361728668, -0.19047639646677944), (' It was named to the National Register of', 0.33700183033943176, -0.32992106536571814), (' It was added to the National list of', 0.44478359818458557, -0.11561275701636256)]\n",
            "negative [(' It was added to the state Register of', 0.12866081297397614, -0.7441767589216118), (' It was added to the National inventory of', 0.07945741713047028, -0.8420105274622675)]\n",
            "\n",
            "\n",
            "['It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [('It was added to the National Register of', 0.5010610818862915), ('It was add to the National Register of', 0.3706061542034149, -0.2603573344626303), ('It was named to the National Register of', 0.3329409956932068, -0.33552812675089605), ('It was added to the National list of', 0.3760473132133484, -0.2494980615982328)]\n",
            "negative [('It was added to the state Register of', 0.11510279774665833, -0.7702819039280739), ('It was added to the National inventory of', 0.067685566842556, -0.8649155376670897)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_4_912:\n",
        "  pruned_prompt = prune(model, \"blocks.4.mlp.hook_mid\", 912, snippet, window=5, proportion_threshold=-0.6)\n",
        "  print([pruned_prompt])\n",
        "  if pruned_prompt is None:\n",
        "    continue\n",
        "  print(\"\\n\")\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.4.mlp.hook_mid\", 912, pruned_prompt, augs, n=2, inclusion_threshold=-0.4, exclusion_threshold=-0.7)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9265JwgS1T2t",
        "outputId": "70b2547b-a7f6-490e-cc86-0acaaaf15bc3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.](bjc201256f1){#fig1']\n",
            "\n",
            "\n",
            "positive [('.](bjc201256f1){#fig1', 2.9047980308532715), ('.](bjc201256f1)fig1', 2.904805898666382, 2.70855771271658e-06), ('.](bjc201256f1]fig1', 2.904805898666382, 2.70855771271658e-06), ('.](bjc201256f1){#;', 2.904805898666382, 2.70855771271658e-06), ('.](bjc201256f1){#}', 2.904805898666382, 2.70855771271658e-06)]\n",
            "negative [('(bjc201256f1){#fig1', 0.03937962278723717, -0.986443249283094), ('#bjc201256f1){#fig1', 0.04763230308890343, -0.983602197955597), ('.](\\\\){#fig1', 0.0253664031624794, -0.9912674124352019), ('.](thumb){#fig1', 0.02478465437889099, -0.9914676841158521)]\n",
            "\n",
            "\n",
            "['.](bjc201156f1){#fig1']\n",
            "\n",
            "\n",
            "positive [('.](bjc201156f1){#fig1', 2.9739017486572266), ('.](bjc201156f1)fig1', 2.973905324935913, 1.202554417992523e-06), ('.](bjc201156f1]fig1', 2.973905324935913, 1.202554417992523e-06), ('.](bjc201156f1){#;', 2.973905324935913, 1.202554417992523e-06), ('.](bjc201156f1){#}', 2.973905324935913, 1.202554417992523e-06)]\n",
            "negative [('(bjc201156f1){#fig1', 0.04686380922794342, -0.9842416417256881), ('#bjc201156f1){#fig1', 0.046479493379592896, -0.9843708712298316), ('.](\\\\){#fig1', 0.0253664031624794, -0.9914703291142914), ('.](thumb){#fig1', 0.02478465437889099, -0.9916659471382733)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tkzvbkHTDR77"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our extension of building neuron pairs to observe and evaluate synergy between multiple neuron pairs\n"
      ],
      "metadata": {
        "id": "tinDThZv8_td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Multi-Neuron Analysis with Automatic Pair Discovery and Joint Interpretability\n",
        "-----------------------------------------------------------------------------\n",
        "\n",
        "1) We pick a layer of interest (e.g., \"blocks.3.mlp.hook_mid\").\n",
        "2) We gather random snippets (or real data) and measure each neuron's activation.\n",
        "3) Compute correlation between neuron pairs, pick top correlated pairs.\n",
        "4) For each pair, run:\n",
        "   - Joint pruning to get a minimal activating example (MAE).\n",
        "   - Local search expansions (DistilBERT or GPT).\n",
        "   - Label expansions by how they affect both neurons' activation.\n",
        "\n",
        "Outputs are printed in a format similar to the single-neuron approach, so you\n",
        "can easily see the MAE, the pair, positive vs. negative expansions, etc.\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "from transformer_lens import EasyTransformer\n",
        "from transformer_lens.utils import to_numpy\n",
        "\n",
        "from transformers import (AutoModelForMaskedLM, AutoTokenizer,\n",
        "                          AutoModelForCausalLM)\n",
        "\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "###############################################################################\n",
        "#                               CONFIG                                        #\n",
        "###############################################################################\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Choose your model\n",
        "MODEL_NAME = \"solu-8l-old\"\n",
        "model = EasyTransformer.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "# DistilBERT for local search expansions\n",
        "AUG_MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
        "aug_tokenizer = AutoTokenizer.from_pretrained(AUG_MODEL_CHECKPOINT)\n",
        "aug_model = AutoModelForMaskedLM.from_pretrained(AUG_MODEL_CHECKPOINT).to(device)\n",
        "aug_model.eval()\n",
        "\n",
        "# GPT for local search expansions\n",
        "GEN_MODEL_NAME = \"gpt2\"\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(GEN_MODEL_NAME).to(device)\n",
        "gen_model.eval()\n",
        "\n",
        "# The layer of interest (feel free to change)\n",
        "LAYER_OF_INTEREST = \"blocks.3.mlp.hook_mid\"\n",
        "# Maximum number of neurons in that layer\n",
        "# If you know the dimension, you can set it. We'll fetch it dynamically after the first pass.\n",
        "\n",
        "# We also define some random text samples to scan for correlation:\n",
        "RANDOM_SNIPPETS = [\n",
        "    \"It was added to the National Register of Historic Places.\",\n",
        "    \"The thought didn't even cross my mind as I was driving home.\",\n",
        "    \"He was put on the IUCN Red List under threatened species.\",\n",
        "    \"I am not a native English speaker, but I'm learning quickly.\",\n",
        "    \"The project was finally finished after months of effort.\",\n",
        "    \"We appreciate your feedback on our performance results.\",\n",
        "    # add more or load from a file if you prefer\n",
        "]\n",
        "\n",
        "###############################################################################\n",
        "#                    STEP 1: FIND CO-ACTIVATED NEURON PAIRS                   #\n",
        "###############################################################################\n",
        "\n",
        "def measure_activations_for_layer(model, layer_name, text):\n",
        "    \"\"\"\n",
        "    Returns a 1D array of shape [num_neurons_in_layer], each neuron’s max activation\n",
        "    on the provided text. We measure the max over the sequence dimension.\n",
        "    \"\"\"\n",
        "    tokens = model.to_tokens(text, prepend_bos=True)\n",
        "    _, cache = model.run_with_cache(tokens.to(device))\n",
        "    layer_act = cache[layer_name][0]  # shape [seq_len, d_mlp]\n",
        "    # we want the max over seq_len for each neuron\n",
        "    max_per_neuron = layer_act.max(dim=0).values.cpu().numpy()  # shape [d_mlp]\n",
        "    return max_per_neuron\n",
        "\n",
        "def find_top_pairs_coactivation(model, layer_name, samples, top_k=3):\n",
        "    \"\"\"\n",
        "    1) For each sample, measure each neuron's max activation. => shape [n_neurons]\n",
        "    2) Stack results for all samples => shape [n_samples, n_neurons]\n",
        "    3) Compute correlation matrix => shape [n_neurons, n_neurons]\n",
        "    4) Return top_k pairs with highest correlation (excluding diagonal).\n",
        "    \"\"\"\n",
        "    # Step 1: gather activations\n",
        "    # We'll do a short run on first snippet to find out how many neurons are in that layer\n",
        "    first_acts = measure_activations_for_layer(model, layer_name, samples[0])\n",
        "    n_neurons = len(first_acts)\n",
        "    all_acts = []\n",
        "    all_acts.append(first_acts)\n",
        "    # measure for the rest\n",
        "    for s in samples[1:]:\n",
        "        acts = measure_activations_for_layer(model, layer_name, s)\n",
        "        all_acts.append(acts)\n",
        "    all_acts = np.stack(all_acts, axis=0)  # shape [len(samples), n_neurons]\n",
        "\n",
        "    # Step 2: correlation matrix across neurons\n",
        "    # correlation across columns => shape [n_neurons, n_neurons]\n",
        "    corr = np.corrcoef(all_acts, rowvar=False)  # rowvar=False => columns are variables\n",
        "\n",
        "    # Step 3: find top pairs\n",
        "    # We'll flatten the upper triangle of corr\n",
        "    pairs = []\n",
        "    for i in range(n_neurons):\n",
        "        for j in range(i+1, n_neurons):\n",
        "            val = corr[i, j]\n",
        "            pairs.append((val, i, j))\n",
        "    # sort descending by correlation\n",
        "    pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "    top_pairs = pairs[:top_k]\n",
        "\n",
        "    return top_pairs, corr\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#  STEP 2: JOINT PRUNING + LOCAL SEARCH FOR A CHOSEN PAIR                     #\n",
        "###############################################################################\n",
        "\n",
        "def to_str_tokens(text, prepend_bos=True):\n",
        "    return model.to_str_tokens(text, prepend_bos=prepend_bos)\n",
        "\n",
        "def measure_two_neurons(\n",
        "    text,\n",
        "    layer_name,\n",
        "    neuronA,\n",
        "    neuronB,\n",
        "    prepend_bos=True,\n",
        "    max_length=512\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns (actA, maxA, argmaxA), (actB, maxB, argmaxB)\n",
        "    for text.\n",
        "    \"\"\"\n",
        "    tokens = model.to_tokens(text, prepend_bos=prepend_bos)\n",
        "    if tokens.shape[1] > max_length:\n",
        "        tokens = tokens[:, :max_length]\n",
        "    _, cache = model.run_with_cache(tokens.to(device))\n",
        "\n",
        "    # shape [seq_len, d_mlp]\n",
        "    act = cache[layer_name][0]\n",
        "    # single neurons\n",
        "    a_vals = act[:, neuronA]\n",
        "    b_vals = act[:, neuronB]\n",
        "    maxA = torch.max(a_vals).item()\n",
        "    argA = torch.argmax(a_vals).item()\n",
        "    maxB = torch.max(b_vals).item()\n",
        "    argB = torch.argmax(b_vals).item()\n",
        "    return (a_vals.cpu(), maxA, argA), (b_vals.cpu(), maxB, argB)\n",
        "\n",
        "def joint_prune(\n",
        "    text,\n",
        "    layer_name,\n",
        "    neuronA,\n",
        "    neuronB,\n",
        "    proportion_threshold=-0.5,\n",
        "    prepend_bos=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Similar to single-neuron prune, except we require BOTH neurons\n",
        "    to remain above proportion_threshold of their original max.\n",
        "\n",
        "    We'll do a naive approach: we guess the relevant sentence from the anchor\n",
        "    for whichever neuron is first, unify the region, prune tokens from ends,\n",
        "    ensure both remain above threshold.\n",
        "    \"\"\"\n",
        "    str_toks = to_str_tokens(text, prepend_bos=prepend_bos)\n",
        "    (actA, initA, argA), (actB, initB, argB) = measure_two_neurons(\n",
        "        text, layer_name, neuronA, neuronB, prepend_bos=prepend_bos\n",
        "    )\n",
        "\n",
        "    # Identify a \"region\" of interest. For now, we just pick the sentence containing argA.\n",
        "    # In practice, you might unify the sentences for argA and argB if they differ.\n",
        "    # We'll do the simpler approach here.\n",
        "    # We'll replicate your original snippet's \"sentence_tokenizer\"\n",
        "    # with a minimal logic for '.' or '\\n'\n",
        "    def basic_sentence_tokenize(tokens):\n",
        "        sents = []\n",
        "        cur = []\n",
        "        idx_map = {}\n",
        "        sent_idx = 0\n",
        "        for i, tok in enumerate(tokens):\n",
        "            cur.append(tok)\n",
        "            idx_map[i] = sent_idx\n",
        "            if tok in {\".\", \"\\n\"}:\n",
        "                sents.append(cur)\n",
        "                cur = []\n",
        "                sent_idx += 1\n",
        "        if cur:\n",
        "            sents.append(cur)\n",
        "        return sents, idx_map\n",
        "\n",
        "    sents, idx_map = basic_sentence_tokenize(str_toks)\n",
        "    if argA not in idx_map:\n",
        "        return text\n",
        "\n",
        "    anchor_sent_index = idx_map[argA]\n",
        "    anchor_sentence = sents[anchor_sent_index]\n",
        "\n",
        "    def measure_substring(sub_toks):\n",
        "        joined = \"\".join(sub_toks)\n",
        "        (a_, ma, _), (b_, mb, _) = measure_two_neurons(\n",
        "            joined, layer_name, neuronA, neuronB, prepend_bos=prepend_bos\n",
        "        )\n",
        "        return ma, mb, joined\n",
        "\n",
        "    def check_okay(ma, mb):\n",
        "        dropA = (ma - initA)/(initA if initA!=0 else 1e-6)\n",
        "        dropB = (mb - initB)/(initB if initB!=0 else 1e-6)\n",
        "        return (dropA >= proportion_threshold) and (dropB >= proportion_threshold)\n",
        "\n",
        "    pruned = anchor_sentence[:]\n",
        "    # prune from the end\n",
        "    while len(pruned)>1:\n",
        "        candidate = pruned[:-1]\n",
        "        ma, mb, joined = measure_substring(candidate)\n",
        "        if check_okay(ma, mb):\n",
        "            pruned = candidate\n",
        "        else:\n",
        "            break\n",
        "    # prune from front\n",
        "    while len(pruned)>1:\n",
        "        candidate = pruned[1:]\n",
        "        ma, mb, joined = measure_substring(candidate)\n",
        "        if check_okay(ma, mb):\n",
        "            pruned = candidate\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    final_text = \"\".join(pruned)\n",
        "    return final_text\n",
        "\n",
        "\n",
        "def multi_masked_generation(base_text, n=2, topk=3):\n",
        "    \"\"\"\n",
        "    A simplified approach that replaces up to `n` tokens with [MASK].\n",
        "    We'll do exactly the same logic from your code for single local search.\n",
        "    \"\"\"\n",
        "    # We'll reuse the approach from the 'multi_masked_generation' in your earlier code\n",
        "    # but keep it simpler. We'll just do a single pass.\n",
        "    tokens = aug_tokenizer.tokenize(base_text)\n",
        "    mask_token = aug_tokenizer.mask_token\n",
        "    if len(tokens) < n:\n",
        "        n = 1\n",
        "    center_idx = len(tokens)//2\n",
        "    start = max(center_idx-(n//2), 0)\n",
        "    end = min(start+n, len(tokens))\n",
        "    masked_tokens = tokens[:start]+[mask_token]*(end-start)+tokens[end:]\n",
        "    masked_input = aug_tokenizer.convert_tokens_to_string(masked_tokens)\n",
        "\n",
        "    inputs = aug_tokenizer(masked_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = aug_model(**inputs)\n",
        "    logits = out.logits  # shape: [1, seq_len, vocab_size]\n",
        "    mask_indices = (inputs[\"input_ids\"] == aug_tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "\n",
        "    all_candidates = []\n",
        "    def fill_mask_single_pass(_masked_tokens, _token_logits, _mask_indices):\n",
        "        cands = [_masked_tokens]\n",
        "        for midx in _mask_indices:\n",
        "            new_cands=[]\n",
        "            for c_ in cands:\n",
        "                rowlog = _token_logits[0,midx,:]\n",
        "                top_inds = torch.topk(rowlog, topk).indices\n",
        "                top_tokens = aug_tokenizer.convert_ids_to_tokens(top_inds)\n",
        "                for tk_ in top_tokens:\n",
        "                    copy_ = c_[:]\n",
        "                    copy_[midx] = tk_\n",
        "                    new_cands.append(copy_)\n",
        "            cands=new_cands\n",
        "        return cands\n",
        "\n",
        "    filled = fill_mask_single_pass(masked_tokens, logits, mask_indices)\n",
        "    for cand in filled:\n",
        "        s_ = aug_tokenizer.convert_tokens_to_string(cand)\n",
        "        all_candidates.append(s_)\n",
        "    return list(set(all_candidates))\n",
        "\n",
        "def gpt_generation(base_text, num_return=3):\n",
        "    prompt = f\"Rewrite the following to preserve some meaning but vary the phrasing:\\n\\n{base_text}\\n\\nRewrite:\\n\"\n",
        "    input_ids = gen_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = gen_model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=20,\n",
        "            do_sample=True,\n",
        "            top_k=40,\n",
        "            top_p=0.9,\n",
        "            num_return_sequences=num_return\n",
        "        )\n",
        "    cands=[]\n",
        "    for x in out:\n",
        "        txt = gen_tokenizer.decode(x, skip_special_tokens=True)\n",
        "        splitted = txt.split(\"Rewrite:\\n\")\n",
        "        if len(splitted)>1:\n",
        "            cands.append(splitted[-1].strip())\n",
        "        else:\n",
        "            cands.append(txt)\n",
        "    return list(set(cands))\n",
        "\n",
        "\n",
        "def measure_and_label_candidates_2neurons(\n",
        "    text_list,\n",
        "    layer_name,\n",
        "    neuronA, neuronB,\n",
        "    origA, origB,\n",
        "    inclusion_threshold=-0.3,\n",
        "    exclusion_threshold=-0.7\n",
        "):\n",
        "    \"\"\"\n",
        "    For each text in text_list, measure new activation for A & B.\n",
        "    Label:\n",
        "       \"positive\" if both dropA,dropB >= inclusion_threshold\n",
        "       \"negative\" if dropA <= exclusion_threshold or dropB <= exclusion_threshold\n",
        "       else \"borderline\"\n",
        "    Return list of dicts\n",
        "    \"\"\"\n",
        "    results=[]\n",
        "    for t_ in text_list:\n",
        "        (a_, newA, _), (b_, newB, _) = measure_two_neurons(t_, layer_name, neuronA, neuronB)\n",
        "        dropA = (newA - origA)/(origA if origA!=0 else 1e-6)\n",
        "        dropB = (newB - origB)/(origB if origB!=0 else 1e-6)\n",
        "        if (dropA >= inclusion_threshold) and (dropB >= inclusion_threshold):\n",
        "            label=\"positive\"\n",
        "        elif (dropA <= exclusion_threshold) or (dropB <= exclusion_threshold):\n",
        "            label=\"negative\"\n",
        "        else:\n",
        "            label=\"borderline\"\n",
        "        results.append({\n",
        "            \"new_text\": t_,\n",
        "            \"new_activation_A\": newA,\n",
        "            \"new_activation_B\": newB,\n",
        "            \"dropA\": dropA,\n",
        "            \"dropB\": dropB,\n",
        "            \"label\": label\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#                              MAIN DEMO                                      #\n",
        "###############################################################################\n",
        "\n",
        "def main():\n",
        "    # 1) Find top correlated pairs\n",
        "    top_pairs, corr = find_top_pairs_coactivation(model, LAYER_OF_INTEREST, RANDOM_SNIPPETS, top_k=3)\n",
        "    print(\"\\n==> Top correlated neuron pairs for layer:\", LAYER_OF_INTEREST)\n",
        "    for i, (val, nA, nB) in enumerate(top_pairs, start=1):\n",
        "        print(f\"{i}) Neuron {nA} & {nB}, correlation={val:.4f}\")\n",
        "\n",
        "    # We'll just pick the top pair for the demonstration\n",
        "    if not top_pairs:\n",
        "        print(\"No pairs found, or something went wrong with correlation.\")\n",
        "        return\n",
        "    best_corr, best_nA, best_nB = top_pairs[0]\n",
        "    print(f\"\\nUsing top pair: Neuron {best_nA} & Neuron {best_nB}, correlation={best_corr:.4f}\\n\")\n",
        "\n",
        "    # 2) Let's define some sample text to interpret (like original code).\n",
        "    # We replicate your snippet sets:\n",
        "    test_snippets = [\n",
        "        \" was put on the IUCN Red List under \",\n",
        "        \" It was added to the National Register of \",\n",
        "        \" The thought didn't even cross my mind\",\n",
        "        \" am not a native English speaker\",\n",
        "        \" .](bjc201256f1){#fig1\",\n",
        "    ]\n",
        "\n",
        "    # 3) For each snippet, do the joint pruning, local expansions, produce structured output\n",
        "    final_reports = []  # store each snippet's result\n",
        "    for snippet in test_snippets:\n",
        "        # measure original\n",
        "        (a_, origA, argA), (b_, origB, argB) = measure_two_neurons(snippet, LAYER_OF_INTEREST, best_nA, best_nB)\n",
        "        # joint prune\n",
        "        pruned = joint_prune(snippet, LAYER_OF_INTEREST, best_nA, best_nB, proportion_threshold=-0.5)\n",
        "        if pruned is None:\n",
        "            pruned = snippet\n",
        "        # measure pruned\n",
        "        (_, newA, _), (_, newB, _) = measure_two_neurons(pruned, LAYER_OF_INTEREST, best_nA, best_nB)\n",
        "        # local expansions with DistilBERT\n",
        "        mlm_candidates = multi_masked_generation(pruned, n=2, topk=3)\n",
        "        # local expansions with GPT\n",
        "        gpt_candidates = gpt_generation(pruned, num_return=3)\n",
        "\n",
        "        # measure expansions\n",
        "        mlm_labeled = measure_and_label_candidates_2neurons(\n",
        "            mlm_candidates, LAYER_OF_INTEREST, best_nA, best_nB,\n",
        "            newA, newB,\n",
        "            inclusion_threshold=-0.3,  # up to 30% drop => positive\n",
        "            exclusion_threshold=-0.7\n",
        "        )\n",
        "        gpt_labeled = measure_and_label_candidates_2neurons(\n",
        "            gpt_candidates, LAYER_OF_INTEREST, best_nA, best_nB,\n",
        "            newA, newB,\n",
        "            inclusion_threshold=-0.3,\n",
        "            exclusion_threshold=-0.7\n",
        "        )\n",
        "\n",
        "        snippet_report = {\n",
        "            \"original_snippet\": snippet,\n",
        "            \"neuron_pair\": (best_nA, best_nB),\n",
        "            \"original_activation_A\": origA,\n",
        "            \"original_activation_B\": origB,\n",
        "            \"pruned_text\": pruned,\n",
        "            \"pruned_activation_A\": newA,\n",
        "            \"pruned_activation_B\": newB,\n",
        "            \"distilbert_expansions\": mlm_labeled,\n",
        "            \"gpt_expansions\": gpt_labeled\n",
        "        }\n",
        "        final_reports.append(snippet_report)\n",
        "\n",
        "    # 4) Print results in a style similar to original\n",
        "    for idx, rep in enumerate(final_reports):\n",
        "        print(\"\\n==============================================================\")\n",
        "        print(f\"Snippet {idx+1}: {rep['original_snippet']}\")\n",
        "        print(f\"Neuron Pair: {rep['neuron_pair']}\")\n",
        "        print(f\"Original Activation => A={rep['original_activation_A']:.4f}, B={rep['original_activation_B']:.4f}\")\n",
        "        print(\"==> Pruned to =>\", rep[\"pruned_text\"])\n",
        "        print(f\"Pruned Activation => A={rep['pruned_activation_A']:.4f}, B={rep['pruned_activation_B']:.4f}\\n\")\n",
        "\n",
        "        print(\"DistilBERT expansions =>\")\n",
        "        for sub in rep[\"distilbert_expansions\"]:\n",
        "            print(f\"  Label={sub['label'].upper()}\"\n",
        "                  f\"  A_new={sub['new_activation_A']:.4f}, B_new={sub['new_activation_B']:.4f},\"\n",
        "                  f\"  DropA={sub['dropA']:.4f}, DropB={sub['dropB']:.4f}\")\n",
        "            print(f\"     -> {sub['new_text']}\")\n",
        "        print()\n",
        "\n",
        "        print(\"GPT expansions =>\")\n",
        "        for sub in rep[\"gpt_expansions\"]:\n",
        "            print(f\"  Label={sub['label'].upper()}\"\n",
        "                  f\"  A_new={sub['new_activation_A']:.4f}, B_new={sub['new_activation_B']:.4f},\"\n",
        "                  f\"  DropA={sub['dropA']:.4f}, DropB={sub['dropB']:.4f}\")\n",
        "            print(f\"     -> {sub['new_text']}\")\n",
        "        print(\"==============================================================\\n\")\n",
        "\n",
        "    # 5) If you want a final structured data for the entire run:\n",
        "    # (e.g. to store as JSON)\n",
        "    # import json\n",
        "    # with open(\"multi_neuron_report.json\", \"w\") as f:\n",
        "    #     json.dump(final_reports, f, indent=2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "gRiaNRd-DSLc",
        "outputId": "78b2bb92-8810-4c49-b844-8b2811c01a37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model solu-8l-old into HookedTransformer\n",
            "Moving model to device:  cuda\n",
            "\n",
            "==> Top correlated neuron pairs for layer: blocks.3.mlp.hook_mid\n",
            "1) Neuron 425 & 1671, correlation=1.0000\n",
            "2) Neuron 425 & 2190, correlation=1.0000\n",
            "3) Neuron 425 & 2266, correlation=1.0000\n",
            "\n",
            "Using top pair: Neuron 425 & Neuron 1671, correlation=1.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================================================\n",
            "Snippet 1:  was put on the IUCN Red List under \n",
            "Neuron Pair: (425, 1671)\n",
            "Original Activation => A=0.0003, B=0.0008\n",
            "==> Pruned to => <|endoftext|>\n",
            "Pruned Activation => A=0.0003, B=0.0008\n",
            "\n",
            "DistilBERT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5058\n",
            "     -> < | end = |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4143\n",
            "     -> < | end | |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3563\n",
            "     -> < | end < =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5165\n",
            "     -> < | end | =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3843\n",
            "     -> < | end | <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4450\n",
            "     -> < | end = =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3257\n",
            "     -> < | end < |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3638\n",
            "     -> < | end = <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0010,  DropA=6.6845, DropB=0.2625\n",
            "     -> < | end < <t | >\n",
            "\n",
            "GPT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0003, B_new=0.0008,  DropA=-0.0000, DropB=-0.0000\n",
            "     -> A man in a wheelchair, a person with a serious medical condition or a woman who is blind\n",
            "  Label=POSITIVE  A_new=0.0008, B_new=0.0008,  DropA=1.7827, DropB=-0.0000\n",
            "     -> If the user does not use the default value of 1 then the user can return false\n",
            "  Label=POSITIVE  A_new=0.0003, B_new=0.0008,  DropA=-0.0000, DropB=0.0187\n",
            "     -> Quote:\n",
            "\n",
            ">The only thing that matters for me with the current game is how well\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "Snippet 2:  It was added to the National Register of \n",
            "Neuron Pair: (425, 1671)\n",
            "Original Activation => A=0.0003, B=0.0008\n",
            "==> Pruned to => <|endoftext|>\n",
            "Pruned Activation => A=0.0003, B=0.0008\n",
            "\n",
            "DistilBERT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5058\n",
            "     -> < | end = |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4143\n",
            "     -> < | end | |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3563\n",
            "     -> < | end < =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5165\n",
            "     -> < | end | =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3843\n",
            "     -> < | end | <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4450\n",
            "     -> < | end = =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3257\n",
            "     -> < | end < |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3638\n",
            "     -> < | end = <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0010,  DropA=6.6845, DropB=0.2625\n",
            "     -> < | end < <t | >\n",
            "\n",
            "GPT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0003, B_new=0.0008,  DropA=-0.0000, DropB=-0.0000\n",
            "     -> Add in the following, then edit the header and body of the page so that it is now\n",
            "  Label=POSITIVE  A_new=0.0006, B_new=0.0008,  DropA=1.0959, DropB=-0.0000\n",
            "     -> \"It was the biggest game on television since \"Game of Thrones.\" It was so popular that\n",
            "  Label=POSITIVE  A_new=0.0033, B_new=0.0008,  DropA=9.8937, DropB=-0.0000\n",
            "     -> <div class=\"container\">\n",
            "\n",
            "<span class=\"image\" src=\"https://image\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "Snippet 3:  The thought didn't even cross my mind\n",
            "Neuron Pair: (425, 1671)\n",
            "Original Activation => A=0.0003, B=0.0008\n",
            "==> Pruned to => <|endoftext|>\n",
            "Pruned Activation => A=0.0003, B=0.0008\n",
            "\n",
            "DistilBERT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5058\n",
            "     -> < | end = |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4143\n",
            "     -> < | end | |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3563\n",
            "     -> < | end < =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5165\n",
            "     -> < | end | =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3843\n",
            "     -> < | end | <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4450\n",
            "     -> < | end = =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3257\n",
            "     -> < | end < |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3638\n",
            "     -> < | end = <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0010,  DropA=6.6845, DropB=0.2625\n",
            "     -> < | end < <t | >\n",
            "\n",
            "GPT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0003, B_new=0.0008,  DropA=-0.0000, DropB=-0.0000\n",
            "     -> \"The \"Guns\" Act of 1862 was a bill intended to prohibit slavery and to prohibit\n",
            "  Label=POSITIVE  A_new=0.0006, B_new=0.0008,  DropA=0.8899, DropB=-0.0000\n",
            "     -> To improve security for customers using your website, we're making it a part of our Terms of\n",
            "  Label=POSITIVE  A_new=0.0003, B_new=0.0008,  DropA=-0.0000, DropB=-0.0000\n",
            "     -> The above table contains a list of the most common and rare cases of an injury. These were\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "Snippet 4:  am not a native English speaker\n",
            "Neuron Pair: (425, 1671)\n",
            "Original Activation => A=0.0003, B=0.0008\n",
            "==> Pruned to => <|endoftext|>\n",
            "Pruned Activation => A=0.0003, B=0.0008\n",
            "\n",
            "DistilBERT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5058\n",
            "     -> < | end = |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4143\n",
            "     -> < | end | |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3563\n",
            "     -> < | end < =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5165\n",
            "     -> < | end | =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3843\n",
            "     -> < | end | <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4450\n",
            "     -> < | end = =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3257\n",
            "     -> < | end < |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3638\n",
            "     -> < | end = <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0010,  DropA=6.6845, DropB=0.2625\n",
            "     -> < | end < <t | >\n",
            "\n",
            "GPT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0010, B_new=0.0008,  DropA=2.3581, DropB=-0.0000\n",
            "     -> RUN\n",
            "\n",
            "\n",
            "If you had a choice between a high-quality new bike and a classic\n",
            "  Label=POSITIVE  A_new=0.0005, B_new=0.0008,  DropA=0.7299, DropB=-0.0000\n",
            "     -> This was done after using the default build method on the server.\n",
            "\n",
            "This was a mistake\n",
            "  Label=POSITIVE  A_new=0.0010, B_new=0.0008,  DropA=2.2692, DropB=-0.0000\n",
            "     -> $ docker run -v foo:20200 -p 8000 -t tp:8000 $\n",
            "==============================================================\n",
            "\n",
            "\n",
            "==============================================================\n",
            "Snippet 5:  .](bjc201256f1){#fig1\n",
            "Neuron Pair: (425, 1671)\n",
            "Original Activation => A=0.0005, B=0.0010\n",
            "==> Pruned to => <|endoftext|>\n",
            "Pruned Activation => A=0.0003, B=0.0008\n",
            "\n",
            "DistilBERT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5058\n",
            "     -> < | end = |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4143\n",
            "     -> < | end | |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3563\n",
            "     -> < | end < =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.5165\n",
            "     -> < | end | =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3843\n",
            "     -> < | end | <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0012,  DropA=6.6845, DropB=0.4450\n",
            "     -> < | end = =t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3257\n",
            "     -> < | end < |t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0011,  DropA=6.6845, DropB=0.3638\n",
            "     -> < | end = <t | >\n",
            "  Label=POSITIVE  A_new=0.0023, B_new=0.0010,  DropA=6.6845, DropB=0.2625\n",
            "     -> < | end < <t | >\n",
            "\n",
            "GPT expansions =>\n",
            "  Label=POSITIVE  A_new=0.0005, B_new=0.0012,  DropA=0.7903, DropB=0.4049\n",
            "     -> [1]\n",
            "\n",
            "[2]\n",
            "\n",
            "[3]\n",
            "\n",
            "[4]\n",
            "  Label=POSITIVE  A_new=0.0004, B_new=0.0008,  DropA=0.3203, DropB=-0.0000\n",
            "     -> [B] This is how it should be:\n",
            "\n",
            "[S] This is a [\n",
            "  Label=POSITIVE  A_new=0.0014, B_new=0.0012,  DropA=3.5400, DropB=0.5143\n",
            "     -> {\n",
            "\n",
            "\" name \" : \" The Game is Over! \" ,\n",
            "\n",
            "\" version\n",
            "==============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "# Multi-Neuron Analysis Example with Large Snippet Sets\n",
        "# ---------------------------------------------------------------------------------\n",
        "# Paste this entire code block into a single cell in your notebook and run.\n",
        "\n",
        "import re\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "from transformer_lens import EasyTransformer\n",
        "from transformer_lens.utils import to_numpy\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForMaskedLM,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM\n",
        ")\n",
        "\n",
        "import nltk\n",
        "try:\n",
        "    _ = nltk.corpus.stopwords.words('english')\n",
        "except:\n",
        "    nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "# ------------------------------ MODEL LOADING ------------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"solu-8l-old\"\n",
        "model = EasyTransformer.from_pretrained(MODEL_NAME).to(device)\n",
        "model.eval()\n",
        "\n",
        "# Masked LM for local search expansions (DistilBERT):\n",
        "AUG_MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
        "aug_tokenizer = AutoTokenizer.from_pretrained(AUG_MODEL_CHECKPOINT)\n",
        "aug_model = AutoModelForMaskedLM.from_pretrained(AUG_MODEL_CHECKPOINT).to(device)\n",
        "aug_model.eval()\n",
        "\n",
        "# GPT-2 for generative expansions:\n",
        "GEN_MODEL_NAME = \"gpt2\"\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(GEN_MODEL_NAME).to(device)\n",
        "gen_model.eval()\n",
        "\n",
        "# Which layer to analyze (you can change if you want):\n",
        "LAYER_OF_INTEREST = \"blocks.3.mlp.hook_mid\"\n",
        "\n",
        "# ------------------------------ SNIPPET SETS -------------------------------------\n",
        "# We combine the \"big\" snippets from your original code into one big set for correlation.\n",
        "snippets_3_1 = [\n",
        "    \"\"\"\n",
        "\"I will. Same to you.\"\n",
        "\n",
        "He tells me that he loves me, and then I hang up just as I arrive at Wes's house.\n",
        "\n",
        "I park in the driveway next to his bike, not bothering to hide my Jeep down the road like usual. I know all about our past, and frankly, now that Wes knows too, his mother's threats are useless. She can't bully me out of Wes's life.\n",
        "\n",
        "I've made mistakes, not all of them completely my fault, but I can try not to make any more. I'm not sure where we stand relationship-wise, but we'll figure it out. We might even make the right decisions this time. For now, we just have to save the world. No pressure.\n",
        "\n",
        "I quickly dial Nathan, but he doesn't answer, making me nervous. I tell him to call me back, and that I'm at Wes's house. I push the phone into my pocket and climb out of the Jeep.\n",
        "\n",
        "Wes waits for me at his door, smiling and looking a little nervous. I wonder if he thought I was going to turn onto the freeway and drive away instead of coming here. The thought didn't even cross my mind. I would have followed him anywhere.\n",
        "\n",
        "\"Parents aren't home,\" he says, watching my approach. \"In case you were worried.\"\n",
        "\n",
        "\"Now you won't have to lock the door,\" I say, and stop in front of him.\n",
        "\n",
        "Wes's smile fades. \"I always lock the door,\" he replies, and turns to push inside his basement apartment.\n",
        "\n",
        "I realize that I'm nervous too. Beyond the life-altering shit that's about to go down with The Program—I'm here with Wes. And I'm still not entirely sure how to act.\n",
        "\n",
        "I understand what Michael Realm meant now, how remembering can be a curse. Because I remember things that Wes doesn't. I remember how much he loved me. How much I loved him. The stuff they couldn't take. The stuff that crashed back. So much history, and now it's only mine.\n",
        "\n",
        "I walk inside his room and close the door behind me. It's dimly lit, the high-set window not enough on a darkened, stormy day. But Wes doesn't flip on the lights as he leads us into the living room area.\n",
        "\n",
        "I sit on the couch, and Wes comes to the coffee table and turns his laptop in my direction before telling me he'll be right back. He jogs up the stairs and disappears inside his house.\n",
        "\n",
        "I smile at the wallpaper on his computer, a vintage motorcycle, mid-repair. It's simple, honest. I click open the browser, and his last page pulls up. It's a board called Survivor Rate, and the quick description says it's a forum for survivors of the epidemic. It has over ten thousand members.\n",
        "\n",
        "I click on the first thread and start to read through, when I hear Wes close the door and lock it before bounding down the stairs. I look up, and he holds out a bag of frozen peas.\n",
        "\n",
        "\"For your head,\" he says. \"I tried to find an aspirin, but my mom won't keep any pills in the house.\"\n",
        "\n",
        "\"Oh,\" I say, taking the icy bag from him. \"Thank you.\" It's kind of sweet of him to do that without me asking. I move my legs aside as he scoots past me and drops down onto the couch in his usual spot. I gently press the peas to my head, groaning at the pressure.\n",
        "\n",
        "\"This is the one,\" Wes starts, turning the screen so he can see it too, \"where the guy had the picture of Michael.\"\n",
        "\n",
        "\"He goes by Realm,\" I say. Under the picture, the post reads: Anyone know this guy?\n",
        "\n",
        "Wes goes into the private messages and shows me his exchange with the original poster. It doesn't give us any information on locating Realm,\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "to the human analyte enzyme in its native matrix (eg serum); iii) and the inter-method ratio should be constant (within the limits of experimental error) for the enzyme calibrator and for all patients' samples.<|endoftext|>Q:\n",
        "\n",
        "Render named children in React component?\n",
        "\n",
        "I have a modal component which take a trigger to open the modal, and the content to go inside the modal.\n",
        "<Modal>\n",
        "  <button className=\"btn btn--primary\">Open modalbutton>\n",
        "  <div>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  div>\n",
        "Modal>\n",
        "\n",
        "And in the Modal component:\n",
        "  return (\n",
        "    <div className=\"Modal\">\n",
        "      {props.children[0]}\n",
        "      <div className=\"Modal__container\">\n",
        "        <div className=\"Modal__header\">\n",
        "          <button className=\"Modal__close btn btn--secondary btn--small\">\n",
        "            Close\n",
        "          button>\n",
        "          <h1 className=\"Modal__heading\">Here is my modalh1>\n",
        "        div>\n",
        "        <div className=\"Modal__content\">{props.children[1]}div>\n",
        "      div>\n",
        "    div>\n",
        "  );\n",
        "\n",
        "This is working but very fragile as Im using an index on props.children. Can I instead name the components I pass to Modal? So something like:\n",
        "<Modal>\n",
        "  <Modal.Trigger>\n",
        "    <button className=\"btn btn--primary\">Open modalbutton>\n",
        "  Modal.Trigger>\n",
        "  <Modal.Content>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  Modal.Content>\n",
        "Modal>\n",
        "...\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "latest lakeshore news & sports for WOMT/WCUB/WQTC/WLKN/WLTU/WEMP\n",
        "\n",
        "Opening Weekend of Sturgeon Spearing\n",
        "\n",
        "This past weekend marked the opening weekend for sturgeon spearing on the Winnebago System. Day one was by far the better day, with 219 fish collected. Lake Winnebago saw decent numbers with 83 fish caught, but the Upriver Lakes saw much better success, with 136 fish reeled in. Day 2 was not quite as fruitful, with a total of 124 sturgeon captured. The split was much closer as well, with 56 fish coming from Lake Winnebago, and 68 fish being pulled from the Upriver Lakes. Joseph Orlando has the distinction of catching the largest sturgeon of the weekend, measuring at 77.5” long, and weighing a whopping 147.3 LBS. Congratulations to Joseph, and good luck to those braving the winter cold.<|endoftext|>I am a 44 yr. old french Canadian PHP developper ...\n",
        "\"\"\"\n",
        "]\n",
        "\n",
        "snippets_3_2 = [\n",
        "    \" am not a native English speaker\",\n",
        "    \" am not a fluent English speaker\",\n",
        "    \" am not a true English speaker\",\n",
        "]\n",
        "\n",
        "snippets_3_912 = [\n",
        "    r\"\"\"was put on the IUCN Red List under\"\"\",\n",
        "    r\"\"\"It was added to the National Register of\"\"\",\n",
        "    r\"\"\"The thought didn't even cross my mind\"\"\",\n",
        "    r\"\"\" .](bjc201256f1){#fig1\"\"\",\n",
        "]\n",
        "\n",
        "snippets_4_912 = [\n",
        "    r\"\"\" (bjc201156f1)\\{\\#fig1\"\"\",\n",
        "    r\"\"\"I realize that I'm nervous too. Beyond the life-altering shit that's about to go down\"\"\",\n",
        "    r\"\"\"(bjc201256f1)\\{\\#fig1\"\"\",\n",
        "    r\"\"\" #bjc201156f1)\\{\\#fig1\"\"\",\n",
        "]\n",
        "\n",
        "# Combine them all for correlation scanning:\n",
        "ALL_SNIPPETS = []\n",
        "ALL_SNIPPETS.extend(snippets_3_1)\n",
        "ALL_SNIPPETS.extend(snippets_3_2)\n",
        "ALL_SNIPPETS.extend(snippets_3_912)\n",
        "ALL_SNIPPETS.extend(snippets_4_912)\n",
        "\n",
        "\n",
        "# ------------------------------ STEP 1: CORRELATION ------------------------------\n",
        "\n",
        "\n",
        "def measure_activations_for_layer(model, layer_name, text):\n",
        "    \"\"\"\n",
        "    Return a 1D array [num_neurons_in_layer] of each neuron's max activation on `text`.\n",
        "    \"\"\"\n",
        "    tokens = model.to_tokens(text, prepend_bos=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        _, cache = model.run_with_cache(tokens)\n",
        "    layer_act = cache[layer_name][0]  # shape [seq_len, d_mlp]\n",
        "    max_per_neuron = layer_act.max(dim=0).values.cpu().numpy()  # shape [d_mlp]\n",
        "    return max_per_neuron\n",
        "\n",
        "def find_top_pairs_coactivation(model, layer_name, samples, top_k=3):\n",
        "    \"\"\"\n",
        "    1) For each sample, measure each neuron's max activation => shape [n_neurons].\n",
        "    2) Stack => shape [num_samples, n_neurons].\n",
        "    3) Corr matrix => shape [n_neurons, n_neurons].\n",
        "    4) Return top_k correlated pairs (descending).\n",
        "    \"\"\"\n",
        "    # measure dimension from first snippet\n",
        "    first_acts = measure_activations_for_layer(model, layer_name, samples[0])\n",
        "    d_mlp = len(first_acts)\n",
        "\n",
        "    all_acts = [first_acts]\n",
        "    for s in samples[1:]:\n",
        "        arr = measure_activations_for_layer(model, layer_name, s)\n",
        "        all_acts.append(arr)\n",
        "    all_acts = np.stack(all_acts, axis=0)  # [num_samples, d_mlp]\n",
        "\n",
        "    corr = np.corrcoef(all_acts, rowvar=False)  # [d_mlp, d_mlp]\n",
        "    pairs = []\n",
        "    for i in range(d_mlp):\n",
        "        for j in range(i+1, d_mlp):\n",
        "            val = corr[i, j]\n",
        "            pairs.append((val, i, j))\n",
        "    pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "    return pairs[:top_k], corr\n",
        "\n",
        "\n",
        "# ------------------------------ STEP 2: JOINT PRUNING ---------------------------\n",
        "\n",
        "\n",
        "def sentence_tokenizer(str_tokens):\n",
        "    \"\"\"\n",
        "    Minimal function to slice tokens into sentences.\n",
        "    We'll treat '.', '\\n' as sentence boundaries.\n",
        "    Return:\n",
        "      sentences: list of list-of-tokens\n",
        "      token_to_sent_idx: map token_idx -> sentence_idx\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    current = []\n",
        "    token_to_sent_idx = {}\n",
        "    sent_idx = 0\n",
        "    for i, tok in enumerate(str_tokens):\n",
        "        current.append(tok)\n",
        "        token_to_sent_idx[i] = sent_idx\n",
        "        if tok in {\".\", \"\\n\"}:\n",
        "            sentences.append(current)\n",
        "            current = []\n",
        "            sent_idx += 1\n",
        "    if current:\n",
        "        sentences.append(current)\n",
        "    return sentences, token_to_sent_idx\n",
        "\n",
        "\n",
        "def measure_two_neurons(text, layer, nA, nB, prepend_bos=True, max_len=512):\n",
        "    \"\"\"\n",
        "    Return (maxA, idxA), (maxB, idxB).\n",
        "    Also the entire activation vectors if needed.\n",
        "    \"\"\"\n",
        "    toks = model.to_tokens(text, prepend_bos=prepend_bos).to(device)\n",
        "    if toks.shape[1] > max_len:\n",
        "        toks = toks[:, :max_len]\n",
        "    with torch.no_grad():\n",
        "        _, cache = model.run_with_cache(toks)\n",
        "    act = cache[layer][0]  # shape [seq_len, d_mlp]\n",
        "    valsA = act[:, nA]\n",
        "    valsB = act[:, nB]\n",
        "    maxA = torch.max(valsA).item()\n",
        "    idxA = torch.argmax(valsA).item()\n",
        "    maxB = torch.max(valsB).item()\n",
        "    idxB = torch.argmax(valsB).item()\n",
        "    return (maxA, idxA), (maxB, idxB)\n",
        "\n",
        "def joint_prune(\n",
        "    text,\n",
        "    layer,\n",
        "    nA, nB,\n",
        "    proportion_threshold=-0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Iterative sentence-level or token-level pruning:\n",
        "    - Find anchor for neuron A or B (or both).\n",
        "    - Extract that sentence as a starting substring.\n",
        "    - Then remove tokens from end, then from start, as long as combined activation\n",
        "      doesn't drop below proportion_threshold for BOTH neurons.\n",
        "\n",
        "    If the snippet doesn't significantly activate the pair, it might prune too aggressively.\n",
        "    You can raise proportion_threshold to prune less, or skip pruning if it kills everything.\n",
        "    \"\"\"\n",
        "    # 1) Convert to str tokens\n",
        "    str_toks = model.to_str_tokens(text, prepend_bos=True)\n",
        "    # measure original\n",
        "    (origA, idxA), (origB, idxB) = measure_two_neurons(text, layer, nA, nB)\n",
        "    if origA < 1e-9 and origB < 1e-9:\n",
        "        # no activation, just return original\n",
        "        return text\n",
        "\n",
        "    # We find which sentence anchor_idx is in (pick the neuron that has the bigger max).\n",
        "    anchor_neuron = \"A\" if origA > origB else \"B\"\n",
        "    anchor_idx = idxA if anchor_neuron==\"A\" else idxB\n",
        "\n",
        "    sents, token_to_sent = sentence_tokenizer(str_toks)\n",
        "    if anchor_idx not in token_to_sent:\n",
        "        return text\n",
        "    anchor_sent_idx = token_to_sent[anchor_idx]\n",
        "    anchor_sentence = sents[anchor_sent_idx]\n",
        "\n",
        "    # We do a token-level approach on that anchor sentence.\n",
        "    # Then we do iterative removal from the ends.\n",
        "    def measure_substring(sub_tokens):\n",
        "        joined = \"\".join(sub_tokens)\n",
        "        (mA, _), (mB, _) = measure_two_neurons(joined, layer, nA, nB)\n",
        "        return mA, mB, joined\n",
        "\n",
        "    best_toks = anchor_sentence[:]\n",
        "    changed = True\n",
        "    while changed and len(best_toks)>1:\n",
        "        changed = False\n",
        "        # try remove last token\n",
        "        trial = best_toks[:-1]\n",
        "        mA, mB, joined = measure_substring(trial)\n",
        "        dropA = (mA-origA)/max(1e-9, origA)\n",
        "        dropB = (mB-origB)/max(1e-9, origB)\n",
        "        # require both drop >= proportion_threshold\n",
        "        if dropA >= proportion_threshold and dropB >= proportion_threshold:\n",
        "            best_toks = trial\n",
        "            changed = True\n",
        "\n",
        "        if not changed and len(best_toks)>1:\n",
        "            # try remove first token\n",
        "            trial = best_toks[1:]\n",
        "            mA, mB, joined = measure_substring(trial)\n",
        "            dropA = (mA-origA)/max(1e-9, origA)\n",
        "            dropB = (mB-origB)/max(1e-9, origB)\n",
        "            if dropA >= proportion_threshold and dropB >= proportion_threshold:\n",
        "                best_toks = trial\n",
        "                changed = True\n",
        "\n",
        "    pruned = \"\".join(best_toks)\n",
        "    return pruned\n",
        "\n",
        "\n",
        "# ------------------------------ STEP 3: LOCAL SEARCH ----------------------------\n",
        "\n",
        "class ContextualAugmenter:\n",
        "    \"\"\"\n",
        "    This is the local search approach with DistilBERT-based masking\n",
        "    you used in single-neuron code.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, tokenizer, interpret_model):\n",
        "        self.lm_model = model\n",
        "        self.lm_tokenizer = tokenizer\n",
        "        self.interpret_model = interpret_model\n",
        "        self.stops = set(stopwords.words('english'))\n",
        "        self.to_strip = \" .,!?;:-_\\\"')(\\n\"\n",
        "        self.word_tokenizer = re.compile(r\"\\b\")\n",
        "\n",
        "    def augment(self, text, n=3):\n",
        "        tokens = self.word_tokenizer.split(text)\n",
        "        masked_tokens = tokens[:]\n",
        "        all_new_texts = []\n",
        "        all_positions = []\n",
        "\n",
        "        for i, tk in enumerate(tokens):\n",
        "            # skip empties or stops\n",
        "            if not tk.strip(self.to_strip) or tk.lower() in self.stops:\n",
        "                continue\n",
        "            # mask\n",
        "            masked_tokens[i] = self.lm_tokenizer.mask_token\n",
        "            masked_str = \"\".join(masked_tokens)\n",
        "            inputs = self.lm_tokenizer(masked_str, return_tensors=\"pt\").to(device)\n",
        "            with torch.no_grad():\n",
        "                out = self.lm_model(**inputs)\n",
        "            logits = out.logits  # [batch=1, seq_len, vocab]\n",
        "            # find mask index\n",
        "            mask_idx = (inputs[\"input_ids\"][0] == self.lm_tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
        "            if len(mask_idx[0])==0:\n",
        "                # revert and skip\n",
        "                masked_tokens[i] = tk\n",
        "                continue\n",
        "            m_i = mask_idx[0].item()\n",
        "            row = logits[0, m_i, :]\n",
        "            top_inds = torch.topk(row, 20).indices.tolist()\n",
        "\n",
        "            found=0\n",
        "            char_pos = len(\"\".join(tokens[:i]))  # approximate\n",
        "\n",
        "            for tt in top_inds:\n",
        "                cand = self.lm_tokenizer.decode([tt]).strip()\n",
        "                if cand.lower() == tk.lower():\n",
        "                    continue\n",
        "                # rebuild\n",
        "                replaced = masked_str.replace(self.lm_tokenizer.mask_token, cand, 1)\n",
        "                all_new_texts.append(replaced)\n",
        "                all_positions.append(char_pos)\n",
        "                found+=1\n",
        "                if found>=n:\n",
        "                    break\n",
        "\n",
        "            # revert\n",
        "            masked_tokens[i] = tk\n",
        "        return all_new_texts, all_positions\n",
        "\n",
        "def gpt_generation(base_text, num_return=3):\n",
        "    prompt = (\n",
        "        \"Rewrite the following snippet in a slightly different way:\\n\\n\"\n",
        "        + base_text\n",
        "        + \"\\n\\nRewrite:\\n\"\n",
        "    )\n",
        "    input_ids = gen_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = gen_model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=20,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.9,\n",
        "            num_return_sequences=num_return,\n",
        "            temperature=1.0\n",
        "        )\n",
        "    cands = []\n",
        "    for xx in out:\n",
        "        txt = gen_tokenizer.decode(xx, skip_special_tokens=True)\n",
        "        # parse out the part after \"Rewrite:\"\n",
        "        splitted = txt.split(\"Rewrite:\\n\")\n",
        "        if len(splitted) > 1:\n",
        "            cands.append(splitted[-1].strip())\n",
        "        else:\n",
        "            cands.append(txt)\n",
        "    return list(set(cands))\n",
        "\n",
        "def measure_and_label_candidates_2neurons(\n",
        "    text_list, layer, nA, nB,\n",
        "    baseA, baseB,\n",
        "    inclusion_threshold=-0.3,\n",
        "    exclusion_threshold=-0.7\n",
        "):\n",
        "    \"\"\"\n",
        "    For each candidate text, measure newA,newB => drop from baseA, baseB.\n",
        "    Then label:\n",
        "      'positive' if dropA>=inclusion_threshold and dropB>=inclusion_threshold\n",
        "      'negative' if dropA<=exclusion_threshold or dropB<=exclusion_threshold\n",
        "      else 'borderline'\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for candidate in text_list:\n",
        "        (mA,_), (mB,_) = measure_two_neurons(candidate, layer, nA, nB)\n",
        "        dropA = (mA-baseA)/max(1e-9, baseA)\n",
        "        dropB = (mB-baseB)/max(1e-9, baseB)\n",
        "        if dropA >= inclusion_threshold and dropB >= inclusion_threshold:\n",
        "            label = \"positive\"\n",
        "        elif dropA <= exclusion_threshold or dropB <= exclusion_threshold:\n",
        "            label = \"negative\"\n",
        "        else:\n",
        "            label = \"borderline\"\n",
        "        results.append(dict(\n",
        "            candidate=candidate,\n",
        "            newA=mA, newB=mB,\n",
        "            dropA=dropA, dropB=dropB,\n",
        "            label=label\n",
        "        ))\n",
        "    return results\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# Main Execution\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "def run_multi_neuron_analysis():\n",
        "    # 1) Find top correlated pairs from big snippet set\n",
        "    top_pairs, corr = find_top_pairs_coactivation(model, LAYER_OF_INTEREST, ALL_SNIPPETS, top_k=3)\n",
        "    print(f\"\\nTop {len(top_pairs)} correlated neuron pairs in layer={LAYER_OF_INTEREST}:\")\n",
        "    for i,(cval,na,nb) in enumerate(top_pairs):\n",
        "        print(f\"  {i+1}) Neuron {na} & {nb}, correlation={cval:.4f}\")\n",
        "\n",
        "    if not top_pairs:\n",
        "        print(\"No pairs found. Possibly all activations are zero/cor=nan.\")\n",
        "        return\n",
        "\n",
        "    # pick the top pair\n",
        "    best_corr, best_nA, best_nB = top_pairs[0]\n",
        "    print(f\"\\nUsing Pair => neurons ({best_nA}, {best_nB}), correlation={best_corr:.4f}\")\n",
        "\n",
        "    # define some test snippets we want to interpret:\n",
        "    test_snippets = [\n",
        "       # if you want to reuse the \"pruned\" or \"non-pruned\" from single-neuron code\n",
        "       \" was put on the IUCN Red List under threatened species, to my surprise.\",\n",
        "       \" am not a native English speaker, but I have learned through practice.\",\n",
        "       \"The thought never even crossed my mind as I was driving home that day.\",\n",
        "       \" .](bjc201256f1){#fig1 depicts the chart clearly.\",\n",
        "       \"I realize that I'm nervous too, beyond the life-altering situation about to happen.\",\n",
        "    ]\n",
        "\n",
        "    # We'll do local expansions with DistilBERT\n",
        "    distilAug = ContextualAugmenter(aug_model, aug_tokenizer, model)\n",
        "\n",
        "    results = []\n",
        "    for snippet in test_snippets:\n",
        "        # measure original\n",
        "        (origA, idxA), (origB, idxB) = measure_two_neurons(snippet, LAYER_OF_INTEREST, best_nA, best_nB)\n",
        "        # do joint prune\n",
        "        pruned = joint_prune(snippet, LAYER_OF_INTEREST, best_nA, best_nB, proportion_threshold=-0.5)\n",
        "        if not pruned:\n",
        "            pruned = snippet\n",
        "        (newA, _), (newB, _) = measure_two_neurons(pruned, LAYER_OF_INTEREST, best_nA, best_nB)\n",
        "\n",
        "        # DistilBERT expansions\n",
        "        distil_texts, _ = distilAug.augment(pruned, n=3)  # you can tune n\n",
        "        # GPT expansions\n",
        "        gpt_texts = gpt_generation(pruned, num_return=3)\n",
        "\n",
        "        # measure expansions\n",
        "        distil_labeled = measure_and_label_candidates_2neurons(\n",
        "            distil_texts, LAYER_OF_INTEREST, best_nA, best_nB,\n",
        "            newA, newB\n",
        "        )\n",
        "        gpt_labeled = measure_and_label_candidates_2neurons(\n",
        "            gpt_texts, LAYER_OF_INTEREST, best_nA, best_nB,\n",
        "            newA, newB\n",
        "        )\n",
        "\n",
        "        snippet_out = {\n",
        "            \"snippet\": snippet,\n",
        "            \"originalA\": origA, \"originalB\": origB,\n",
        "            \"pruned_text\": pruned,\n",
        "            \"prunedA\": newA, \"prunedB\": newB,\n",
        "            \"distil_expansions\": distil_labeled,\n",
        "            \"gpt_expansions\": gpt_labeled,\n",
        "            \"anchorA_idx\": idxA,\n",
        "            \"anchorB_idx\": idxB\n",
        "        }\n",
        "        results.append(snippet_out)\n",
        "\n",
        "    # Print\n",
        "    for i, rep in enumerate(results):\n",
        "        print(\"\\n\"+\"=\"*60)\n",
        "        print(f\"Snippet {i+1}: {rep['snippet']}\")\n",
        "        print(f\"Neuron Pair = ({best_nA}, {best_nB}), originalActivations => A={rep['originalA']:.4f}, B={rep['originalB']:.4f}\")\n",
        "        print(f\"Pruned => {rep['pruned_text']}\")\n",
        "        print(f\"PrunedActivations => A={rep['prunedA']:.4f}, B={rep['prunedB']:.4f}\\n\")\n",
        "        print(\"DistilBERT expansions:\")\n",
        "        for d in rep[\"distil_expansions\"]:\n",
        "            print(f\"   Label={d['label'].upper()}  A_new={d['newA']:.4f}, B_new={d['newB']:.4f}, dropA={d['dropA']:.3f}, dropB={d['dropB']:.3f}\")\n",
        "            print(\"      ->\", d['candidate'])\n",
        "        print()\n",
        "        print(\"GPT expansions:\")\n",
        "        for d in rep[\"gpt_expansions\"]:\n",
        "            print(f\"   Label={d['label'].upper()}  A_new={d['newA']:.4f}, B_new={d['newB']:.4f}, dropA={d['dropA']:.3f}, dropB={d['dropB']:.3f}\")\n",
        "            print(\"      ->\", d['candidate'])\n",
        "        print(\"=\"*60,\"\\n\")\n",
        "\n",
        "\n",
        "# Run it now:\n",
        "run_multi_neuron_analysis()\n"
      ],
      "metadata": {
        "id": "hdZ3BUVj5WPs",
        "outputId": "4ec97cd5-0af8-4896-b374-2600431034ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model solu-8l-old into HookedTransformer\n",
            "Moving model to device:  cuda\n",
            "\n",
            "Top 3 correlated neuron pairs in layer=blocks.3.mlp.hook_mid:\n",
            "  1) Neuron 268 & 1867, correlation=1.0000\n",
            "  2) Neuron 990 & 3419, correlation=1.0000\n",
            "  3) Neuron 990 & 3898, correlation=1.0000\n",
            "\n",
            "Using Pair => neurons (268, 1867), correlation=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Snippet 1:  was put on the IUCN Red List under threatened species, to my surprise.\n",
            "Neuron Pair = (268, 1867), originalActivations => A=0.0028, B=0.0019\n",
            "Pruned =>  put on\n",
            "PrunedActivations => A=0.0020, B=0.0052\n",
            "\n",
            "DistilBERT expansions:\n",
            "   Label=NEGATIVE  A_new=0.0009, B_new=0.0002, dropA=-0.576, dropB=-0.967\n",
            "      ->  click on\n",
            "   Label=NEGATIVE  A_new=0.0000, B_new=0.0002, dropA=-0.989, dropB=-0.954\n",
            "      ->  based on\n",
            "   Label=NEGATIVE  A_new=-0.0000, B_new=0.0002, dropA=-1.015, dropB=-0.960\n",
            "      ->  variations on\n",
            "\n",
            "GPT expansions:\n",
            "   Label=NEGATIVE  A_new=0.0024, B_new=0.0001, dropA=0.200, dropB=-0.981\n",
            "      -> <?xml version=\"1.0\" encoding=\"utf-8\"?> <script type=\"\n",
            "   Label=NEGATIVE  A_new=0.0070, B_new=0.0005, dropA=2.461, dropB=-0.905\n",
            "      -> 1 1 -a\n",
            "\n",
            "1\n",
            "\n",
            "1 1\n",
            "\n",
            "1 1\n",
            "\n",
            "1 2\n",
            "   Label=NEGATIVE  A_new=0.0006, B_new=0.0002, dropA=-0.727, dropB=-0.954\n",
            "      -> <!DOCTYPE html> <html> <head> <title>The Big\n",
            "============================================================ \n",
            "\n",
            "\n",
            "============================================================\n",
            "Snippet 2:  am not a native English speaker, but I have learned through practice.\n",
            "Neuron Pair = (268, 1867), originalActivations => A=0.0001, B=0.0006\n",
            "Pruned =>  a\n",
            "PrunedActivations => A=0.0003, B=0.0009\n",
            "\n",
            "DistilBERT expansions:\n",
            "\n",
            "GPT expansions:\n",
            "   Label=POSITIVE  A_new=0.0010, B_new=0.0007, dropA=2.040, dropB=-0.271\n",
            "      -> {% load 'example.php', 'index.php' %}\n",
            "\n",
            "</head\n",
            "   Label=NEGATIVE  A_new=-0.0000, B_new=0.0000, dropA=-1.027, dropB=-0.988\n",
            "      -> If\n",
            "   Label=NEGATIVE  A_new=0.0035, B_new=0.0001, dropA=9.948, dropB=-0.922\n",
            "      -> {{#each({}, [a,b]}})\n",
            "\n",
            "{{#each({},\n",
            "============================================================ \n",
            "\n",
            "\n",
            "============================================================\n",
            "Snippet 3: The thought never even crossed my mind as I was driving home that day.\n",
            "Neuron Pair = (268, 1867), originalActivations => A=0.0019, B=0.0236\n",
            "Pruned =>  thought never even crossed my\n",
            "PrunedActivations => A=0.0012, B=0.0186\n",
            "\n",
            "DistilBERT expansions:\n",
            "   Label=NEGATIVE  A_new=0.0009, B_new=0.0008, dropA=-0.226, dropB=-0.957\n",
            "      ->  i never even crossed my\n",
            "   Label=NEGATIVE  A_new=0.0012, B_new=0.0032, dropA=0.050, dropB=-0.826\n",
            "      ->  he never even crossed my\n",
            "   Label=NEGATIVE  A_new=0.0014, B_new=0.0032, dropA=0.175, dropB=-0.830\n",
            "      ->  she never even crossed my\n",
            "   Label=POSITIVE  A_new=0.0017, B_new=0.0186, dropA=0.485, dropB=-0.000\n",
            "      ->  thought ##lessly even crossed my\n",
            "   Label=POSITIVE  A_new=0.0009, B_new=0.0186, dropA=-0.228, dropB=0.000\n",
            "      ->  thought had even crossed my\n",
            "   Label=BORDERLINE  A_new=0.0005, B_new=0.0186, dropA=-0.540, dropB=-0.000\n",
            "      ->  thought ##lessness even crossed my\n",
            "   Label=POSITIVE  A_new=0.0012, B_new=0.0186, dropA=0.075, dropB=0.000\n",
            "      ->  thought never before crossed my\n",
            "   Label=POSITIVE  A_new=0.0010, B_new=0.0186, dropA=-0.130, dropB=0.000\n",
            "      ->  thought never quite crossed my\n",
            "   Label=POSITIVE  A_new=0.0010, B_new=0.0186, dropA=-0.141, dropB=0.000\n",
            "      ->  thought never once crossed my\n",
            "   Label=POSITIVE  A_new=0.0100, B_new=0.0186, dropA=7.678, dropB=0.000\n",
            "      ->  thought never even touched my\n",
            "   Label=BORDERLINE  A_new=0.0008, B_new=0.0186, dropA=-0.325, dropB=-0.000\n",
            "      ->  thought never even penetrated my\n",
            "   Label=POSITIVE  A_new=0.0102, B_new=0.0186, dropA=7.827, dropB=0.000\n",
            "      ->  thought never even reached my\n",
            "\n",
            "GPT expansions:\n",
            "   Label=NEGATIVE  A_new=0.0004, B_new=0.0000, dropA=-0.619, dropB=-0.999\n",
            "      -> <a href=\"https://api.mydomain.com/\" class=\"simple-post-\n",
            "   Label=NEGATIVE  A_new=0.0003, B_new=0.0000, dropA=-0.743, dropB=-0.999\n",
            "      -> <meta itemprop=\"description\" content=\"<meta http-equiv=\"X-UA\n",
            "   Label=NEGATIVE  A_new=0.0005, B_new=0.0001, dropA=-0.597, dropB=-0.995\n",
            "      -> {$name = \"Wizard\"; $value = $string->replace('\\w',\n",
            "============================================================ \n",
            "\n",
            "\n",
            "============================================================\n",
            "Snippet 4:  .](bjc201256f1){#fig1 depicts the chart clearly.\n",
            "Neuron Pair = (268, 1867), originalActivations => A=0.0008, B=0.0011\n",
            "Pruned => ](bjc201256f1){#fig1 depicts the\n",
            "PrunedActivations => A=0.0011, B=0.0006\n",
            "\n",
            "DistilBERT expansions:\n",
            "   Label=BORDERLINE  A_new=0.0010, B_new=0.0003, dropA=-0.091, dropB=-0.427\n",
            "      -> (bjc201256f1){#fig1 depicts the\n",
            "   Label=BORDERLINE  A_new=0.0010, B_new=0.0002, dropA=-0.121, dropB=-0.676\n",
            "      -> {bjc201256f1){#fig1 depicts the\n",
            "   Label=NEGATIVE  A_new=0.0010, B_new=0.0002, dropA=-0.137, dropB=-0.729\n",
            "      -> #bjc201256f1){#fig1 depicts the\n",
            "   Label=POSITIVE  A_new=0.0009, B_new=0.0006, dropA=-0.222, dropB=-0.000\n",
            "      -> ](file){#fig1 depicts the\n",
            "   Label=POSITIVE  A_new=0.0012, B_new=0.0006, dropA=0.070, dropB=-0.000\n",
            "      -> ](3){#fig1 depicts the\n",
            "   Label=POSITIVE  A_new=0.0012, B_new=0.0006, dropA=0.121, dropB=-0.000\n",
            "      -> ](8){#fig1 depicts the\n",
            "   Label=POSITIVE  A_new=0.0009, B_new=0.0006, dropA=-0.215, dropB=0.000\n",
            "      -> ](bjc201256f1)fig1 depicts the\n",
            "   Label=BORDERLINE  A_new=0.0005, B_new=0.0006, dropA=-0.521, dropB=0.000\n",
            "      -> ](bjc201256f1]fig1 depicts the\n",
            "   Label=BORDERLINE  A_new=0.0006, B_new=0.0006, dropA=-0.427, dropB=0.000\n",
            "      -> ](bjc201256f1}fig1 depicts the\n",
            "   Label=POSITIVE  A_new=0.0009, B_new=0.0006, dropA=-0.217, dropB=0.000\n",
            "      -> ](bjc201256f1){#} depicts the\n",
            "   Label=POSITIVE  A_new=0.0008, B_new=0.0006, dropA=-0.263, dropB=0.000\n",
            "      -> ](bjc201256f1){#] depicts the\n",
            "   Label=BORDERLINE  A_new=0.0003, B_new=0.0006, dropA=-0.692, dropB=0.000\n",
            "      -> ](bjc201256f1){## depicts the\n",
            "   Label=BORDERLINE  A_new=0.0004, B_new=0.0006, dropA=-0.680, dropB=0.000\n",
            "      -> ](bjc201256f1){#fig1 } the\n",
            "   Label=NEGATIVE  A_new=0.0003, B_new=0.0007, dropA=-0.759, dropB=0.142\n",
            "      -> ](bjc201256f1){#fig1 | the\n",
            "   Label=NEGATIVE  A_new=0.0003, B_new=0.0006, dropA=-0.754, dropB=0.000\n",
            "      -> ](bjc201256f1){#fig1 ] the\n",
            "\n",
            "GPT expansions:\n",
            "   Label=NEGATIVE  A_new=0.0002, B_new=0.0001, dropA=-0.861, dropB=-0.775\n",
            "      -> # different than this\n",
            "\n",
            "if\n",
            "   Label=BORDERLINE  A_new=0.0025, B_new=0.0002, dropA=1.233, dropB=-0.673\n",
            "      -> [{\n",
            "\n",
            "return (<p>\n",
            "\n",
            "<p>Your message is in your\n",
            "   Label=BORDERLINE  A_new=0.0004, B_new=0.0002, dropA=-0.616, dropB=-0.676\n",
            "      -> { \"cid\": \"4f5e88a-34c5-4c\n",
            "============================================================ \n",
            "\n",
            "\n",
            "============================================================\n",
            "Snippet 5: I realize that I'm nervous too, beyond the life-altering situation about to happen.\n",
            "Neuron Pair = (268, 1867), originalActivations => A=0.0007, B=0.0020\n",
            "Pruned =>  realize\n",
            "PrunedActivations => A=0.0009, B=0.0026\n",
            "\n",
            "DistilBERT expansions:\n",
            "   Label=NEGATIVE  A_new=0.0001, B_new=0.0002, dropA=-0.942, dropB=-0.927\n",
            "      ->  •\n",
            "   Label=NEGATIVE  A_new=0.0000, B_new=0.0004, dropA=-0.994, dropB=-0.855\n",
            "      ->  ·\n",
            "   Label=NEGATIVE  A_new=-0.0000, B_new=0.0001, dropA=-1.015, dropB=-0.980\n",
            "      ->  .\n",
            "\n",
            "GPT expansions:\n",
            "   Label=NEGATIVE  A_new=-0.0000, B_new=0.0000, dropA=-1.034, dropB=-0.996\n",
            "      -> \n",
            "   Label=NEGATIVE  A_new=0.0003, B_new=0.0003, dropA=-0.665, dropB=-0.898\n",
            "      -> { }\n",
            "\n",
            "Rewrite::operator() => ({ \"error\": { \"code\": \"\n",
            "   Label=NEGATIVE  A_new=0.0013, B_new=0.0000, dropA=0.489, dropB=-0.995\n",
            "      -> <link rel=\"stylesheet\" href=\"https://s3.amazonaws.com/\n",
            "============================================================ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L1HPJX8F7cEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}