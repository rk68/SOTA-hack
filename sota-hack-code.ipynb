{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2c59f6449764624b899bf062069cdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cff84f57a4540ed99d0631a214dd0cc",
              "IPY_MODEL_b187a7d48e364e809acbabcdc7e9f383",
              "IPY_MODEL_e174bc147b614ae08fb6060d41a64a6c"
            ],
            "layout": "IPY_MODEL_94eb556399f74944b6e9dc085f06f177"
          }
        },
        "7cff84f57a4540ed99d0631a214dd0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4ed8239b35b41e39d1c5f7e30632a7c",
            "placeholder": "​",
            "style": "IPY_MODEL_035c8632b7f74b0995049e75a451564c",
            "value": "config.json: 100%"
          }
        },
        "b187a7d48e364e809acbabcdc7e9f383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a4484a3fb604bc89ce9c7e8a61f4f11",
            "max": 767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6af3150b1bdd483bafdc37af9fc34e42",
            "value": 767
          }
        },
        "e174bc147b614ae08fb6060d41a64a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59276f8195fa4698aa661e701a1aa434",
            "placeholder": "​",
            "style": "IPY_MODEL_b77ffc39445b433d9e7f0d73f35dfad2",
            "value": " 767/767 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "94eb556399f74944b6e9dc085f06f177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ed8239b35b41e39d1c5f7e30632a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035c8632b7f74b0995049e75a451564c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a4484a3fb604bc89ce9c7e8a61f4f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af3150b1bdd483bafdc37af9fc34e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59276f8195fa4698aa661e701a1aa434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77ffc39445b433d9e7f0d73f35dfad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12afc678a2be4bb0869c524444e33caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7d446b093144e21a3c5d89e409483a0",
              "IPY_MODEL_52d810c8ca6842b68961bae0aa6a6698",
              "IPY_MODEL_861c61376642403a87329fb809547a67"
            ],
            "layout": "IPY_MODEL_b0231ea18bb14d0882f69ef6b8601608"
          }
        },
        "a7d446b093144e21a3c5d89e409483a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_705a0d45317542f0a8f761a77f59b542",
            "placeholder": "​",
            "style": "IPY_MODEL_c1523a8ce2dc4c88a3309714fd01440a",
            "value": "SoLU_8L_v21_final.pth: 100%"
          }
        },
        "52d810c8ca6842b68961bae0aa6a6698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afacfede38334a3894a77fe45765e836",
            "max": 827868535,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa80bcb902734100af4baf2d807a85ae",
            "value": 827868535
          }
        },
        "861c61376642403a87329fb809547a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76384d70fbc646ec8f6c430eb39fe656",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac24e90cf6d4892995ade19717e658b",
            "value": " 828M/828M [00:10&lt;00:00, 96.2MB/s]"
          }
        },
        "b0231ea18bb14d0882f69ef6b8601608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705a0d45317542f0a8f761a77f59b542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1523a8ce2dc4c88a3309714fd01440a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afacfede38334a3894a77fe45765e836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa80bcb902734100af4baf2d807a85ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76384d70fbc646ec8f6c430eb39fe656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac24e90cf6d4892995ade19717e658b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f7032b45797420fb07c9f520659d11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c87f8994fb3a40cdafd24307060c670f",
              "IPY_MODEL_43cb92a5f9c947d8a3696b0e7b5932db",
              "IPY_MODEL_1d659bb2c48e4c4a97228bf67b76d1f1"
            ],
            "layout": "IPY_MODEL_5b2adbc7784d4d389be0c3e41916152f"
          }
        },
        "c87f8994fb3a40cdafd24307060c670f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb84d6b29655483781d9a42ad26a60d1",
            "placeholder": "​",
            "style": "IPY_MODEL_7f5c23c3681f4e068a5a1f9f031b7cc0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "43cb92a5f9c947d8a3696b0e7b5932db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfaa876a3524c658fe680c3321c4294",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fd42d584760485e9bb4ccf12de0a9ea",
            "value": 156
          }
        },
        "1d659bb2c48e4c4a97228bf67b76d1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e49289bf59f491daf57ebf90c92f10e",
            "placeholder": "​",
            "style": "IPY_MODEL_411fb4c2b2f342689fe5bad217136eb8",
            "value": " 156/156 [00:00&lt;00:00, 2.98kB/s]"
          }
        },
        "5b2adbc7784d4d389be0c3e41916152f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb84d6b29655483781d9a42ad26a60d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5c23c3681f4e068a5a1f9f031b7cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acfaa876a3524c658fe680c3321c4294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd42d584760485e9bb4ccf12de0a9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e49289bf59f491daf57ebf90c92f10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411fb4c2b2f342689fe5bad217136eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a58505053a15494d9d491de870211656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f9ec63b21864156a0edb24eb34d04a3",
              "IPY_MODEL_d4592fe22d5841f0a24652dbb7829c0a",
              "IPY_MODEL_76f770f6592e41cf8cc84aca3a346de6"
            ],
            "layout": "IPY_MODEL_fbb1dc29bc084651bc5eee748f425988"
          }
        },
        "3f9ec63b21864156a0edb24eb34d04a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a77f839daf5e46f5b1c7c76cb756cd77",
            "placeholder": "​",
            "style": "IPY_MODEL_5acb52c1b8f34aaf8395d1b334f9d1fc",
            "value": "vocab.json: 100%"
          }
        },
        "d4592fe22d5841f0a24652dbb7829c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21bedb4abc84cecb4dee5196b1e1299",
            "max": 1077392,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f533ff612cc044f4b316edfa4278b375",
            "value": 1077392
          }
        },
        "76f770f6592e41cf8cc84aca3a346de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd068762d39495daa91f8cc1765b655",
            "placeholder": "​",
            "style": "IPY_MODEL_5bfdddbea3004e0cba7f1b5c1c040882",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 8.09MB/s]"
          }
        },
        "fbb1dc29bc084651bc5eee748f425988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a77f839daf5e46f5b1c7c76cb756cd77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5acb52c1b8f34aaf8395d1b334f9d1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b21bedb4abc84cecb4dee5196b1e1299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f533ff612cc044f4b316edfa4278b375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebd068762d39495daa91f8cc1765b655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfdddbea3004e0cba7f1b5c1c040882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d1d76ca6144d1aac6aec57033c9147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14c821fcb6104824b2c7d0b6f58b9bf4",
              "IPY_MODEL_cf93df811c1848d7921a2e59e415e653",
              "IPY_MODEL_091caee05777453584b2536427b5aa9b"
            ],
            "layout": "IPY_MODEL_c0c3986466d84b54a08b180b2fb4a911"
          }
        },
        "14c821fcb6104824b2c7d0b6f58b9bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8210be793ef9438daecf52fb56032e1f",
            "placeholder": "​",
            "style": "IPY_MODEL_8c816d5b5ae74dd8b038ce647d52467f",
            "value": "merges.txt: 100%"
          }
        },
        "cf93df811c1848d7921a2e59e415e653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d5f96f8d4442488fc8ace0951dde07",
            "max": 456583,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_251c53d98437427a85aed3256c91886b",
            "value": 456583
          }
        },
        "091caee05777453584b2536427b5aa9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a25d433b0224f84be4809357b550e94",
            "placeholder": "​",
            "style": "IPY_MODEL_33916d941e00410689e540fc28464bfd",
            "value": " 457k/457k [00:00&lt;00:00, 3.71MB/s]"
          }
        },
        "c0c3986466d84b54a08b180b2fb4a911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8210be793ef9438daecf52fb56032e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c816d5b5ae74dd8b038ce647d52467f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93d5f96f8d4442488fc8ace0951dde07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251c53d98437427a85aed3256c91886b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a25d433b0224f84be4809357b550e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33916d941e00410689e540fc28464bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "187fdac9207942fb8116ef50eb5f3586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64f213718570425499c8cfbb1ea59235",
              "IPY_MODEL_4443aa8856234b2d8b6dea52859b3347",
              "IPY_MODEL_21dbfc9fb4d242358c34539d8c54cba3"
            ],
            "layout": "IPY_MODEL_d2ed0f7c4ee44983bc3ef11fa23c0d66"
          }
        },
        "64f213718570425499c8cfbb1ea59235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_181572be26524d25b81a82d400bf8e29",
            "placeholder": "​",
            "style": "IPY_MODEL_30d614ef2177488b9e43f3adf0707c12",
            "value": "tokenizer.json: 100%"
          }
        },
        "4443aa8856234b2d8b6dea52859b3347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e8fdda9c17493e88ba0e4d99eeec9d",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f10b6e9b5624f67ade73f6fd93d7d57",
            "value": 2113710
          }
        },
        "21dbfc9fb4d242358c34539d8c54cba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee474d590834522a69ba79b34b43be6",
            "placeholder": "​",
            "style": "IPY_MODEL_98e5224f702a415f90f3480cdde938e5",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "d2ed0f7c4ee44983bc3ef11fa23c0d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "181572be26524d25b81a82d400bf8e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d614ef2177488b9e43f3adf0707c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02e8fdda9c17493e88ba0e4d99eeec9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f10b6e9b5624f67ade73f6fd93d7d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ee474d590834522a69ba79b34b43be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e5224f702a415f90f3480cdde938e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6120ed2a712a4467b9038c78ce0e2d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_925b6b5c6a9b432d83b551adfdec6d0e",
              "IPY_MODEL_bcc48a2bf3d347148b4912011c38f826",
              "IPY_MODEL_0501d3ee5db040689fe5a948c83cb674"
            ],
            "layout": "IPY_MODEL_842e29a1629b4493935061f7f6fd4384"
          }
        },
        "925b6b5c6a9b432d83b551adfdec6d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11be8ec272764eba94e6bb30836ef363",
            "placeholder": "​",
            "style": "IPY_MODEL_b1d9a9ac18184412bfb1a88cdd905d92",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "bcc48a2bf3d347148b4912011c38f826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d6697d5da194e85be1b65eb665d9ac1",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78611720f20f47829ece180564f4d375",
            "value": 90
          }
        },
        "0501d3ee5db040689fe5a948c83cb674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c88de3f2bf1482486769cee19af42a8",
            "placeholder": "​",
            "style": "IPY_MODEL_fe6fee8a87b846de8f05fc498837f161",
            "value": " 90.0/90.0 [00:00&lt;00:00, 5.76kB/s]"
          }
        },
        "842e29a1629b4493935061f7f6fd4384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11be8ec272764eba94e6bb30836ef363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1d9a9ac18184412bfb1a88cdd905d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d6697d5da194e85be1b65eb665d9ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78611720f20f47829ece180564f4d375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c88de3f2bf1482486769cee19af42a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6fee8a87b846de8f05fc498837f161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe3198e6d534415a59925d48297c5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b370130b7854e4b948137616ff27ca2",
              "IPY_MODEL_90b2bb9ddb3044d3b60f99860b911c07",
              "IPY_MODEL_89ce9735ddbe47e2a6ba800fc7d8a2bc"
            ],
            "layout": "IPY_MODEL_8b028ec711814a31918ecc737842febf"
          }
        },
        "5b370130b7854e4b948137616ff27ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6687556f56d54e1ea7b120b3ae9f596e",
            "placeholder": "​",
            "style": "IPY_MODEL_604886b115584c158de2cfe2aef26009",
            "value": "config.json: 100%"
          }
        },
        "90b2bb9ddb3044d3b60f99860b911c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa35d84e07894963aabd23ea196b0a75",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbba856676b14be69ca9df425999535e",
            "value": 483
          }
        },
        "89ce9735ddbe47e2a6ba800fc7d8a2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b98a44690e6c4e13a590305ae5138928",
            "placeholder": "​",
            "style": "IPY_MODEL_e07fadc538504408870ce34ca959b25d",
            "value": " 483/483 [00:00&lt;00:00, 32.1kB/s]"
          }
        },
        "8b028ec711814a31918ecc737842febf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6687556f56d54e1ea7b120b3ae9f596e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604886b115584c158de2cfe2aef26009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa35d84e07894963aabd23ea196b0a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbba856676b14be69ca9df425999535e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b98a44690e6c4e13a590305ae5138928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07fadc538504408870ce34ca959b25d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44ca027c6bca40d9950af2fc317e3f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_860efee2c4544efc9c4ccf5daa53db62",
              "IPY_MODEL_18d6ac9ea01b4913ba0f11f4d1bbc7cf",
              "IPY_MODEL_cacfe9ade35d4192a0e6e2e0a7785a7b"
            ],
            "layout": "IPY_MODEL_c060b2d3634647e086f7f24b40721e73"
          }
        },
        "860efee2c4544efc9c4ccf5daa53db62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714753c470364fd88619f597c86f3a74",
            "placeholder": "​",
            "style": "IPY_MODEL_b437aee6f1bf48f2b0bd8946f25deb28",
            "value": "model.safetensors: 100%"
          }
        },
        "18d6ac9ea01b4913ba0f11f4d1bbc7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f33f6cca89432ba9724520fa3dfe44",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b60c1f91555e4ee58f3f5bbe1b649cac",
            "value": 267954768
          }
        },
        "cacfe9ade35d4192a0e6e2e0a7785a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbd2d14ad734c4092d1bf726cb18215",
            "placeholder": "​",
            "style": "IPY_MODEL_6d1aaea96f644c518924b41d41c3fdd3",
            "value": " 268M/268M [00:01&lt;00:00, 191MB/s]"
          }
        },
        "c060b2d3634647e086f7f24b40721e73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714753c470364fd88619f597c86f3a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b437aee6f1bf48f2b0bd8946f25deb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2f33f6cca89432ba9724520fa3dfe44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60c1f91555e4ee58f3f5bbe1b649cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fbd2d14ad734c4092d1bf726cb18215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1aaea96f644c518924b41d41c3fdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "256cb59c0cc9496d959e47639801d885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e9ee166245d4f2a949020142be816a0",
              "IPY_MODEL_526be9bad92e4c1ca2f1f51956c42a82",
              "IPY_MODEL_bd266f07b25c4de79b88dfecaa9b574f"
            ],
            "layout": "IPY_MODEL_42d82908ec804884801b842091a40a60"
          }
        },
        "3e9ee166245d4f2a949020142be816a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e8505d2f944f65a8a0d1d6df402dcb",
            "placeholder": "​",
            "style": "IPY_MODEL_0330e64740d444b2a823c0de4f257b5c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "526be9bad92e4c1ca2f1f51956c42a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4cd7d9e94854ec380d6818aad6a2b4e",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22f34cbdcd884e428c5861ec3a7cccdc",
            "value": 48
          }
        },
        "bd266f07b25c4de79b88dfecaa9b574f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb5104ec619c4337a709df9a35303ae3",
            "placeholder": "​",
            "style": "IPY_MODEL_64c6cf95c5a34e0894f06f3d7967549a",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.07kB/s]"
          }
        },
        "42d82908ec804884801b842091a40a60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0e8505d2f944f65a8a0d1d6df402dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0330e64740d444b2a823c0de4f257b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4cd7d9e94854ec380d6818aad6a2b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f34cbdcd884e428c5861ec3a7cccdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb5104ec619c4337a709df9a35303ae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c6cf95c5a34e0894f06f3d7967549a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931408006b614426af136166a0445eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_707d6b94f69d43edadc869cc2279d7a9",
              "IPY_MODEL_c1aaf59d86304f798cdf8332ae79752a",
              "IPY_MODEL_358a2e86086a4560bdc94c43812bc9e6"
            ],
            "layout": "IPY_MODEL_17de8dac4182475aa74dece6eb128bc1"
          }
        },
        "707d6b94f69d43edadc869cc2279d7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f0a76d2d244ab9921eb54344e0d3f6",
            "placeholder": "​",
            "style": "IPY_MODEL_eb22eb1208ac4bfbb77fc19a2d14da14",
            "value": "vocab.txt: 100%"
          }
        },
        "c1aaf59d86304f798cdf8332ae79752a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70673e8815a478aa6cd34688952ec10",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75226eec7f70456a8ab6f1d78261edcb",
            "value": 231508
          }
        },
        "358a2e86086a4560bdc94c43812bc9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f67ab83ff145558e756c12832e81e5",
            "placeholder": "​",
            "style": "IPY_MODEL_ab09b71b87dc4d38bd72be371519bc10",
            "value": " 232k/232k [00:00&lt;00:00, 13.4MB/s]"
          }
        },
        "17de8dac4182475aa74dece6eb128bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f0a76d2d244ab9921eb54344e0d3f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb22eb1208ac4bfbb77fc19a2d14da14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b70673e8815a478aa6cd34688952ec10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75226eec7f70456a8ab6f1d78261edcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98f67ab83ff145558e756c12832e81e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab09b71b87dc4d38bd72be371519bc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5120496fb7242b487e890a5e1e4302a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_924ff429ca5c4a648b17085beb2e77fd",
              "IPY_MODEL_fa84937a9c9b4d9ba7fab4f89f8e64fb",
              "IPY_MODEL_dd0ee63428db4031b27cdd3abf5e36ac"
            ],
            "layout": "IPY_MODEL_ce7f92a343d84eab9a6183387e520c23"
          }
        },
        "924ff429ca5c4a648b17085beb2e77fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0eeb8a18db4465780369fbf2c24cee7",
            "placeholder": "​",
            "style": "IPY_MODEL_adbfc5c8a77741b39d5a97bac3326756",
            "value": "tokenizer.json: 100%"
          }
        },
        "fa84937a9c9b4d9ba7fab4f89f8e64fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49532d6c320a4877ac1d7a6b3098dd26",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_841f0e3d66124ce9944a95c22894da73",
            "value": 466062
          }
        },
        "dd0ee63428db4031b27cdd3abf5e36ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f08de6d9b904cab82f5cc51429abb9b",
            "placeholder": "​",
            "style": "IPY_MODEL_93211bcf245245919309e6e1f733789a",
            "value": " 466k/466k [00:00&lt;00:00, 3.50MB/s]"
          }
        },
        "ce7f92a343d84eab9a6183387e520c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0eeb8a18db4465780369fbf2c24cee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbfc5c8a77741b39d5a97bac3326756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49532d6c320a4877ac1d7a6b3098dd26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "841f0e3d66124ce9944a95c22894da73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f08de6d9b904cab82f5cc51429abb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93211bcf245245919309e6e1f733789a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Og88PwkTXo-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformer_lens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khMzKnDkaBB8",
        "outputId": "c10eb6b9-0072-4518-e1fa-901076683f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.11.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.2.1)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.8.0)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.2.36-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.47.1)\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.11.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer_lens) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37.2->transformer_lens) (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.25.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.10.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Downloading transformer_lens-2.11.0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.2.36-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: better-abc, xxhash, jaxtyping, fsspec, fancy-einsum, dill, beartype, multiprocess, datasets, transformer_lens\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.2.0 dill-0.3.8 fancy-einsum-0.0.3 fsspec-2024.9.0 jaxtyping-0.2.36 multiprocess-0.70.16 transformer_lens-2.11.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "# from google.colab import drive\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from functools import *\n",
        "import pandas as pd\n",
        "import gc\n",
        "import collections\n",
        "import copy\n",
        "\n",
        "# import comet_ml\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets"
      ],
      "metadata": {
        "id": "q8XmZlmOUtoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pv-WbMWZxXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformer_lens.utils import (\n",
        "    gelu_new,\n",
        "    to_numpy,\n",
        "    get_corner,\n",
        "    lm_cross_entropy_loss,\n",
        ")  # Helper functions\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import EasyTransformer, EasyTransformerConfig\n",
        "import transformer_lens\n",
        "# from transformer_lens.experiments import (\n",
        "#     ExperimentMetric,\n",
        "#     AblationConfig,\n",
        "#     EasyAblation,\n",
        "#     EasyPatching,\n",
        "#     PatchingConfig,\n",
        "# )"
      ],
      "metadata": {
        "id": "_DZmDwTSUjwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "wG5dKXVyVExr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model_name = \"solu-8l-old\"\n",
        "model = EasyTransformer.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472,
          "referenced_widgets": [
            "c2c59f6449764624b899bf062069cdc4",
            "7cff84f57a4540ed99d0631a214dd0cc",
            "b187a7d48e364e809acbabcdc7e9f383",
            "e174bc147b614ae08fb6060d41a64a6c",
            "94eb556399f74944b6e9dc085f06f177",
            "e4ed8239b35b41e39d1c5f7e30632a7c",
            "035c8632b7f74b0995049e75a451564c",
            "7a4484a3fb604bc89ce9c7e8a61f4f11",
            "6af3150b1bdd483bafdc37af9fc34e42",
            "59276f8195fa4698aa661e701a1aa434",
            "b77ffc39445b433d9e7f0d73f35dfad2",
            "12afc678a2be4bb0869c524444e33caf",
            "a7d446b093144e21a3c5d89e409483a0",
            "52d810c8ca6842b68961bae0aa6a6698",
            "861c61376642403a87329fb809547a67",
            "b0231ea18bb14d0882f69ef6b8601608",
            "705a0d45317542f0a8f761a77f59b542",
            "c1523a8ce2dc4c88a3309714fd01440a",
            "afacfede38334a3894a77fe45765e836",
            "aa80bcb902734100af4baf2d807a85ae",
            "76384d70fbc646ec8f6c430eb39fe656",
            "5ac24e90cf6d4892995ade19717e658b",
            "8f7032b45797420fb07c9f520659d11d",
            "c87f8994fb3a40cdafd24307060c670f",
            "43cb92a5f9c947d8a3696b0e7b5932db",
            "1d659bb2c48e4c4a97228bf67b76d1f1",
            "5b2adbc7784d4d389be0c3e41916152f",
            "eb84d6b29655483781d9a42ad26a60d1",
            "7f5c23c3681f4e068a5a1f9f031b7cc0",
            "acfaa876a3524c658fe680c3321c4294",
            "6fd42d584760485e9bb4ccf12de0a9ea",
            "8e49289bf59f491daf57ebf90c92f10e",
            "411fb4c2b2f342689fe5bad217136eb8",
            "a58505053a15494d9d491de870211656",
            "3f9ec63b21864156a0edb24eb34d04a3",
            "d4592fe22d5841f0a24652dbb7829c0a",
            "76f770f6592e41cf8cc84aca3a346de6",
            "fbb1dc29bc084651bc5eee748f425988",
            "a77f839daf5e46f5b1c7c76cb756cd77",
            "5acb52c1b8f34aaf8395d1b334f9d1fc",
            "b21bedb4abc84cecb4dee5196b1e1299",
            "f533ff612cc044f4b316edfa4278b375",
            "ebd068762d39495daa91f8cc1765b655",
            "5bfdddbea3004e0cba7f1b5c1c040882",
            "33d1d76ca6144d1aac6aec57033c9147",
            "14c821fcb6104824b2c7d0b6f58b9bf4",
            "cf93df811c1848d7921a2e59e415e653",
            "091caee05777453584b2536427b5aa9b",
            "c0c3986466d84b54a08b180b2fb4a911",
            "8210be793ef9438daecf52fb56032e1f",
            "8c816d5b5ae74dd8b038ce647d52467f",
            "93d5f96f8d4442488fc8ace0951dde07",
            "251c53d98437427a85aed3256c91886b",
            "4a25d433b0224f84be4809357b550e94",
            "33916d941e00410689e540fc28464bfd",
            "187fdac9207942fb8116ef50eb5f3586",
            "64f213718570425499c8cfbb1ea59235",
            "4443aa8856234b2d8b6dea52859b3347",
            "21dbfc9fb4d242358c34539d8c54cba3",
            "d2ed0f7c4ee44983bc3ef11fa23c0d66",
            "181572be26524d25b81a82d400bf8e29",
            "30d614ef2177488b9e43f3adf0707c12",
            "02e8fdda9c17493e88ba0e4d99eeec9d",
            "3f10b6e9b5624f67ade73f6fd93d7d57",
            "2ee474d590834522a69ba79b34b43be6",
            "98e5224f702a415f90f3480cdde938e5",
            "6120ed2a712a4467b9038c78ce0e2d54",
            "925b6b5c6a9b432d83b551adfdec6d0e",
            "bcc48a2bf3d347148b4912011c38f826",
            "0501d3ee5db040689fe5a948c83cb674",
            "842e29a1629b4493935061f7f6fd4384",
            "11be8ec272764eba94e6bb30836ef363",
            "b1d9a9ac18184412bfb1a88cdd905d92",
            "1d6697d5da194e85be1b65eb665d9ac1",
            "78611720f20f47829ece180564f4d375",
            "2c88de3f2bf1482486769cee19af42a8",
            "fe6fee8a87b846de8f05fc498837f161"
          ]
        },
        "id": "W416JfwYVEzx",
        "outputId": "c17f4fd4-c173-4a1e-e1e4-d9cefe4e49d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/767 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2c59f6449764624b899bf062069cdc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SoLU_8L_v21_final.pth:   0%|          | 0.00/828M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12afc678a2be4bb0869c524444e33caf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f7032b45797420fb07c9f520659d11d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a58505053a15494d9d491de870211656"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/457k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33d1d76ca6144d1aac6aec57033c9147"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "187fdac9207942fb8116ef50eb5f3586"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6120ed2a712a4467b9038c78ce0e2d54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model solu-8l-old into HookedTransformer\n",
            "Moving model to device:  cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning"
      ],
      "metadata": {
        "id": "ox_8QsnsYkIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_3_1 = [\n",
        "    \"\"\"\n",
        "\"I will. Same to you.\"\n",
        "\n",
        "He tells me that he loves me, and then I hang up just as I arrive at Wes's house.\n",
        "\n",
        "I park in the driveway next to his bike, not bothering to hide my Jeep down the road like usual. I know all about our past, and frankly, now that Wes knows too, his mother's threats are useless. She can't bully me out of Wes's life.\n",
        "\n",
        "I've made mistakes, not all of them completely my fault, but I can try not to make any more. I'm not sure where we stand relationship-wise, but we'll figure it out. We might even make the right decisions this time. For now, we just have to save the world. No pressure.\n",
        "\n",
        "I quickly dial Nathan, but he doesn't answer, making me nervous. I tell him to call me back, and that I'm at Wes's house. I push the phone into my pocket and climb out of the Jeep.\n",
        "\n",
        "Wes waits for me at his door, smiling and looking a little nervous. I wonder if he thought I was going to turn onto the freeway and drive away instead of coming here. The thought didn't even cross my mind. I would have followed him anywhere.\n",
        "\n",
        "\"Parents aren't home,\" he says, watching my approach. \"In case you were worried.\"\n",
        "\n",
        "\"Now you won't have to lock the door,\" I say, and stop in front of him.\n",
        "\n",
        "Wes's smile fades. \"I always lock the door,\" he replies, and turns to push inside his basement apartment.\n",
        "\n",
        "I realize that I'm nervous too. Beyond the life-altering shit that's about to go down with The Program—I'm here with Wes. And I'm still not entirely sure how to act.\n",
        "\n",
        "I understand what Michael Realm meant now, how remembering can be a curse. Because I remember things that Wes doesn't. I remember how much he loved me. How much I loved him. The stuff they couldn't take. The stuff that crashed back. So much history, and now it's only mine.\n",
        "\n",
        "I walk inside his room and close the door behind me. It's dimly lit, the high-set window not enough on a darkened, stormy day. But Wes doesn't flip on the lights as he leads us into the living room area.\n",
        "\n",
        "I sit on the couch, and Wes comes to the coffee table and turns his laptop in my direction before telling me he'll be right back. He jogs up the stairs and disappears inside his house.\n",
        "\n",
        "I smile at the wallpaper on his computer, a vintage motorcycle, mid-repair. It's simple, honest. I click open the browser, and his last page pulls up. It's a board called Survivor Rate, and the quick description says it's a forum for survivors of the epidemic. It has over ten thousand members.\n",
        "\n",
        "I click on the first thread and start to read through, when I hear Wes close the door and lock it before bounding down the stairs. I look up, and he holds out a bag of frozen peas.\n",
        "\n",
        "\"For your head,\" he says. \"I tried to find an aspirin, but my mom won't keep any pills in the house.\"\n",
        "\n",
        "\"Oh,\" I say, taking the icy bag from him. \"Thank you.\" It's kind of sweet of him to do that without me asking. I move my legs aside as he scoots past me and drops down onto the couch in his usual spot. I gently press the peas to my head, groaning at the pressure.\n",
        "\n",
        "\"This is the one,\" Wes starts, turning the screen so he can see it too, \"where the guy had the picture of Michael.\"\n",
        "\n",
        "\"He goes by Realm,\" I say, and feel Wes turn to me. I point at the screen to move forward. \"Can I see the picture?\"\n",
        "\n",
        "\"Sure,\" Wes replies, and clicks into a different thread, scrolling through posts. He double-clicks one. \"Here you go. That's him, right?\"\n",
        "\n",
        "And it is. There's a picture of Realm, not looking at the camera. He's partially turned away, his scar prominent on his neck. He doesn't seem to know his picture is being taken, and I'm reminded of Melody and how she never wanted to be in any photos. She always found an excuse. It was probably because she was a handler, a closer, and she didn't want to be recognized. She didn't want a record of being Jana Simms.\n",
        "\n",
        "\"That's definitely him,\" I say. Under the picture, the post reads: Anyone know this guy?\n",
        "\n",
        "Wes goes into the private messages and shows me his exchange with the original poster. It doesn't give us any information on locating Realm,\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "to the human analyte enzyme in its native matrix (eg serum); iii) and the inter-method ratio should be constant (within the limits of experimental error) for the enzyme calibrator and for all patients' samples.<|endoftext|>Q:\n",
        "\n",
        "Render named children in React component?\n",
        "\n",
        "I have a modal component which take a trigger to open the modal, and the content to go inside the modal.\n",
        "<Modal>\n",
        "  <button className=\"btn btn--primary\">Open modalbutton>\n",
        "  <div>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  div>\n",
        "Modal>\n",
        "\n",
        "And in the Modal component:\n",
        "  return (\n",
        "    <div className=\"Modal\">\n",
        "      {props.children[0]}\n",
        "      <div className=\"Modal__container\">\n",
        "        <div className=\"Modal__header\">\n",
        "          <button className=\"Modal__close btn btn--secondary btn--small\">\n",
        "            Close\n",
        "          button>\n",
        "          <h1 className=\"Modal__heading\">Here is my modalh1>\n",
        "        div>\n",
        "        <div className=\"Modal__content\">{props.children[1]}div>\n",
        "      div>\n",
        "    div>\n",
        "  );\n",
        "\n",
        "This is working but very fragile as Im using an index on props.children. Can I instead name the components I pass to Modal? So something like:\n",
        "<Modal>\n",
        "  <Modal.Trigger>\n",
        "    <button className=\"btn btn--primary\">Open modalbutton>\n",
        "  Modal.Trigger>\n",
        "  <Modal.Content>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  Modal.Content>\n",
        "Modal>\n",
        "\n",
        "A:\n",
        "\n",
        "I suggest you use props instead:\n",
        "declare your Modal like so:\n",
        "<Modal action={<button className=\"btn btn--primary\">Open modalbutton>}>\n",
        "  <div>\n",
        "    <p>Modal contentp>\n",
        "    <p>More modal contentp>\n",
        "  div>\n",
        "Modal>\n",
        "\n",
        "and your render method will then look something like\n",
        "return (\n",
        "  <div className=\"Modal\">\n",
        "    {props.action}\n",
        "    <div className=\"Modal__container\">\n",
        "      <div className=\"Modal__header\">\n",
        "        <button className=\"Modal__close btn btn--secondary btn--small\">\n",
        "          Close\n",
        "        button>\n",
        "        <h1 className=\"Modal__heading\">Here is my modalh1>\n",
        "      div>\n",
        "      <div className=\"Modal__content\">{props.children[1]}div>\n",
        "    div>\n",
        "  div>\n",
        ");\n",
        "\n",
        "<|endoftext|>A man told Dr. Phil on his show yesterday that he might have to kill his own child to protect his wife. His 12-year-old son, Jack, has exhibited traits of “demon possession” since he was two and needed an exorcism, according to the father John.\n",
        "\n",
        "John, a Christian, went on to say that the demon controlled his son and told him to kill people in the family.\n",
        "\n",
        "He says he’s so concerned, he has plans for Jack to have an exorcism because he fears that if he doesn’t, one day, he may have to kill his son to protect his wife and children.\n",
        "\n",
        "I don’t know about you, but this is never a thought that would cross my mind. I would protect my child at all costs, but I guess that’s just what false beliefs do to people. It’s much easier to kill your son if you think he’s an evil devil creature.\n",
        "\n",
        "Fortunately, Dr. Phil didn’t allow John’s baseless assertion to go unchallenged. He questioned how he could know that Jack is possessed by demons and followed up several times.\n",
        "\n",
        "“Tell me how you’ve come to the conclusion that it’s demonic possession,” Dr. Phil says to John on Monday’s episode. “At 2 ½-years old, he began exhibiting traits,” John says. “There was the stacking glass around his mother’s neck, point side up, and if she would’ve turned — I mean, I caught him in the middle of it. I felt the energy shift, and I woke up.” “But how is that behavior demonic? “Dr. Phil presses.\n",
        "\n",
        "It turned out most of the behavior John thought was caused by the devil was pretty typical. The young boy did stack glass around his mother’s neck, and when asked why he did it, he said he was “making mommy pretty.” That’s… normal. Not demonic.\n",
        "\n",
        "Here are some other reasons John said his son was possessed:\n",
        "\n",
        "Eyes glazed over, fil\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "latest lakeshore news & sports for WOMT/WCUB/WQTC/WLKN/WLTU/WEMP\n",
        "\n",
        "Opening Weekend of Sturgeon Spearing\n",
        "\n",
        "This past weekend marked the opening weekend for sturgeon spearing on the Winnebago System. Day one was by far the better day, with 219 fish collected. Lake Winnebago saw decent numbers with 83 fish caught, but the Upriver Lakes saw much better success, with 136 fish reeled in. Day 2 was not quite as fruitful, with a total of 124 sturgeon captured. The split was much closer as well, with 56 fish coming from Lake Winnebago, and 68 fish being pulled from the Upriver Lakes. Joseph Orlando has the distinction of catching the largest sturgeon of the weekend, measuring at 77.5” long, and weighing a whopping 147.3 LBS. Congratulations to Joseph, and good luck to those braving the winter cold.<|endoftext|>I am a 44 yr. old french Canadian PHP developper who has been freelancing and offering consulting services for the past 15 years. I have had the opportunity to cater to a diverse range of clients: manufacturers, pharmaceutical companies and media corporations among others.\n",
        "\n",
        "I am interested in anything related to Open-Source Web developpment.\n",
        "\n",
        "I am curious on many subjects and aspects of programming: frameworks, design methodologies, testing methodologies, security, analysis and requirement coding tools, and any computer or stat related math.<|endoftext|>Sevoflurane and isoflurane impair edrophonium reversal of vecuronium-induced neuromuscular block.\n",
        "A dose-response relationship study for edrophonium to examine the modification of volatile anaesthetics on reversal of vecuronium block. One hundred and twenty ASA (I-II) patients were anaesthetized with sevoflurane, isoflurane (1 minimum alveolar anaesthetic concentration [MAC] end-tidal concentration), or fentanyl-diazepam anaesthesia, in combination with 66% nitrous oxide (n = 40 for each group). The evoked electromyogram (EMG) response of the abductor digiti minimi was monitored at 20 sec intervals following train-of-four (TOF) stimulation of the ulnar nerve. The initial neuromuscular block was produced by vecuronium 100 micrograms.kg-1. When the amplitude of the first response (T1) had spontaneously recovered to 10% of the control, edrophonium (0, 125, 400, 700 or 1000 micrograms.kg-1; eight patients each) was randomly administered, and the ratio of the fourth TOF to the first response (TOFR) was monitored at one minute intervals for 10 min. Sevoflurane and isoflurane impaired the edrophonium-assisted TOFR recovery in an edrophonium dose and time dependent manner. The dose-response curves at 10 min exhibited a greater shift to the right in the sevoflurane and isoflurane groups than in the fentanyl-diazepam-nitrous oxide group (P < 0.05). Higher ED50 values (the edrophonium dose required to obtain TOFR value of 50%) in the sevoflurane (> 1000 micrograms.kg-1) and isoflurane groups (851 micrograms.kg-1) were observed than in the fentanyl-diazepam-nitrous oxide group (339 micrograms.kg-1) (P < 0.05). One MAC sevoflurane and isoflurane anaesthesia impair edrophonium reversal of vecuronium block to a similar degree.<|endoftext|>Last weekend, Super Smash Bros. Melee's top talent traveled to Salt Lake City's Vivint Smart Home Arena for three days of high-level competition. Although Game Tyrant Expo (GT-X) had a bracket chock-full of potential winners, nobody could have predicted the extreme upsets that rocked Utah's first major.\n",
        "\n",
        "It's only fitting that a tournament defined by upsets would finish with one. At the end of the day, Adam \"Armada\" Lindgren, undoubtedly the favorite to win, was not the player standing atop the podium. Instead, Juan \"Hungrybox\" Debiedma slugged his way through a grueling 10-game grand finals to claim the largest share of the event's unprecedented $30,000 prize pool.\n",
        "\n",
        "By capturing back-to-back major titles, Hungrybox has definitively set himself apart from the group of contenders trying to take the number one ranking from Armada. But while the thought of playing further probably didn't cross Hungrybox's mind as he celebrated with a sea of fans, the season is far from over. In less than a week, Melee's pros will pick up their controllers once more to see who can fight their way to the top at The Big House 7. And despite his recent losses, Armada will still b\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "goodness my boss valued me and my job was safe, but my gut instincts had landed me in more than a little trouble that day and I was left wondering if I was right. The thought did briefly cross my mind that maybe I was over-analysing the situation and perhaps I was just a judgemental meanie!\n",
        "\n",
        "I had accepted that I'd never know if my intuition was right or if I was way out of line, when several months later Jim wandered into the lounge one afternoon, grinning at me.\n",
        "\n",
        "'There you go, you can put yourself out of your misery.' As he tossed me the paper he exclaimed, 'You were right!'\n",
        "\n",
        "As I started to read the article headed 'These little piggies have roast beef ', my jaw dropped. The sweet animal-hugging vegetarian, who had condemned me so harshly for not adopting out our animals to her, had started a free-range home-kill meat business and breeding facility. There she was with her husband, proudly cuddling one of their pigs. The article went into detail about how much they loved their lifestyle, their animals and their new wonderful service to the community.\n",
        "\n",
        "While I agree that free-range pig farming can be a momentous improvement on the cruel practice of factory farming, I think it's important for people to be honest and ethical in their intentions—a vegetarian pig farmer is somewhat hypocritical in my view!\n",
        "\n",
        "'Hey Carolyn, I just drove past the circus and there were a whole lot of protesters picketing it.'\n",
        "\n",
        "Jim was calling me from his cell phone. He made a great roving reporter, and could have had a job as the eye in the sky for the local radio station.\n",
        "\n",
        "'Is it the elephant do you think?'\n",
        "\n",
        "We had heard about the controversy surrounding this particular circus and its exploitation of exotic animals. A year had passed since our sneak peek behind the scenes of this very circus, and the animals we had seen had not stopped preying on our minds. As Jim continued to talk, all the unpleasant memories came flooding back.\n",
        "\n",
        "'What do you think, should we protest with them?' Jim had pulled over to watch the chaos as the big top was being erected in a local park.\n",
        "\n",
        "'I don't know. I wonder if anyone has actually just talked to him . . . maybe we should try?'\n",
        "\n",
        "As we sat with the ringmaster, we just listened at first. It was obvious he still loved an audience and he loved to tell his story. His was a classic; he had joined the circus as a boy and 50-odd years later it was all he knew. We asked him what his plans were and he admitted that he was tired and would love to slow down as his health was deteriorating. 'But with the bloody protesters on his back' he was too proud and stubborn to make the move.\n",
        "\n",
        "Over the next week Jim and I went to the river and foraged for willow branches for the elephant, loaded up Jim's ute and drove our offerings to the circus. We became familiar faces and the team of roadies were always grateful for our help. Before long we were able to talk to the ringmaster about retiring the animals. There was the elephant, the monkeys, the donkeys and pony as well as the lions, poodles and doves. He agreed it was time to let all of them go, except for the poodles and doves which were his wife's much-loved pets. After doing the sums and assessing our land we gave ourselves a reality check; lions and an elephant were probably too much for us to handle and after talking with the ringmaster we knew he had other good offers on the table from established wildlife sanctuaries. No one, however, wanted the monkeys. There were no sensible solutions in the pipeline, so we decided we would put our hands up. We also agreed to take Pablo the pony and Jenny and Wee One the donkeys back to HUHA.\n",
        "\n",
        "The day we were going to pick up the monkeys came along in a bit of a hurry. The ringmaster wasn't well and needed to move them on faster than agreed. It was winter and the tricky thing was that we didn't have anywhere to put them yet, let alone have an official sign-off from the Ministry of Agriculture and Fisheries (MAF). The ringmaster insisted that they needed to be gone immediately. He also insisted that we pay for the monkeys' caravan and temporary enclosure as part of the deal for which he would accept no less than $20,000. We tried to reason with him but his final words were always, 'Well you can bugger off then, and they can stay here.'\n",
        "\n",
        "We didn't want to lose the opportunity to get them out of the circus. We knew there was an opportunity for the ringmaster to sell them to another circus, so we weighed up our options and organised a second mortgage on our\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "&= \\iiiint_{\\mathbb{R}^{4}}\\left(-4\\pi \\delta(\\bar{r} -\\bar{r}')\\delta(t -t'))\\right) f(\\bar{r}',t') \\,dx'dy'dz'dt'=\\\\\n",
        "&= -4\\pi \\iiiint_{\\mathbb{R}^{4}}\\delta(\\bar{r} -\\bar{r}')\\delta(t -t') f(\\bar{r}',t') \\,dx'dy'dz'dt'=\\\\\n",
        "&=-4\\pi f(\\bar{r},t)\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\\end{mybox}\n",
        "\\begin{tikzpicture}[remember picture, overlay]\n",
        "\\draw[->] (pic cs:start) -- ++(0,-0.5) -- ++(-13,0) |- (pic cs:stop);\n",
        "\\end{tikzpicture}\n",
        "\\end{document}\n",
        "\n",
        "<|endoftext|>Ultra storage-efficient time digitizer for pseudorandom single photon counter implemented on a field-programmable gate array.\n",
        "Pseudorandom single photon counting is a novel time-resolved optical measurement method, which is advantageous over convention techniques in terms of data-acquisition speed and system cost. As a critical component of the pseudorandom single photon counter, the photon arriving time digitizer should be storage efficient for a high photon counting rate, while maintaining good time accuracy. We report an ultra storage-efficient time digitizer for a pseudorandom single photon counter in this paper, which is based on the asynchronous serial communication and can store the arriving time of every photon in 1-b memory space. In addition, a novel comb-wave modulator is proposed to achieve the dc balance required for asynchronous serial communication. Our prototype implemented on field-programmable gate arrays provides a time resolution of 400 ps. It can register up to 4.2-Giga photon arriving time tags with 1024 × 32-b memory space.<|endoftext|>I didn't wear my Veronica Mars T-shirt to interview Jason Dohring, but the thought did briefly cross my mind. After all, I was one of the few (well, 2.5 million) viewers who obsessively watched the teen sleuth drama from 2004 to 2007, first on UPN and then The CW.\n",
        "\n",
        "I integrated Veronica's vernacular into my vocabulary, purchased Mars memorabilia, asked my parents to buy me a T-Mobile Sidekick (Veronica's cellular weapon of choice), and when series creator Rob Thomas asked for my money in 2013 to help fund a feature film, I happily donated.\n",
        "\n",
        "And I was not alone.\n",
        "\n",
        "By now, the story of how Veronica Mars became 2013's most talked-about social media event is the stuff of legend. Heck, my father even asked if I donated to \"that Pluto movie\" (he's trying, guys) when I was home for Thanksgiving. But for those of you who just emerged from underneath a rock, here's the quick version:\n",
        "\n",
        "On March 12, 2013, Rob Thomas launched a Kickstarter campaign to turn his beloved neo-noir series about a teenage private eye into a movie. He gave himself two days to raise $2 million. That goal was met in 10 hours. But the Kickstarter clock kept counting and the donations continued to pour in, eventually topping out at $5,702,153 (a new Kickstarter record). So, the film was funded, the movie was made, the T-shirts were silkscreened, and that brings us to the present day, when I'm sitting cross-legged on the floor of a Los Angeles office with Jason Dohring — who played Logan Echolls, the show's bad boy with a heart of 24-karat gold — talking about the March 14 release of Veronica Mars' feature film.<|endoftext|><script>\n",
        "\texport let foo = '\">div><script>alert(42)' + 'script>';\n",
        "script>\n",
        "\n",
        "<div foo={foo}>div><|endoftext|>Q:\n",
        "\n",
        "Why do Maps have slower lookup property than Records in Erlang?\n",
        "\n",
        "I'm reading Programming Erlang, in Chapter 5 of the book it says:\n",
        "\n",
        "Records are just tuples in disguise, so they have the same storage and performance\n",
        "  characteristics as tuples. Maps use more storage than tuples and have\n",
        "  slower lookup properties.\n",
        "\n",
        "In languages I've learned before, this is not the case. Maps are usually implemented as a Hash Table, so the lookup time complexity is O(1); Records (Tuples with names) are usually implemented as an immutable List, and the lookup time complexity is O(N).\n",
        "What's different in the implementation of these data structures in Erlang?\n",
        "\n",
        "A:\n",
        "\n",
        "There's no real practical performance difference between record lookup and map lookup for small numbers of fields. For\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "though people recognize that smoking can lead to adverse health consequences, they do not have even a basic understanding of the nature and severity of these consequences.<|endoftext|>Digital Speech Standard\n",
        "\n",
        "Digital Speech Standard (DSS) is a proprietary compressed digital audio file format defined by the International Voice Association, a co-operative venture by Olympus, Philips and Grundig Business Systems.\n",
        "\n",
        "DSS was originally developed in 1994 by Grundig with the University of Nuremberg. In 1997, the digital speech standard was released, which was based on the previous codec. It is commonly used on digital dictation recorders. Modern psychoacoustical codecs that perform nearly as well at only slightly higher bitrates have led to this speech coding standard being less used in modern voice recording equipment.\n",
        "\n",
        "Operation\n",
        "The DSS file format stores voice audio data in a highly compressed format that allows basic recording functionality (such as recording, playing, rewinding, etc.) as well as the ability to record in either insert or overwrite mode making it ideal for dictation. This along with ability to include additional information in the file header for the transcriptionist including priority mark, author, job type, etc.\n",
        "\n",
        "DSS is a format designed specifically for speech, equivalent to MP3 for music. In contrast with MP3, however, the quality usually is as low as possible, to minimize the size of the file.\n",
        "\n",
        "External links\n",
        "Philips Dictation Systems- Website of Philips Dictation Systems\n",
        "Olympus Professional Dictation- Website of Olympus Professional Dictation\n",
        "Olympus.\n",
        "Grundig Business Systems - Website of Grundig Business Systems\n",
        "Express Scribe DSS player and transcription assistant from NCH Software\n",
        "\n",
        "See also\n",
        "Speech Processing Solutions\n",
        "Philips\n",
        "Olympus\n",
        "Grundig Business Systems\n",
        "\n",
        "\n",
        "Category:Digital dictation\n",
        "Category:Speech codecs<|endoftext|>House Speaker Mark Ferrandino, D-Denver, right, says goodbye to partner Greg Wertsch following the passage of Senate Bill 11, which will allow gay couples to form civil unions in Colorado. (Craig F. Walker, The Denver Post)\n",
        "\n",
        "A bill allowing same-sex couples to form civil unions is on its way to the governor for his signature, but gay-rights activists say they won't stop until they get true equality, which is marriage.\n",
        "\n",
        "The Colorado House on Tuesday passed the bill 39-26 despite protests from Republicans that the bill faces legal challenges because it doesn't offer religious exemptions.\n",
        "\n",
        "\"We won't get to debate this again here, but we will debate this in a court of law,\" said Rep. Lori Saine, R-Dacono.\n",
        "\n",
        "The passage marks the first time in three years the bill has made it through the House, which was controlled by Republicans in the two previous sessions.\n",
        "\n",
        "Reps. Paul Rosenthal, D-Denver; Joann Ginal, D-Fort Collins; and Dominick Moreno, D-Commerce City hold hands while listening to comments before a vote on civil unions. The three lawmakers are gay. (Craig F. Walker, The Denver Post)\n",
        "\n",
        "Speaker Mark Ferrandino, a gay Denver Democrat who has carried the bill each year, said Senate Bill 11 is about love, family and equality under the law.\n",
        "\n",
        "\"This wasn't a choice. This is who I am. This is who we are,\" he said of being gay. \"We need to make laws in our society that respect everyone equally.\"\n",
        "\n",
        "After the vote, the five gay lawmakers in the House and the three gay lawmakers in the Senate lauded those who decades ago took up the fight for equality or were forced to live in the shadows.\n",
        "\n",
        "\"Today is really a memorial, remembering those who were shamed because they were gay or had AIDS,\" said Sen. Lucia Guzman, D-Denver.\n",
        "\n",
        "Sen. Pat Steadman, D-Denver, who has sponsored the civil-unions bill for three years, said its passage is the high point of a decades-long struggle.\n",
        "\n",
        "\"Yet we're not there yet. I don't want anyone to think that we somehow reached the peak,\" Steadman said. \"Civil unions are not marriage. They are something that are separate and distinct and lesser and unequal, and that really is not good enough.\"\n",
        "\n",
        "But both he and Ferrandino pointed out that civil unions offer important protections for children and families, and they were thrilled to see the bill finally pass.\n",
        "\n",
        "Gays cannot marry in Colorado because of a 2006 constitutional amendment that defined marriage as between one man and one woman. Voters passed it 55 percent to 45 percent while defeating a civil-unions-type measure.\n",
        "\n",
        "Gov. John Hickenlooper, a Democrat and a longtime supporter of gay rights, is expected to sign the bill later this month. The bill becomes law May 1.\n",
        "\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "5dncann6Ympb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_3_2 = [\n",
        "    r\"\"\"\n",
        "     xmllint only uses the reader interface when passed the --stream option:\n",
        "$ xmllint --stream --pattern /foo/bar test.xml\n",
        "Node /foo/bar[1] matches pattern /foo/bar\n",
        "Node /foo/bar matches pattern /foo/bar\n",
        "\n",
        "A:\n",
        "\n",
        "From the xmllint(1) man page:\n",
        "   --pattern PATTERNVALUE\n",
        "          Used to exercise the pattern recognition engine, which can be\n",
        "          used with the reader interface to the parser. It allows to\n",
        "          select some nodes in the document based on an XPath (subset)\n",
        "          expression. Used for debugging.\n",
        "\n",
        "It only understands a subset of XPath and its intention is to aid debugging. The library that does understand XPath fully is libxslt(3) and its command-line tool xsltproc(1).\n",
        "The ``pattern'' module in libxml \"allows to compile and test pattern expressions for nodes either in a tree or based on a parser state\" and its documentation lives here: http://xmlsoft.org/html/libxml-pattern.html\n",
        "Ari.\n",
        "\n",
        "<|endoftext|>Q:\n",
        "\n",
        "Choosing the best fit sentence to mail prospective PhD supervisor\n",
        "\n",
        "I am applying for a PhD scholarship which was posted on the university website and for that, I am writing mail to the professor. I have written about my background, academics, interests and experience. I want to ask him the procedure for applying for the scholarship. I am not a native English speaker so I am not sure that which of the following sentence would be best for that:\n",
        "Plese let me know about the application procedure\n",
        "Please let me know how can I apply for the position\n",
        "Or if there is another way to ask, kindly suggest.\n",
        "\n",
        "A:\n",
        "\n",
        "The wording probably doesn't matter too much. You can simply say \"I am interested in applying for X scholarship. How does the application procedure work?\".\n",
        "However, before you send the email, make sure you check the details aren't already online somewhere. Also consider if your email would be better addressed to the department administrator rather than the professor, as an administrator is more likely to know all the necessary technical details.\n",
        "\n",
        "<|endoftext|>Bone marrow microvessel density in chronic myeloproliferative disorders: a study of 115 patients with clinicopathological and molecular correlations.\n",
        "Philadelphia-negative chronic myeloproliferative disorders (CMD) include polycythemia vera (PV), essential thrombocythemia (ET) and primary myelofibrosis (PMF). Angiogenesis is critical in the pathogenesis of PMF. We studied angiogenesis in 115 patients with CMD (23 PV, 24 ET, 46 PMF, 12 post-PV and 10 post-ET myelofibrosis) by assessment of microvessel density (MVD) in bone marrow (BM). Kruskall-Wallis analysis of variance showed that patients with PMF had significantly higher values of MVD than those with PV (P < 0.001), ET (P < 0.001) and controls (P < 0.001). Mann-Whitney U-test demonstrated that patients with PMF at the prefibrotic stage had significantly higher MVD values than those with ET (P = 0.02). Patients with post-PV myelofibrosis showed significantly higher MVD values than those with PV (P < 0.001), as did patients with post-ET myelofibrosis compared with ET (P < 0.001). In patients with CMD, the multivariate generalized linear regression model showed that the JAK2 (V617F) mutational burden (P = 0.01), serum lactate dehydrogenase level (P = 0.003), and anaemia (P < 0.001) independently correlated with MVD. In summary, this study indicates that assessment of BM angiogenesis, as measured by MVD, may be a useful additional tool in the histopathological definition of CMD.<|endoftext|>Microfabrication conventionally uses photolithography or optical lithography processes for selectively removing parts of a substrate, or parts of a material layer on the substrate. For example, photolithography uses a directed light (radiation) source to transfer a pattern from a photomask (also referred to as a mask or reticle) to a light-sensitive resist material formed on the substrate or material layer, thereby generating an exposure pattern in the resist material. Chemical treatments may then be used to etch or otherwise transfer the exposure pattern in the resist material to the substrate or material layer. More recently, microfabrication has implemented other lithography types, such as charged particle beam lithography, that do not necessitate the intermediary step of creating the mask to transfer or generate an exposure pattern in a resist material. For example, electron beam (e-beam) lithography uses a focused beam of electrons to expose the resist material. Instead of using a mask, e-beam lithography “writes” a pattern directly into an energy-sensitive resist material\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "     before).\n",
        "What I don't know is how can I have 32 inputs, since the Raspberry Pi board has less than 32 I/O pins.\n",
        "I have the impression I need another component for that (like a converter... or something), but again, I don't know what I need to build the electronic part of this project.\n",
        "How can I connect more inputs to the Raspberry Pi? What would be the best way to build this?\n",
        "\n",
        "The pedals should work simultaneously as well.\n",
        "\n",
        "A:\n",
        "\n",
        "The best way depends on factors only you can determine.\n",
        "I give a couple of ways.\n",
        "\n",
        "use two MCP23017, each of which supply 16 digital IO.  They use the I2C bus (pins 3/5, GPIO 2/3) and up to 8 can be used on the bus.\n",
        "use 4 8-bit input shift registers.  They provide 8 digital inputs each.  They can use the SPI bus and you can daisy chain as many as you want.  If needed you could instead bit bang reading the devices from any GPIO.\n",
        "\n",
        "The shift registers are probably better for your application.  They are likely to be more responsive as you can drive the SPI bus much faster than the I2C bus.\n",
        "\n",
        "<|endoftext|>Vadym Karatayev\n",
        "\n",
        "Vadym Karatayev or Vadim Karataev (born 15 January 1964) is an association footballer from the former Soviet Union.\n",
        "\n",
        "In 1983 Karatayev took part in the Summer Spartakiad of the Peoples of the USSR in the team of Ukrainian SSR. He also participated in the 1983 FIFA World Youth Championship for the Soviet team.\n",
        "\n",
        "References\n",
        "\n",
        "External links\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Category:1964 births\n",
        "Category:Living people\n",
        "Category:People from Alchevsk\n",
        "Category:Soviet footballers\n",
        "Category:Ukrainian footballers\n",
        "Category:Soviet Top League players\n",
        "Category:FC Dynamo Kyiv players\n",
        "Category:FC Chornomorets Odesa players\n",
        "Category:FC Shakhtar Stakhanov players\n",
        "Category:FC Krystal Kherson players\n",
        "Category:FC Zimbru Chișinău players\n",
        "Category:Wisła Płock players\n",
        "Category:Hapoel Ashkelon F.C. players\n",
        "Category:Ukrainian expatriate footballers\n",
        "Category:Expatriate footballers in Israel\n",
        "Category:Expatriate footballers in Poland\n",
        "Category:Association football defenders\n",
        "Category:Neftçi PFK players<|endoftext|>Q:\n",
        "\n",
        "Choosing the best fit sentence to mail prospective PhD supervisor\n",
        "\n",
        "I am applying for a PhD scholarship which was posted on the university website and for that, I am writing mail to the professor. I have written about my background, academics, interests and experience. I want to ask him the procedure for applying for the scholarship. I am not a native English speaker so I am not sure that which of the following sentence would be best for that:\n",
        "Plese let me know about the application procedure\n",
        "Please let me know how can I apply for the position\n",
        "Or if there is another way to ask, kindly suggest.\n",
        "\n",
        "A:\n",
        "\n",
        "The wording probably doesn't matter too much. You can simply say \"I am interested in applying for X scholarship. How does the application procedure work?\".\n",
        "However, before you send the email, make sure you check the details aren't already online somewhere. Also consider if your email would be better addressed to the department administrator rather than the professor, as an administrator is more likely to know all the necessary technical details.\n",
        "\n",
        "<|endoftext|>Our first glimpse at components that could be destined for the much-rumored 5.8-inch \"iPhone 8\" and its 4.7 and 5.5-inch companion devices surfaced this morning in a post on reddit. The images are said to be sourced from a case manufacturer who received them from a glass supplier in China.\n",
        "\n",
        "The first photo depicts what is said to be the front and back panel of the iPhone 8, with the front panel featuring a super thin bezel around all sides along with a top bar that could perhaps house a front-facing camera, microphone, and speaker. There's been some question on how Apple will handle the front-facing camera and mockup devices and renderings haven't offered a clear picture.\n",
        "\n",
        "\n",
        "\n",
        "Some design renderings have shown a section at the top of the device similar to the front panel in this image, while others seem to feature a bar that extends fully across the top of the device.\n",
        "\n",
        "The rear panel features a vertical dual-lens camera and a separate protruding lens component, with no rear Touch ID in sight, in line with rumors suggesting Apple has indeed figured out how to build Touch ID into the display of the device.\n",
        "\n",
        "A second photo depicts the two alleged iPhone 8 components next to alleged components for the 4.7-inch iPhone 7s and the 5.5-inch iPhone 7s Plus, two devices that are rumored\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    correlate these alterations with histological damage. Wistar rats were treated with methotrexate (1.5-3.5 mg/kg) for 3 days to induce mucositis. Intestinal permeability was measured by the urinary excretion rate of lactulose and mannitol following administration by gavage. Intestinal perfusion was performed in vivo for evaluation of water and electrolyte transports. Methotrexate-treated rats lost a significant amount of weight and presented a marked reduction in food intake. Methotrexate induced significant and dose-dependent villous atrophy and elongation of crypts in duodenum, jejunum, and ileum. Methotrexate also induced an increase in sodium and potassium secretion and an important reduction of the mucosa absorptive surface area, shown by the decrease in the mannitol excretion ratio. In conclusion, methotrexate caused major changes in small bowel function by disrupting intestinal permeability and inducing electrolyte secretion in parallel with substantial histological damage.<|endoftext|>Buhay OFW\n",
        "\n",
        "Buhay OFW (English translation: Life of an OFW) is a weekly public service program aired on 5 Plus catered for the Overseas Filipino Workers or OFWs based in different countries outside the Philippines. The program also featured government and non-government organizations who are charged in taking care the concerns of OFWs such as labor and recruitment issues. Buhay OFW also highlighted untold and successful stories of OFWs who are survived from adversities and sufferings while working outside the country but have also given inspiration to their fellow Kababayans. The program also successfully organized several projects for the OFW community such as the Mr. and Ms. Citizens of the World, which was launched In 2012, in time for the program's 1st anniversary.\n",
        "\n",
        "The program was premiered on September 10, 2011, and it currently aired as the blocktime program of AksyonTV (5 Plus since 2019) every Saturday evenings at 9-10pm (PST). It is also aired worldwide via AksyonTV International. The program currently hosted by Marissa del Mar, a one-time PMPC Star Awards Best Public Service Program Host awardee and former host of Up Close and Personal on IBC-13, which was awarded as the Best Public Service Program, also from the PMPC Star Awards. Buhay OFW is produced by Millicent Productions, del Mar's own production house.\n",
        "\n",
        "On October 2016, Buhay OFW was awarded as the Best Public Service Program, together with Mission: Possible of ABS-CBN, in the recently concluded 30th PMPC Star Awards for Television.\n",
        "\n",
        "References\n",
        "\n",
        "External links\n",
        "Official Website\n",
        "\n",
        "Category:AksyonTV shows\n",
        "Category:Philippine documentary television series\n",
        "Category:News5 programs\n",
        "Category:2011 Philippine television series debuts\n",
        "Category:2019 Philippine television series endings<|endoftext|>Comparative viability of expanded and unexpanded axial pattern skin flaps in pigs.\n",
        "A comparison of viable areas of axial pattern flaps post inset was made between expanded and non-expanded pig buttock island flaps. The deep circumflex iliac artery and vein supply approximately the proximal 14 x 10 cm area of this flap. Larger flaps were raised on expanded and control sides of eight pigs to determine if expansion increased the area of survival. In six of eight pigs whose initial tissue expansion did not create more than approximately a 50% increase in skin area, the expanded flaps had a statistically significant increase in viable skin area (proportionally) 10 days post inset than their control flaps (p less than 0.05). Two other pigs did not conform to this pattern. Their initial tissue expansion was greater than 50%, and the resulting area of flap viability was proportionally less in expanded flaps than the control flaps.<|endoftext|>Q:\n",
        "\n",
        "Question about recommendation letter\n",
        "\n",
        "I am applying my MA program in October, there is a professor agree to write a recommendation letter for me. But I couldn't find another professor who is willing to write a recommendation letter for me. So I have to apply the mater program next year. I want to email to that professor to tell her I decide not to apply for the MA program this year and ask if she can still help me with the recommendation letter next year (I don't know if she finish it or not). I am not a native English speaker, so I want to ask what should I say to the professor in the email? In a polite way. Thanks!\n",
        "\n",
        "Can anyone help me to check if this email is polite? Can I say like this?\n",
        "\n",
        "Hi professor,  I am writing to tell you that unfortunately I met some\n",
        "  problems with my application for the graduate program, and now I do\n",
        "  not have enough time for applying my dream school this year.\n",
        "  Therefore, I decide to take a gap year to participate in some\n",
        "  internships and prepare for the IELTS test. I will apply the graduate\n",
        "  program again in September\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "     that right? If so, then is it safe to assume that the draft introduction is essentially the \"pitch\" for the substance of the book? Thanks!\n",
        "\n",
        "David, I know you've stated the royalty rate hasn't yet been determined, but are there any reasonable assumptions that might be made. For example, will the royalty rate run any higher than it might have in the past to make up for the lack of advance? Is there any sort of ballpark range to help writers determine whether writing a book — or even a proposal — is worth the time spent on the gamble?\n",
        "\n",
        "Also, what are the terms of copyright/ownership Bloomsbury is purchasing?\n",
        "\n",
        "What guarantee is there that, once contracted, the book written will ever be published? It seems like without any financial investment in the author, Bloomsbury doesn't have much skin in the game, so to speak... How are you ensuring good-faith with the selected writers?\n",
        "\n",
        "Mike: Yes, that's a fair assumption, about the draft Intro. Ideally we'd ask for more but it doesn't seem fair to ask people for more when it's entirely possible that we'll receive 200-300 proposals and will only be able to publish 15-20 of them. If we're intrigued by a proposal and want to find out more, we may get back to individual authors at that point.\n",
        "\n",
        "Anon #1: I can't see that the royalty rate will go any higher than what it's always been on these, which is 10% of net receipts. I'll try to build in some kind of staggered royalty so that the rate goes up after a certain number of sales. Copyright: our contracts all contain, before Clause 1, the phrase \"Author is the author of, and owner of the copyright in, the work provisionally entitled...\" Good faith: we're nice people. If we sign a contract to work together, we assume that the author will deliver his/her side of the deal, we'll absolutely do the same. Works a treat, every time.\n",
        "\n",
        "i am not a native speaker, my english is quite good though (i believe). i'm sure i could write a great text for the series. would the possible need for extra proof reading / editing on your end be a problem?\n",
        "\n",
        "and also: what is the situation with foreign rights? since some of my research for the porposed text would be german language interviews and german is my first language, it would be a reasonably modest job for me to produce a german version of the text. would i be able to sell that directly to a german publisher or would bloomsbury's contract extend to the german version as well?\n",
        "\n",
        "I got some very positive feedback on a proposal I submitted in the last round (thanks Dave!) but was told the \"marketing guys\" (okay maybe that was not the term used) were not sold on it because they thought it might not sell enough copies. Should I try again, re-tweaking to suggest why it is in fact a viable idea?\n",
        "\n",
        "David, My agent believes she should submit my proposal (as she does my work with other publishers), but I don't see how to do that given the carefully choreographed submission procedures. Can an agent submit on behalf of a client?\n",
        "\n",
        "From the same anonymous: hi again! I should clarify that the \"reissue\" here is not a reissue of a previously issued compilation but, rather, the first time that three hard-to-find albums were issued as a set. Thanks for any light you can shed on this!\n",
        "\n",
        "1. Is there any way for you to elaborate on how the royalties work? My understanding is that since there's no advance to recoup, the writer would get royalties starting with the very first copy that sells, correct? Also, does \"10% net receipts\" mean the author will receive 10% of all sales? Just trying to get an idea. Say the author sold 5,000 copies. How much money would that give them in royalties?\n",
        "\n",
        "2. Will oral histories be considered for publication? My apologies if there's already been a 33 1/3 oral history published that I haven't read.\n",
        "\n",
        "Lunt435: No, that would not be a problem, if the proposal is good enough. Foreign rights: Bloomsbury would want to keep these if at all possible, although such matters can be sometimes negotiated at contract stage.\n",
        "\n",
        "Peg: it's a question we're asked often and there's no easy answer to it! If the project is one you're passionate about, and you feel confident you can persuade us of its viability then yes, please do submit a revised version of it.\n",
        "\n",
        "Anon #1: yes, an agent can submit your proposal on your behalf, as long as it conforms to the guidelines we've set out.\n",
        "\n",
        "Anon #2: A collection of short albums\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "uiTBismrOobo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_3_912 = [\n",
        "    r\"\"\"\n",
        "                super(columns);\n",
        "            if (type == null || number == null) {\n",
        "                throw new IllegalArgumentException(\n",
        "                    \"type and number must be non-null\");\n",
        "            }\n",
        "            this.type = type;\n",
        "            this.number = number;\n",
        "            isComparable = (number instanceof Comparable);\n",
        "        }\n",
        "\n",
        "        @Override\n",
        "        @SuppressWarnings(\"unchecked\")\n",
        "        protected boolean include(\n",
        "                Entry extends M, ? extends I> value, int index) {\n",
        "            Object v = value.getValue(index);\n",
        "\n",
        "            if (v instanceof Number) {\n",
        "                boolean compared = true;\n",
        "                int compareResult;\n",
        "                Class> vClass = v.getClass();\n",
        "                if (number.getClass() == vClass && isComparable) {\n",
        "                    compareResult = ((Comparable)number).compareTo(v);\n",
        "                }\n",
        "                else {\n",
        "                    compareResult = longCompare((Number)v);\n",
        "                }\n",
        "                switch(type) {\n",
        "                case BEFORE:\n",
        "                    return (compareResult > 0);\n",
        "                case AFTER:\n",
        "                    return (compareResult < 0);\n",
        "                case EQUAL:\n",
        "                    return (compareResult == 0);\n",
        "                case NOT_EQUAL:\n",
        "                    return (compareResult != 0);\n",
        "                default:\n",
        "                    break;\n",
        "                }\n",
        "            }\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        private int longCompare(Number o) {\n",
        "            long diff = number.longValue() - o.longValue();\n",
        "\n",
        "            if (diff < 0) {\n",
        "                return -1;\n",
        "            }\n",
        "            else if (diff > 0) {\n",
        "                return 1;\n",
        "            }\n",
        "            return 0;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    private static class OrFilter<M,I> extends RowFilter<M,I> {\n",
        "        List<RowFilter super M,? super I>> filters;\n",
        "\n",
        "        OrFilter(Iterable extends RowFilter super M, ? super I>> filters) {\n",
        "            this.filters = new ArrayList<RowFilter super M,? super I>>();\n",
        "            for (RowFilter super M, ? super I> filter : filters) {\n",
        "                if (filter == null) {\n",
        "                    throw new IllegalArgumentException(\n",
        "                        \"Filter must be non-null\");\n",
        "                }\n",
        "                this.filters.add(filter);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        public boolean include(Entry extends M, ? extends I> value) {\n",
        "            for (RowFilter super M,? super I> filter : filters) {\n",
        "                if (filter.include(value)) {\n",
        "                    return true;\n",
        "                }\n",
        "            }\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    private static class AndFilter<M,I> extends OrFilter<M,I> {\n",
        "        AndFilter(Iterable extends RowFilter super M,? super I>> filters) {\n",
        "            super(filters);\n",
        "        }\n",
        "\n",
        "        public boolean include(Entry extends M, ? extends I> value) {\n",
        "            for (RowFilter super M,? super I> filter : filters) {\n",
        "                if (!filter.include(value)) {\n",
        "                    return false;\n",
        "                }\n",
        "            }\n",
        "            return true;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    private static class NotFilter<M,I> extends RowFilter<M,I> {\n",
        "        private RowFilter<M,I> filter;\n",
        "\n",
        "        NotFilter(RowFilter<M,I> filter) {\n",
        "            if (filter == null) {\n",
        "                throw new IllegalArgumentException(\n",
        "                    \"filter must be non-null\");\n",
        "            }\n",
        "            this.filter = filter;\n",
        "        }\n",
        "\n",
        "        public boolean include(Entry extends M, ? extends I> value) {\n",
        "            return !filter.include(value);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "<|endoftext|>Mesonerilla prospera\n",
        "\n",
        "Mesonerilla prospera is a species of invertebrate in the Nerillidae family endemic to Bermuda.\n",
        "In 2000, M. prospera was put on the IUCN Red List under the critically endangered category. The IUCN states that \"there are problems with the Order name and the correct placement of the family.\"\n",
        "\n",
        "References\n",
        "\n",
        "Category:Polychaetes\n",
        "Category:Endemic fauna of Bermuda\n",
        "Category:Animals described in 1982\n",
        "Category:Taxonomy articles created by Polbot<|endoftext|>We have to prepare ourselves for a second referendum\n",
        "\n",
        "It is hard to think of any phrase in 21st-century Britain that is more Orwellian than ‘People’s Vote’.\n",
        "\n",
        "The bruised elites, still reeling from the vote for Brexit, say ‘People’s Vote’ when what they really mean is second\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "     Between 1994 and now, one other person was infected and survived. Though, confusingly, the US Centers for Disease Control reports that two out of three human infections prior to this year were fatal.\n",
        "\n",
        "Julia Whitty is Mother Jones’ environmental correspondent, lecturer, and 2008 winner of the Kiriyama Prize and the John Burroughs Medal Award.<|endoftext|>Old Hamilton County Jail\n",
        "\n",
        "The Old Hamilton County Jail is a historic building at 501 Northeast 1st Avenue, Jasper, Florida, United States. It was added to the National Register of Historic Places in 1983.  The Old Hamilton County Jail now serves as the Hamilton County Historical Museum.\n",
        "\n",
        "Hamilton County Historical Museum\n",
        "\n",
        "The Hamilton County Historical Museum consists of a jail.\n",
        "\n",
        "See also\n",
        "Jails and prisons listed on the National Register of Historic Places\n",
        "\n",
        "References\n",
        "\n",
        "External links\n",
        " Hamilton County Historical Museum - official site\n",
        " Hamilton County listings, Florida's Office of Cultural and Historical Programs\n",
        "\n",
        "Hamilton County Jail\n",
        "Category:Museums in Hamilton County, Florida\n",
        "Hamilton County Jail\n",
        "Category:Prison museums in Florida\n",
        "Category:History museums in Florida\n",
        "Category:Jails in Florida\n",
        "Category:National Register of Historic Places in Hamilton County, Florida\n",
        "Category:1893 establishments in Florida<|endoftext|>Q:\n",
        "\n",
        "Убрать у всех class=\"active\"\n",
        "\n",
        "Как на js можно у всех li которые в ul убрать класс active, есть идея реализации в цикле пройтись и проверить наличие класса и убрать, но не думаю что лучшее решение, как правильнее сделать?\n",
        "<ul class=\"nav navbar-nav\">\n",
        "  <li class=\"active\" id=\"1\" ><a href=\"/\" >9a>li>\n",
        "  <li class=\"active\" id=\"2\" ><a href=\"/\" >8a>li>\n",
        "  <li class=\"active\" id=\"3\" ><a href=\"/\" >7a>li>\n",
        "  <li id=\"4\" ><a href=\"/\" >6a>li>\n",
        "  <li class=\"active\" id=\"5\" ><a href=\"/\">5a>li>\n",
        "  <li id=\"6\" ><a href=\"/\" >4a>li>\n",
        "  <li class=\"active\" id=\"7\"  ><a href=\"/\" >3a>li>\n",
        "  <li id=\"8\" ><a href=\"/\" >2 a>li>\n",
        "  <li class=\"active\" id=\"9\" ><a href=\"/\" >1a>li>\n",
        " ul>\n",
        "\n",
        "P.s. active может отсутствовать у некоторых элементов как выше в 8, 6, 4\n",
        "\n",
        "A:\n",
        "\n",
        "Проще всего это сделать вот так:\n",
        "$('ul li.active').removeClass('active');\n",
        "\n",
        "<|endoftext|>More Like This\n",
        "\n",
        "Quick Reference\n",
        "\n",
        "The subphylum chelicerata, of which horseshoe crabs form a small part, is more commonly represented by its terrestrial members – the arachnids (spiders, scorpions, and their relatives). The horseshoe crabs'primordial ...<|endoftext|>Q:\n",
        "\n",
        "How apply a bitmask to an integer in MySQL?\n",
        "\n",
        "Here is the problem:\n",
        "The database Rx30 stores the status of a prescription in a field called 'Rxstatus.' The number they store there is an integer that is never higher than 255. The bits that are set determine whether or not a script is filled.\n",
        "A representative told us that if 16, 32, or 128 is set, the script is deemed 'unfilled.'\n",
        "So now what we need to do is take an integer, say '49', and see which bits are set. This needs to be done through MySQL for speed's sake. I understand that 49 is:\n",
        "32+16+1 = 49\n",
        "\n",
        "So 16 is set in this field, therefore the script is unfilled.\n",
        "How (in MySQL) can I take an integer, say 152 for example, and determine which bits of it are set?\n",
        "Once we determine what's set, if 16, 32, or 128 is set we can deem the script unfilled and produce the correct results.\n",
        "\n",
        "A:\n",
        "\n",
        "If you have a test bit mask, e.g. 32+16+1 = 49, and you want to know if any of these are set in Rxstatus, you use:\n",
        "SELECT Rxstatus & 49 != 0\n",
        "\n",
        "If you want to know if all of them are set, you use:\n",
        "SELECT Rxstatus & 49 = 49\n",
        "\n",
        "To set all the bits from\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    plan for the duration of the work.\n",
        "\n",
        "April, 2005: Proceedings are instituted in the High Court to prevent residents obstructing the construction of the gas pipeline at Rossport. The High Court grants Shell the right to access private lands in the village for the installation of the pipeline. Meanwhile, it is revealed that Shell employed a company of which it is a substantial shareholder to conduct an ‘independent’ audit of the pipeline’s safety.\n",
        "\n",
        "June, 2005: Five residents from Rossport are jailed for contempt of court for refusing to obey the High Court order not to interfere with the construction of the Corrib gas pipeline. The men vow to stay in prison until they get justice.\n",
        "\n",
        "Families and supporters of the Rossport Five commence round the clock picketing at Rossport, Bellinaboy and Glengad: Shell pipeline sites in Mayo.\n",
        "\n",
        "July, 2005: National rallies held in support of the Rossport Five in Castlebar, Belmullet, Ballina, Dublin.\n",
        "\n",
        "Natural Resources Minister Noel Dempsey orders a further safety review of the Corrib Gas pipeline with a view to ending the standoff between Shell and local residents in Co Mayo.\n",
        "\n",
        "Minister Dempsey said Marine and Natural Resources Dept officials had carried out an inspection at the Shell onshore site and subject to further legal advice, it was his view that a serious breach of the consents given to Shell in relation to the pipeline had occurred. He ordered Shell to dismantle three kilometres of gas pipeline that it had assembled in north Mayo.\n",
        "\n",
        "August, 2005: Marine and Natural Resources Minister, Noel Dempsey, granted Shell permission to lay the 75 kilometres of pipeline from the Corrib Field to the North Mayo coastline.\n",
        "\n",
        "Shell E&P Ireland defers laying the offshore pipeline for the Corrib gas project until 2006. Shell said the temporary suspension ''will not materially affect the project's completion schedule'', and will ''allow for a period of discussion and dialogue''.\n",
        "\n",
        "Shell announces that it is to lay off 128 workers at the Corrib gas pipeline in Co Mayo. National rally in support of the Rossport 5 held in Galway. Minister for Communications, Marine and Natural Resources Noel Dempsey announces a further safety review.\n",
        "\n",
        "September, 2005: Family and supporters visit Norway and meet Statoil and public representatives. Rossport Five appear before Mr Justice Finnegan in the High Court.\n",
        "\n",
        "1 October, 2005: Thousands rally in support of Rossport Five in Dublin.\n",
        "\n",
        "12 October, 2005: A two-day public consultation organised by the Department of the Marine is held in Geesala, Co. Mayo\n",
        "\n",
        "25 October, 2005: Rossport Five appear before Mr Justice Finnegan in the High Court\n",
        "\n",
        "31 October, 2005: The Minister announced that he had appointed Mr Peter Cassells, a former general secretary of the Irish Congress of Trade Unions, to mediate between Shell E&P and the Rossport residents\n",
        "\n",
        "11th September - Solitaire forced to withdraw from Broadhaven bay after its pipe laying appartus became damaged. The previousday several people had been arrested while blocking roads and Pat O'Donell and his son had been arrested again to prevent them fishing the bay.\n",
        "\n",
        "Search\n",
        "\n",
        "Blast from the Past\n",
        "\n",
        "Garda whistleblower Maurice McCabe’s first contact with a TD came about because he saw Clare Daly TD on ‘Tonight with Vincent Browne’ talking about policing of Corrib Gas protests, writes William Hederman\n",
        "\n",
        "The repercussions for Garda whistleblowers Maurice McCabe and John Wilson will be familiar to others who have publicly embarrassed An Garda Síochána. They were clearly acting in the public interest, but their revelations brought the force into disrepute, and the two men suffered as a result. Revenge was exacted – not only by colleagues, but also by way of public denunciation by the Garda Commissioner (“disgusting”), the Minister for Justice (“not co-operating”) and by various other parties loyal to the force.<|endoftext|>Allendale County Courthouse\n",
        "\n",
        "Allendale County Courthouse is a historic county courthouse in Allendale, Allendale County, South Carolina. It was added to the National Register of Historic Places in 2007.\n",
        "\n",
        "Description and history\n",
        "It was built in 1921-1922, and is a two-story yellow brick and limestone-accented building with a central block with pedestaled pediment dominated by a monumental, unengaged, flat-roofed Neoclassical Revival portico. The portico features four massive limestone columns and responding pilasters of the Tuscan order, a classical entablature, and a brick-and-limestone parapet.\n",
        "\n",
        "Immediately to the rear and connected to the historic courthouse by a narrow two-story hyphen is a large office and courtroom building that was completed and occupied in 2004\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    <|endoftext|>TimerEventDefinition.class);\n",
        "    timerDefinition.setTimeDate(timeDate);\n",
        "    return timerDefinition;\n",
        "  }\n",
        "\n",
        "  protected TimerEventDefinition createTimeDuration(String timerDuration) {\n",
        "    TimeDuration timeDuration = createInstance(TimeDuration.class);\n",
        "    timeDuration.setTextContent(timerDuration);\n",
        "    TimerEventDefinition timerDefinition = createInstance(TimerEventDefinition.class);\n",
        "    timerDefinition.setTimeDuration(timeDuration);\n",
        "    return timerDefinition;\n",
        "  }\n",
        "}\n",
        "<|endoftext|>China Grove (Gardner, Louisiana)\n",
        "\n",
        "China Grove is a historic house located in Gardner, Louisiana. It was added to the National Register of Historic Places on December 5, 1984. The house is considered to be an outstanding example of neo-classical and Greek Revival architecture; its Greek Revival woodwork in particular stands out among houses in the region.\n",
        "\n",
        "It was listed as one result of a study of 10 Neo-Classical farm-plantation houses along Bayou Rapides.  As for several of the others (Eden, Geneva, Hope, Island Home, Longview), China Grove was modified by addition of hood along its original gallery, termed a false gallery, which provides additional protection from the rain, detracting somewhat but not greatly from its original appearance.\n",
        "\n",
        "References\n",
        "\n",
        "Category:Houses on the National Register of Historic Places in Louisiana\n",
        "Category:Houses completed in 1857\n",
        "Category:Houses in Rapides Parish, Louisiana\n",
        "Category:Neoclassical architecture in Louisiana\n",
        "Category:National Register of Historic Places in Rapides Parish, Louisiana\n",
        "Category:1857 establishments in Louisiana<|endoftext|>Travis Dyson is the 30-year-old Florida man who was found in a hotel room with Democratic politician Andrew Gillum on March 13. Police said Dyson appeared to have suffered a drug overdose. He is conscious and in stable condition in a Miami-area hospital.\n",
        "\n",
        "Dyson maintains a profile on a website for male escorts and is studying at a nurse practitioner school. Gillum has been married to R. Jai Gillum since 2009. The couple have three children together.\n",
        "\n",
        "In 2018, Gillum, 40, was the surprise winner of the Democratic primary for governor in Florida. Gillum lost the general election narrowly to Ron De Santis. Since then, Gillum has been a rising star in the Democratic party. Between 2014 and 2018, Gillum served as the mayor of Tallahassee.\n",
        "\n",
        "Here’s what you need to know:\n",
        "\n",
        "1. Gillum Said He Was in Miami to Celebrate a Wedding but Dyson Said the Former Mayor Never Mentioned it\n",
        "\n",
        "Former Gubernatorial Candidate Andrew Gillum Found In Room With Possible Crystal MethAndrew Gillum said he was in town for a wedding and had too much to drink but never used methamphetamines 2020-03-13T16:44:08.000Z\n",
        "\n",
        "Gillum has said that he was in Miami for a wedding. The former Tallahassee mayor admitted to “drinking too much” but denied that he had taken any drugs. Gillum was too drunk to speak to the police when they arrived at the scene, documents say. Speaking to the Miami New Times, Dyson said that Gillum did not mention attending a wedding. In his statement, Gillum referred to Dyson as a “friend.” Dyson said that he and Gillum had been friends since last spring. Dyson told the website, “I personally was not celebrating a wedding. I don’t know if [Gillum] was in town for a wedding. He did not mention that.”\n",
        "\n",
        "Former Florida governor candidate Andrew Gillum involved in Miami meth overdose 2020-03-13T16:41:12.000Z\n",
        "\n",
        "The man who rented the room, Aldo Mejias, 53, said he went to the room before midnight on March 12. Mejias said that he found Dyson and Gillum “under the influence of an unknown substance.” Mejias said that Gillum had been vomiting into the toilet and that Dyson was unconscious. Mejias performed CPR on Dyson until the paramedics arrived. The incident occurred at the Mondrian South Beach Hotel in Miami Beach, Florida.\n",
        "\n",
        "The drug in question was crystal meth. Those narcotics were impounded. It’s not clear if Gillum or Dyson will be facing any charges. Gillum was allowed to leave the scene and return home by officers.\n",
        "\n",
        "2. Dyson Was Last in Trouble With the Law in August 2019\n",
        "\n",
        "Dyson was arrested in August 2019 and accused of resisting officer without violence to his person reckless driving.\n",
        "\n",
        "On his Instagram page, which was set to private in the fallout from the Gillum scandal, Dyson referred to himself as “still young,” “sometimes professional,” “very taken” and a “grad student.” Dyson says that he studying at nurse\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    , audio equipment, tripods, batteries, etc. Works in all kinds of weather conditions.\n",
        "Statement about Other Duties:\n",
        "The foregoing is not necessarily an exhaustive list of all functions essential to the job for which the employee is responsible, nor an exhaustive list of the minimum requirements and specifications necessary to perform the essential functions, including all responsibilities, skills, duties, requirements, efforts, or working conditions associated with the job. While this is intended to be an accurate reflection of the current job, management reserves the right to revise the job or to require that other or different functions be performed when circumstances change or exigencies require it.\n",
        "Interested parties should submit resume, reel (links) and references to Robby Ferguson, Chief Photographer, KFSM-TV via e-mail (preferred method) to robby.ferguson@kfsm.com or by mail to 4201 North Shiloh Dr. Suite 169, Fayetteville, AR 72703<|endoftext|>J.H. Haag House\n",
        "\n",
        "J.H. Haag House is a historic home located at Garrett, DeKalb County, Indiana.  It was built about 1875, and is a two-story, Italianate-style brick dwelling. It has a cross gable roof and two-story gabled wing.\n",
        "\n",
        "It was added to the National Register of Historic Places in 1983.\n",
        "\n",
        "References\n",
        "\n",
        "Category:Houses on the National Register of Historic Places in Indiana\n",
        "Category:Italianate architecture in Indiana\n",
        "Category:Houses completed in 1875\n",
        "Category:Houses in DeKalb County, Indiana\n",
        "Category:National Register of Historic Places in DeKalb County, Indiana<|endoftext|>B.C. Premier Christy Clark says 2012 has been a challenging year but she's confident of the road ahead, including her party's chances in the coming provincial election.\n",
        "\n",
        "Clark said despite trailing the opposition by more than a dozen points in the polls for most of the year and a number of high-profile resignations in her cabinet, she feels good about what she has accomplished in 2012.\n",
        "\n",
        "\"It's been busy. It's been challenging. Probably in many ways it's been the best year of my life,\" Clark told CBC News Vancouver host Gloria Macarenko during a year-end interview.\n",
        "\n",
        "The premier said a big part of that confidence has come from focusing on her own agenda with her jobs plan, as opposed to continuing what was started by her predecessor.\n",
        "\n",
        "\"We've really been living that plan and so that has been something of my making, of my government's making.\"\n",
        "\n",
        "As for 2013 and the upcoming May provincial election, Clark isn't making any bold predictions but says she is optimistic about her party's chances.\n",
        "\n",
        "\"I'm confident when people sit down and really ask themselves the question about where they want their economy to go, that they'll look at the plan that we've delivered and say, 'You know what? It wasn't perfect, but they got the big things right.'\"\n",
        "\n",
        "Clark was elected as the leader of the B.C. Liberal Party in February 2011. The upcoming May 14 provincial election will be her first as the party's leader.\n",
        "\n",
        "Also on HuffPost:\n",
        "\n",
        "Close\n",
        "\n",
        "���\n",
        "\n",
        "Who Is Canada's Least Popular Premier?\n",
        "\n",
        "of\n",
        "\n",
        "���\n",
        "\n",
        "���\n",
        "\n",
        "Angus Reid Public Opinion surveyed 6,657 Canadian adults from August 21 to August 27, 2012. The margin of error is +/- 1.2 per cent, 19 times out of 20.<|endoftext|>Spatial cognition in children. II. Visuospatial and constructional skills in developmental reading disability.\n",
        "Cognitive models for developmental dyslexia are nowadays centered on the hypothesis of a specific deficit within the phonologic module of the language system. To ascertain whether defects of spatial cognition are associated with developmental reading disability, we investigated a sample of 43 school children (aged 8-9 years) found to be reading impaired during a wide screening survey for developmental dyslexia in the province of Naples, Italy. After one year all children were tested again and only 9/43 still presented reading impairment, while the remaining had achieved a variable range of spontaneous recovery. A detailed analysis was performed on all children to characterize their cognitive performances using on one hand classical conventional tests for constructional praxis, visuospatial cognition, and visuospatial memory and on the other a specific neuropsychological battery for constructional disorders. The results of our study demonstrated that children with long-lasting reading impairment exhibited normal performances on spatial cognition tasks. Moreover, one single child was found with relevant visuospatial deficits pointing to the possible existence of a visuospatial subtype for developmental dyslexia.<|endoftext|>Venice, Day 2\n",
        "\n",
        "We had spend a lot of time people watching and gelato eating in Piazza San Marco, but this morning we decided to head up the Campanile Bell Tower (thankfully there was\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "m-RePlDutkmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippets_4_912 = [\n",
        "    r\"\"\"\n",
        "    Conclusion\n",
        "==========\n",
        "\n",
        "Phenformin significantly inhibited both the development and growth of established MCF7 and MDAMB231 tumours without murine toxicity. The potential for phenformin should be considered further as an antineoplastic agent of greater *in vivo* efficacy than metformin for the treatment of breast cancer.\n",
        "\n",
        "We would like to thank the Breast Cancer Research, Scotland, for financial support.\n",
        "\n",
        "This work is published under the standard license to publish agreement. After 12 months the work will become freely available and the license terms will switch to a Creative Commons Attribution-NonCommercial-Share Alike 3.0 Unported License.\n",
        "\n",
        "![Effect of 300 mg kg^−1^ phenformin on human breast MCF7 (**A**) and MDAMB231 (**B**), and 300 mg kg^−1^ metformin on MDAMB231 (**C**) tumour xenografts. For the phenformin experiment, mice were divided into three groups. Controls received no phenformin. Pre-treatment mice were given phenformin (300 mg kg^−1^) in 5% sucrose instead of normal drinking water for 2 weeks prior to injection of MCF7 or MDAMB231 cells. The phenformin group received normal drinking water until tumours reached ���30 mm^3^, after which drinking water was replaced with 5% sucrose containing phenformin (300 mg kg^−1^). Control group also had water replaced with 5% sucrose. For the metformin experiment, mice were divided into two groups. Controls received no metformin and mice with established tumours received metformin (300 mg kg^−1^) in water. MCF7 tumours pre-treated or treated with phenformin had statistically significant inhibition of tumour growth of 88% relative to the control group (*P*\\<0.05). Animals injected with MDAMB231 cells and treated prophylactically with phenformin showed small lumps 6 weeks after inoculation, which remained static for the rest of the experiment. Established MDAMB231 tumours treated with phenformin demonstrated statistically significant inhibition of tumour growth of 60% relative to the control group (*P*\\<0.05). There were no statistically significant differences between control mice and mice treated with metformin.](bjc201256f1){#fig1}\n",
        "\n",
        "![Connective tissue histological analysis of MCF7 and MDAMB231 xenografts treated with phenformin using Van Gieson stain. MCF7 tumours treated with phenformin showed substantial increase of connective tissue, demonstrated as red/pink staining, which replaces epithelial tumour cells (**A** and **B**). No differences were observed in MDAMB231 tumours (**C** and **D**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies, Vista, CA, USA.](bjc201256f2){#fig2}\n",
        "\n",
        "![Phospho-histone H3 immunohistochemistry analysis of MCF7 and MDAMB231 xenografts treated with phenformin. Tumours were harvested and immunohistochemistry analysis performed as described in Materials and methods. No significant differences were observed for phenformin (**B** and **D**) compared with untreated MCF7 and MDAMB231 tumours (**A** and **C**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies.](bjc201256f3){#fig3}\n",
        "\n",
        "![Cleaved PARP analysis of MCF7 and MDAMB231 xenografts treated with phenformin. Tumours were harvested and immunohistochemistry analysis performed as described in Materials and methods. No significant differences were observed for phenformin (**B** and **D**) compared with untreated MCF7 and MDAMB231 tumours (**A** and **C**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies.](bjc201256f4){#fig4}\n",
        "\n",
        "![Ki67 immunohistochemistry analysis of MCF7 and MDAMB231 xenografts treated with phenformin. Tumours were harvested and immunohistochemistry analysis performed as described in Materials and methods. No significant differences were observed for MCF7 tumour treated with phenformin compared with control (**A** and **B**). Similar results were found for MDAMB231 tumours (**C** and **D**), × 5 magnified image captured with an Aperio ScanScope XT, Aperio Technologies.](bjc201256f5){#fig5}\n",
        "\n",
        "![AMPK activation in liver and spleen of mice. Liver and spleen of control mice and mice that were pre-treated or treated after xenograft establishment with 300 mg kg^−1^ phenformin were processed and western blots produced as described in Materials and methods. Lanes 1--4 show the results for control mice, lanes 5--9 show the results for mice pre-treated with phenformin and lanes 10--13 show the results for mice treated with phenformin. Phosphorylation of the activation loop of AMPK (T172) was enhanced in liver and spleen from mice pre-treated or treated (lanes 10--13) with phenformin\n",
        "    \"\"\",\n",
        "    r\"\"\"\n",
        "    10 days in increasing doses of MMC. Average and s.d. of at least three repeats is shown. (**B**) Survival as measured by MTT assay of short-term primary UM cells after 14 days in 50 n MMC. Cells were extracted from short-term primary UM cultures and tested before passage 5. Survival fraction is the OD value in MMC/the OD value seen in the same cell line grown for 14 days without treatment. Average and s.d. of three repeats are shown, except for two primary cultures where limited passages meant that one repeat was completed, in this case the value obtained from one repeat is shown without error bars.](bjc201156f1){#fig1}\n",
        "\n",
        "![Mitomycin C induces fewer DNA ICLs in UM. (**A**) Average TM in UM (SOM 157d, SOM 196b) and control cell lines untreated, treated with 10 Gy IR or pretreated with 150 *μ* MMC for 1 h before being treated with IR. The average TM was calculated using CometScore software where at least 50 cells were analysed on each of three occasions and the s.d. is shown. Significance was determined using the Student\\'s *t*-test where *n*=3 and *P*\\<0.01 is indicated by ^\\*\\*^. (**B**) MMC-induced percentage decrease in migration calculated for each cell line. The decrease is directly proportional to the amount of ICLs formed. Average and s.d. are shown for at least two repeats. (**C**) Representative COMET assay images for each of the treatments. Images were obtained using the full spectrum function of the CometScore computer software. Cells were originally stained with SYBR Safe DNA gel stain.](bjc201156f2){#fig2}\n",
        "\n",
        "![Mitomycin C induces fewer *γ-*H2AX foci and less cell cycle arrest in UM. (**A**) Quantification of *γ-*H2AX foci formation in UM (SOM 157d, SOM 196b) and control cell lines with and without incubation in 90 n MMC for 1 h. Average and s.d. of three repeats is shown. Significance was calculated using the Student\\'s *t*-test where *n*=3 and *P*\\<0.001 is indicated by ^\\*\\*\\*^. (**B**) Percentage of cells in G2-phase of the cell cycle with or without incubation in 90 n MMC for 24 h as measured by PI staining. Average and s.d. of three repeats is shown. Significance was calculated using the Student\\'s *t*-test where *n*=3 and ^\\*^*P*\\<0.05.](bjc201156f3){#fig3}\n",
        "\n",
        "![Uveal melanoma exhibit reduced expression of CYP450R. (**A**) Western blot for cytochrome p450 reductase (CYP450R), DTD (NQO1) and *β*-ACTIN protein expression in UM (SOM 157d, SOM 196b) and control cell lines. (**B**) Western blot for CYP450R and *β*-ACTIN protein expression in cells extracted from primary UM short-term cultures and tested before passage 5.](bjc201156f4){#fig4}\n",
        "\n",
        "![Complementation of UM cell lines with CYP450R increases sensitivity to MMC. Western blot for cytochrome p450 reductase (CYP450R) and *β*-ACTIN protein expression in (**A**) control (WM793) and (**C**) UM (SOM 196b) cell lines 48 h after transfection with or without a plasmid expressing CYP450R. (**B** and **D**) Clonogenic survival of cell lines shown above after 10 days in increasing doses of MMC. Average and s.d. of at least three repeats is shown.](bjc201156f5){#fig5}\n",
        "\n",
        "![Uveal melanoma is resistant to cisplatin but not to HU. Clonogenic survival of UM (SOM 157d, SOM 196b) and control cell lines after 10 days in increasing doses of (**A**) cisplatin and (**B**) HU. Average and s.d. of at least three repeats is shown.](bjc201156f6){#fig6}\n",
        "\n",
        "###### Clinicopathological details for patients with primary uveal melanoma, and correlation with genetic markers of poor prognosis\n",
        "\n",
        "  **SOM**    **Sex**  **Cell type**          **Tumour location**   **Copy number for chromosomes 3 and 8 respectively, as determined by FISH[a](#t1-fn2){ref-type=\"fn\"}**\n",
        "  --------- --------- ---------------------- --------------------- --------------------------------------------------------------------------------------------------------\n",
        "  SOM520        F     Cilary body            Spindle               2 : 2 Good prognosis\n",
        "  SOM524        F     Ciliary body           Mixed                 2 : 3 Poor prognosis\n",
        "  SOM526        F     Ciliary body           Mixed                 2 :\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "K5oEFD2i1Fa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdT54W_fwTNw",
        "outputId": "4562422f-6cab-46b2-fbc8-1088d6987951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForMaskedLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "aug_model_checkpoint = \"distilbert-base-uncased\"\n",
        "aug_model = TFAutoModelForMaskedLM.from_pretrained(aug_model_checkpoint)\n",
        "aug_tokenizer = AutoTokenizer.from_pretrained(aug_model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "4fe3198e6d534415a59925d48297c5ee",
            "5b370130b7854e4b948137616ff27ca2",
            "90b2bb9ddb3044d3b60f99860b911c07",
            "89ce9735ddbe47e2a6ba800fc7d8a2bc",
            "8b028ec711814a31918ecc737842febf",
            "6687556f56d54e1ea7b120b3ae9f596e",
            "604886b115584c158de2cfe2aef26009",
            "fa35d84e07894963aabd23ea196b0a75",
            "fbba856676b14be69ca9df425999535e",
            "b98a44690e6c4e13a590305ae5138928",
            "e07fadc538504408870ce34ca959b25d",
            "44ca027c6bca40d9950af2fc317e3f1a",
            "860efee2c4544efc9c4ccf5daa53db62",
            "18d6ac9ea01b4913ba0f11f4d1bbc7cf",
            "cacfe9ade35d4192a0e6e2e0a7785a7b",
            "c060b2d3634647e086f7f24b40721e73",
            "714753c470364fd88619f597c86f3a74",
            "b437aee6f1bf48f2b0bd8946f25deb28",
            "a2f33f6cca89432ba9724520fa3dfe44",
            "b60c1f91555e4ee58f3f5bbe1b649cac",
            "8fbd2d14ad734c4092d1bf726cb18215",
            "6d1aaea96f644c518924b41d41c3fdd3",
            "256cb59c0cc9496d959e47639801d885",
            "3e9ee166245d4f2a949020142be816a0",
            "526be9bad92e4c1ca2f1f51956c42a82",
            "bd266f07b25c4de79b88dfecaa9b574f",
            "42d82908ec804884801b842091a40a60",
            "f0e8505d2f944f65a8a0d1d6df402dcb",
            "0330e64740d444b2a823c0de4f257b5c",
            "e4cd7d9e94854ec380d6818aad6a2b4e",
            "22f34cbdcd884e428c5861ec3a7cccdc",
            "bb5104ec619c4337a709df9a35303ae3",
            "64c6cf95c5a34e0894f06f3d7967549a",
            "931408006b614426af136166a0445eed",
            "707d6b94f69d43edadc869cc2279d7a9",
            "c1aaf59d86304f798cdf8332ae79752a",
            "358a2e86086a4560bdc94c43812bc9e6",
            "17de8dac4182475aa74dece6eb128bc1",
            "41f0a76d2d244ab9921eb54344e0d3f6",
            "eb22eb1208ac4bfbb77fc19a2d14da14",
            "b70673e8815a478aa6cd34688952ec10",
            "75226eec7f70456a8ab6f1d78261edcb",
            "98f67ab83ff145558e756c12832e81e5",
            "ab09b71b87dc4d38bd72be371519bc10",
            "e5120496fb7242b487e890a5e1e4302a",
            "924ff429ca5c4a648b17085beb2e77fd",
            "fa84937a9c9b4d9ba7fab4f89f8e64fb",
            "dd0ee63428db4031b27cdd3abf5e36ac",
            "ce7f92a343d84eab9a6183387e520c23",
            "a0eeb8a18db4465780369fbf2c24cee7",
            "adbfc5c8a77741b39d5a97bac3326756",
            "49532d6c320a4877ac1d7a6b3098dd26",
            "841f0e3d66124ce9944a95c22894da73",
            "1f08de6d9b904cab82f5cc51429abb9b",
            "93211bcf245245919309e6e1f733789a"
          ]
        },
        "id": "WthFIEKnpf6B",
        "outputId": "d1e3b330-d505-4afe-8b06-b71e9bd4f6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fe3198e6d534415a59925d48297c5ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44ca027c6bca40d9950af2fc317e3f1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForMaskedLM.\n",
            "\n",
            "All the weights of TFDistilBertForMaskedLM were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "256cb59c0cc9496d959e47639801d885"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "931408006b614426af136166a0445eed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5120496fb7242b487e890a5e1e4302a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import re\n",
        "\n",
        "class ContextualAugmenter:\n",
        "  def __init__(self, model, tokenizer, neuron_model):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.neuron_model = neuron_model\n",
        "    self.stops = set(stopwords.words('english'))\n",
        "    self.punctuation_set = set(punctuation)\n",
        "    self.to_strip = \" \" + punctuation\n",
        "    # self.word_tokenizer = re.compile(\"[ \\[\\]\\(\\)]\")\n",
        "    self.word_tokenizer = re.compile(r\"\\b\")\n",
        "\n",
        "\n",
        "  def augment(self, text, n=5):\n",
        "    tokens = self.word_tokenizer.split(text)\n",
        "    # tokens = text.split(\" \")\n",
        "    # print(tokens)\n",
        "    masked_tokens = copy.deepcopy(tokens)\n",
        "    all_new_texts = []\n",
        "    all_positions = []\n",
        "\n",
        "    neuron_tokens = self.neuron_model.to_str_tokens(text)\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "      if token in {\"\", \" \"} or token.strip(self.to_strip).lower() in self.stops:\n",
        "        continue\n",
        "      masked_tokens[i] = \"[MASK]\"\n",
        "      before = tokens[:i]\n",
        "      before_text = \"\".join(before)\n",
        "      position = len(before_text)\n",
        "      # print(masked_tokens)\n",
        "      masked_text = \"\".join(masked_tokens)\n",
        "      inputs = self.tokenizer(masked_text, return_tensors=\"np\")\n",
        "      token_logits = self.model(**inputs).logits\n",
        "      # Find the location of [MASK] and extract its logits\n",
        "      mask_token_index = np.argwhere(inputs[\"input_ids\"] == self.tokenizer.mask_token_id)[0, 1]\n",
        "      mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "      # Pick the [MASK] candidates with the highest logits\n",
        "      # We negate the array before argsort to get the largest, not the smallest, logits\n",
        "      top_tokens = np.argsort(-mask_token_logits).tolist()\n",
        "\n",
        "      new_texts = []\n",
        "      positions = []\n",
        "      for j, top_token in enumerate(top_tokens):\n",
        "        candidate_token = self.tokenizer.decode([top_token])\n",
        "        normalised_candidate = candidate_token.strip(self.to_strip).lower() if candidate_token not in self.punctuation_set else candidate_token\n",
        "        normalised_token = token.strip(self.to_strip).lower() if token not in self.punctuation_set else token\n",
        "        # print(\"token, top_token\", [normalised_token], [normalised_candidate])\n",
        "\n",
        "        if normalised_candidate == normalised_token:\n",
        "          continue\n",
        "        new_text = masked_text.replace(self.tokenizer.mask_token, candidate_token)\n",
        "        new_texts.append(new_text)\n",
        "        positions.append(position)\n",
        "        # print(len(new_texts), j, n)\n",
        "        if len(new_texts) >= n or j >= n + 5:\n",
        "          break\n",
        "\n",
        "      all_new_texts.extend(new_texts)\n",
        "      all_positions.extend(positions)\n",
        "      masked_tokens[i] = token\n",
        "\n",
        "    return all_new_texts, all_positions"
      ],
      "metadata": {
        "id": "OyHgzc3bmGWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contextual_aug = ContextualAugmenter(aug_model, aug_tokenizer, model)"
      ],
      "metadata": {
        "id": "3mtGC3yeqG_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contextual_aug.augment(\"This is a test.\", n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak8NfDHzpxhr",
        "outputId": "6ce2a934-2427-48a5-a6d2-249581ff051b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['This is a list.',\n",
              "  'This is a timeline.',\n",
              "  'This is a test:',\n",
              "  'This is a test!'],\n",
              " [10, 10, 14, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augs = [\n",
        "    contextual_aug\n",
        "]"
      ],
      "metadata": {
        "id": "qJATNug8WlzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from collections import defaultdict\n",
        "from string import punctuation\n",
        "import re\n",
        "import copy\n",
        "\n",
        "splitter = re.compile(\"[\\.!\\\\n]\")\n",
        "\n",
        "def sentence_tokenizer(str_tokens):\n",
        "  sentences = []\n",
        "  sentence = []\n",
        "  sentence_to_token_indices = defaultdict(list)\n",
        "  token_to_sentence_indices = {}\n",
        "\n",
        "  for i, str_token in enumerate(str_tokens):\n",
        "    sentence.append(str_token)\n",
        "    sentence_to_token_indices[len(sentences)].append(i)\n",
        "    token_to_sentence_indices[i] = len(sentences)\n",
        "    # if splitter.search(str_token) is not None or i + 1 == len(str_tokens):\n",
        "    if str_token in {\".\", \"\\n\"} or i + 1 == len(str_tokens):\n",
        "      sentences.append(sentence)\n",
        "      sentence = []\n",
        "\n",
        "  return sentences, sentence_to_token_indices, token_to_sentence_indices\n",
        "\n",
        "\n",
        "def prune(model, layer, neuron, prompt, max_length=1024, proportion_threshold=-0.5, window=4):\n",
        "  prepend_bos = True\n",
        "  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n",
        "  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n",
        "\n",
        "  # print(tokens)\n",
        "  # print(str_tokens)\n",
        "  # print(tokens.shape)\n",
        "\n",
        "  if len(tokens[0]) > max_length:\n",
        "    tokens = tokens[0, :max_length].unsqueeze(0)\n",
        "\n",
        "  # print(tokens.shape)\n",
        "  # print(prompt)\n",
        "  # print(\"tokens\", tokens)\n",
        "  # print(\"str_tokens\", str_tokens)\n",
        "\n",
        "  logits, cache = model.run_with_cache(tokens)\n",
        "  activations = cache[layer][0, :, neuron]\n",
        "\n",
        "  initial_max = torch.max(activations).cpu().item()\n",
        "  initial_argmax = torch.argmax(activations).cpu().item()\n",
        "\n",
        "  # print(\"initial_max\", initial_max)\n",
        "  # print(\"initial_argmax\", initial_argmax)\n",
        "\n",
        "  sentences, sentence_to_token_indices, token_to_sentence_indices = sentence_tokenizer(str_tokens)\n",
        "\n",
        "  max_sentence_index = token_to_sentence_indices[initial_argmax]\n",
        "  sentence = sentences[max_sentence_index]\n",
        "\n",
        "  offset = sentence_to_token_indices[max_sentence_index][0]\n",
        "  max_token_index = initial_argmax - offset\n",
        "\n",
        "  shortest_prompt = sentence\n",
        "  shortest_successful_prompt = None\n",
        "  for i, index in enumerate([len(sentence) - min((max_token_index + window), len(sentence)), max(0, max_token_index - window)]):\n",
        "    sentence = shortest_prompt\n",
        "    for j in range(index):\n",
        "      if i == 0:\n",
        "        truncated_prompt = shortest_prompt[:-1]\n",
        "      else:\n",
        "        truncated_prompt = shortest_prompt[1:]\n",
        "\n",
        "      # print(\"shortest_prompt\", shortest_prompt)\n",
        "      # print(j)\n",
        "      # print(\"truncated_prompt\", truncated_prompt)\n",
        "\n",
        "      joined = \"\".join(truncated_prompt)\n",
        "      # joined = \"\".join(sentence)\n",
        "\n",
        "      # print(\"\\n\")\n",
        "      # print([joined])\n",
        "      # print(model.to_str_tokens(joined, prepend_bos=prepend_bos))\n",
        "\n",
        "      sentence_tokens = model.to_tokens(joined, prepend_bos=prepend_bos)\n",
        "      logits, cache = model.run_with_cache(sentence_tokens)\n",
        "      activations = cache[layer][0, :, neuron]\n",
        "      sentence_argmax = torch.argmax(activations).cpu().item() + offset\n",
        "      if prepend_bos:\n",
        "        sentence_argmax -= 1\n",
        "      if i == 1:\n",
        "        sentence_argmax += j + 1\n",
        "      sentence_max = torch.max(activations).cpu().item()\n",
        "\n",
        "      # print(sentence_max)\n",
        "      # print(sentence_argmax)\n",
        "      shortest_prompt = truncated_prompt\n",
        "\n",
        "      if sentence_argmax == initial_argmax and (sentence_max - initial_max) / initial_max > proportion_threshold:\n",
        "        shortest_successful_prompt = copy.deepcopy(truncated_prompt)\n",
        "\n",
        "  return \"\".join(shortest_successful_prompt) if shortest_successful_prompt is not None else None\n",
        "\n",
        "def augment(model, layer, index, prompt, augs, max_length=1024, inclusion_threshold=-0.5, exclusion_threshold=-0.8, n=1):\n",
        "  prepend_bos = True\n",
        "  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n",
        "  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n",
        "\n",
        "  if len(tokens[0]) > max_length:\n",
        "    tokens = tokens[0, :max_length].unsqueeze(0)\n",
        "\n",
        "  # print(tokens)\n",
        "  # print(str_tokens)\n",
        "\n",
        "  logits, cache = model.run_with_cache(tokens)\n",
        "  activations = cache[layer][0, :, index]\n",
        "\n",
        "  initial_max = torch.max(activations).cpu().item()\n",
        "  initial_argmax = torch.argmax(activations).cpu().item()\n",
        "  max_char_position = len(\"\".join(str_tokens[int(prepend_bos):initial_argmax]))\n",
        "  # print(\"initial_max\", initial_max)\n",
        "  # print(\"initial_argmax\", initial_argmax)\n",
        "\n",
        "  positive_prompts = [(prompt, initial_max)]\n",
        "  negative_prompts = []\n",
        "  # print(\"starting prompt\", prompt)\n",
        "  for aug in augs:\n",
        "    aug_prompts, aug_positions = aug.augment(prompt, n=n)\n",
        "    aug_tokens = model.to_tokens(aug_prompts, prepend_bos=prepend_bos)\n",
        "    aug_logits, aug_cache = model.run_with_cache(aug_tokens)\n",
        "    all_aug_activations = aug_cache[layer][:, :, index]\n",
        "\n",
        "    for aug_prompt, char_position, aug_activations in zip(aug_prompts, aug_positions, all_aug_activations):\n",
        "      aug_max = torch.max(aug_activations).cpu().item()\n",
        "      aug_argmax = torch.argmax(aug_activations).cpu().item()\n",
        "      # print(aug_max)\n",
        "      # print(\"actual aug_argmax\", aug_argmax)\n",
        "\n",
        "      # print(str_tokens)\n",
        "      # print(model.to_str_tokens(aug_prompt, prepend_bos=prepend_bos))\n",
        "      # print(char_position, max_char_position, aug_argmax)\n",
        "      if char_position < max_char_position:\n",
        "        new_str_tokens = model.to_str_tokens(aug_prompt, prepend_bos=prepend_bos)\n",
        "        aug_argmax += len(new_str_tokens) - len(str_tokens)\n",
        "        # print(\"len(new_str_tokens)\", len(new_str_tokens))\n",
        "        # print(\"len(str_tokens)\", len(str_tokens))\n",
        "        # print(\"adjusted aug_argmax\", aug_argmax)\n",
        "\n",
        "      proportion_drop = (aug_max - initial_max) / initial_max\n",
        "\n",
        "      if proportion_drop > inclusion_threshold:\n",
        "        positive_prompts.append((aug_prompt, aug_max, proportion_drop))\n",
        "      elif proportion_drop < exclusion_threshold:\n",
        "        negative_prompts.append((aug_prompt, aug_max, proportion_drop))\n",
        "\n",
        "  return positive_prompts, negative_prompts"
      ],
      "metadata": {
        "id": "4lVq8zY1ZNNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_3_1:\n",
        "  pruned_prompt = prune(model, \"blocks.3.mlp.hook_mid\", 1, snippet, window=3)\n",
        "  print([pruned_prompt])\n",
        "  if pruned_prompt is None:\n",
        "    continue\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.3.mlp.hook_mid\", 1, pruned_prompt, augs, n=4)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWd4qY6VM9kk",
        "outputId": "a7446852-8d2e-41ee-ceed-00c8addad84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" The thought didn't even cross my mind\"]\n",
            "positive [(\" The thought didn't even cross my mind\", 0.5641509294509888), (\" The words didn't even cross my mind\", 0.28522393107414246, -0.49441910633434205), (\" The question didn't even cross my mind\", 0.36284705996513367, -0.3568262657685537), (\" The idea didn't even cross my mind\", 0.4032665193080902, -0.28517973071402264), (' The thought didn’t even cross my mind', 0.5588909983634949, -0.009323623897265702), (' The thought didn`t even cross my mind', 0.4473731517791748, -0.20699740366546568), (' The thought didn=t even cross my mind', 0.3544962406158447, -0.3716287218372083), (' The thought didn′t even cross my mind', 0.3767392635345459, -0.33220128893313194), (\" The thought didn't immediately cross my mind\", 0.47130563855171204, -0.16457526887287133), (\" The thought didn't completely cross my mind\", 0.48807692527770996, -0.134846900362836), (\" The thought didn't quite cross my mind\", 0.518216073513031, -0.08142299079904007), (\" The thought didn't exactly cross my mind\", 0.4073651432991028, -0.2779146110854842), (\" The thought didn't even cross my .\", 0.5641501545906067, -1.3734983700800496e-06), (\" The thought didn't even cross my heart\", 0.5641501545906067, -1.3734983700800496e-06), (\" The thought didn't even cross my skin\", 0.5641501545906067, -1.3734983700800496e-06), (\" The thought didn't even cross my stomach\", 0.5641501545906067, -1.3734983700800496e-06)]\n",
            "negative [(\" The thought didn't even touch my mind\", 0.08117473125457764, -0.8561116768280893), (\" The thought didn't even occupy my mind\", 0.10757307708263397, -0.809318621193587)]\n",
            "\n",
            "\n",
            "[' a thought that would cross my mind']\n",
            "positive [(' a thought that would cross my mind', 0.3207255005836487), (' a question that would cross my mind', 0.17470508813858032, -0.4552815793547562), (' a dream that would cross my mind', 0.20599623024463654, -0.3577179554797811), (' a feeling that would cross my mind', 0.2329348921775818, -0.2737250647245312), (' a thought that might cross my mind', 0.28260600566864014, -0.1188539571865648), (' a thought that could cross my mind', 0.21652577817440033, -0.32488755094193683), (' a thought that will cross my mind', 0.29058152437210083, -0.09398683970152844), (' a thought that can cross my mind', 0.18536093831062317, -0.4220573731327639), (' a thought that would cross my heart', 0.3207249939441681, -1.579666972750373e-06), (' a thought that would cross my .', 0.3207249939441681, -1.579666972750373e-06), (' a thought that would cross my soul', 0.3207249939441681, -1.579666972750373e-06), (' a thought that would cross my veins', 0.3207249939441681, -1.579666972750373e-06)]\n",
            "negative [(' a thought that would haunt my mind', 0.03651097044348717, -0.8861613112239427), (' a thought that would fill my mind', 0.019201800227165222, -0.9401301106640344), (' a thought that would occupy my mind', 0.06379438936710358, -0.8010934919393311)]\n",
            "\n",
            "\n",
            "[\" the thought of playing further probably didn't cross Hungry\"]\n",
            "positive [(\" the thought of playing further probably didn't cross Hungry\", 0.4925268888473511), (\" the thought of going further probably didn't cross Hungry\", 0.5491595268249512, 0.11498385014092552), (\" the thought of moving further probably didn't cross Hungry\", 0.41414254903793335, -0.15914733100736636), (\" the thought of getting further probably didn't cross Hungry\", 0.4121707081794739, -0.16315085021232617), (\" the thought of it further probably didn't cross Hungry\", 0.45013076066970825, -0.08607880937599462), (\" the thought of playing further out didn't cross Hungry\", 0.4554440975189209, -0.07529089714312684), (\" the thought of playing further games didn't cross Hungry\", 0.338706374168396, -0.31230886711370737), (\" the thought of playing further along didn't cross Hungry\", 0.3297443389892578, -0.3305048994158459), (' the thought of playing further probably didn’t cross Hungry', 0.4783133864402771, -0.02885832779675744), (' the thought of playing further probably didn`t cross Hungry', 0.38208556175231934, -0.22423410700174146), (' the thought of playing further probably didn\"t cross Hungry', 0.31668713688850403, -0.35701553750773), (\" the thought of playing further probably didn't cross .\", 0.492527037858963, 3.025451306571401e-07), (\" the thought of playing further probably didn't cross ;\", 0.492527037858963, 3.025451306571401e-07), (\" the thought of playing further probably didn't cross :\", 0.492527037858963, 3.025451306571401e-07), (\" the thought of playing further probably didn't cross ?\", 0.492527037858963, 3.025451306571401e-07)]\n",
            "negative [(\" the thought of playing further probably didn't seem Hungry\", 0.015294071286916733, -0.9689477434973975), (\" the thought of playing further probably didn't sound Hungry\", 0.04927101358771324, -0.8999627945125575), (\" the thought of playing further probably didn't help Hungry\", 0.0366876982152462, -0.9255112785799258), (\" the thought of playing further probably didn't hurt Hungry\", 0.042147427797317505, -0.9144261384470721)]\n",
            "\n",
            "\n",
            "[' The thought did briefly cross my mind']\n",
            "positive [(' The thought did briefly cross my mind', 0.35408151149749756), (' The thought did not cross my mind', 0.44871440529823303, 0.26726301918592066), (' The thought did indeed cross my mind', 0.31471899151802063, -0.11116796189951623), (' The thought did eventually cross my mind', 0.356440931558609, 0.006663494095280163), (' The thought did finally cross my mind', 0.4307894706726074, 0.2166392671865105), (' The thought did briefly cross my .', 0.3540809452533722, -1.599191448803485e-06), (' The thought did briefly cross my heart', 0.3540809452533722, -1.599191448803485e-06), (' The thought did briefly cross my skin', 0.3540809452533722, -1.599191448803485e-06), (' The thought did briefly cross my eyes', 0.3540809452533722, -1.599191448803485e-06)]\n",
            "negative [(' The memory did briefly cross my mind', 0.06387186795473099, -0.81961253022051), (' The image did briefly cross my mind', 0.06579767167568207, -0.8141736590611366), (' The thought did briefly occupy my mind', 0.06400439888238907, -0.819238235253519), (' The thought did briefly touch my mind', 0.0650738850235939, -0.8162177834465841), (' The thought did briefly haunt my mind', 0.04034968093037605, -0.8860440897924114)]\n",
            "\n",
            "\n",
            "[' the thought did briefly cross my mind']\n",
            "positive [(' the thought did briefly cross my mind', 0.34335750341415405), (' the words did briefly cross my mind', 0.18898484110832214, -0.44959746261793293), (' the thought did not cross my mind', 0.4154031276702881, 0.20982685259460718), (' the thought did indeed cross my mind', 0.2942322790622711, -0.14307310562142755), (' the thought did eventually cross my mind', 0.3496294319629669, 0.018266467126677975), (' the thought did finally cross my mind', 0.4276314973831177, 0.24544095623654757), (' the thought did briefly cross my .', 0.3433556854724884, -5.294602994176111e-06), (' the thought did briefly cross my heart', 0.3433556854724884, -5.294602994176111e-06), (' the thought did briefly cross my skin', 0.3433556854724884, -5.294602994176111e-06), (' the thought did briefly cross my eyes', 0.3433556854724884, -5.294602994176111e-06)]\n",
            "negative [(' the memory did briefly cross my mind', 0.057300157845020294, -0.8331180845758146), (' the image did briefly cross my mind', 0.05655977129936218, -0.8352743984419633), (' the thought did briefly occupy my mind', 0.061299022287130356, -0.8214717264728241), (' the thought did briefly touch my mind', 0.06607751548290253, -0.8075547648562654), (' the thought did briefly haunt my mind', 0.038574784994125366, -0.8876541662536587)]\n",
            "\n",
            "\n",
            "[' to see the bill finally pass.']\n",
            "positive [(' to see the bill finally pass.', 0.21282093226909637), (' to let the bill finally pass.', 0.18214480578899384, -0.1441405511809094), (' to make the bill finally pass.', 0.11506354808807373, -0.45934102035327823), (' to help the bill finally pass.', 0.13688865303993225, -0.3567895245057632), (' to watch the bill finally pass.', 0.15941940248012543, -0.25092235627202614), (' to see the bill now pass.', 0.27064549922943115, 0.2717052610558997), (' to see the bill would pass.', 0.19407856464385986, -0.08806637310252062), (' to see the bill eventually pass.', 0.25635242462158203, 0.20454516333686243), (' to see the bill finally passed.', 0.13392682373523712, -0.37070652633972806), (' to see the bill finally passes.', 0.12354626506567001, -0.41948254925669215), (' to see the bill finally passing.', 0.13641904294490814, -0.35899612180809204), (' to see the bill finally pass:', 0.21282117068767548, 1.1202778625182404e-06), (' to see the bill finally pass;', 0.21282117068767548, 1.1202778625182404e-06), (' to see the bill finally pass!', 0.21282117068767548, 1.1202778625182404e-06), (' to see the bill finally pass?', 0.21282117068767548, 1.1202778625182404e-06)]\n",
            "negative [(' to see the day finally pass.', 0.013326101936399937, -0.9373834998544689), (' to see the clouds finally pass.', 0.00415749941021204, -0.9804648003094207), (' to see the night finally pass.', 0.014814223162829876, -0.9303911367886577), (' to see the days finally pass.', 0.010212182998657227, -0.9520151383147563), (' to see the bill finally enacted.', 0.02125813253223896, -0.9001125861747489)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_3_2:\n",
        "  pruned_prompt = prune(model, \"blocks.3.mlp.hook_mid\", 2, snippet, window=3)\n",
        "  print([pruned_prompt])\n",
        "  print(\"\\n\")\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.3.mlp.hook_mid\", 2, pruned_prompt, augs, n=4)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN_H8t7QPBt2",
        "outputId": "f4ed3647-14ff-4cdb-98a4-fa0b5a0778c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' am not a native English speaker']\n",
            "\n",
            "\n",
            "positive [(' am not a native English speaker', 0.28990522027015686), (' am not a native american speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native hawaiian speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native indian speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native language speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English ?', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English .', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English language', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English ;', 0.2899050712585449, -5.140011338865014e-07)]\n",
            "negative [(' am not a fluent English speaker', 0.01956666260957718, -0.9325066910097604), (' am not a proper English speaker', 0.02307438664138317, -0.920407136443143), (' am not a true English speaker', 0.021251223981380463, -0.9266959595912868), (' am not a good English speaker', 0.0231549721211195, -0.9201291646299372)]\n",
            "\n",
            "\n",
            "[' am not a native English speaker']\n",
            "\n",
            "\n",
            "positive [(' am not a native English speaker', 0.28990522027015686), (' am not a native american speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native hawaiian speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native indian speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native language speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English ?', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English .', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English language', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English ;', 0.2899050712585449, -5.140011338865014e-07)]\n",
            "negative [(' am not a fluent English speaker', 0.01956666260957718, -0.9325066910097604), (' am not a proper English speaker', 0.02307438664138317, -0.920407136443143), (' am not a true English speaker', 0.021251223981380463, -0.9266959595912868), (' am not a good English speaker', 0.0231549721211195, -0.9201291646299372)]\n",
            "\n",
            "\n",
            "[' am not a native English speaker']\n",
            "\n",
            "\n",
            "positive [(' am not a native English speaker', 0.28990522027015686), (' am not a native american speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native hawaiian speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native indian speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native language speaker', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English ?', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English .', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English language', 0.2899050712585449, -5.140011338865014e-07), (' am not a native English ;', 0.2899050712585449, -5.140011338865014e-07)]\n",
            "negative [(' am not a fluent English speaker', 0.01956666260957718, -0.9325066910097604), (' am not a proper English speaker', 0.02307438664138317, -0.920407136443143), (' am not a true English speaker', 0.021251223981380463, -0.9266959595912868), (' am not a good English speaker', 0.0231549721211195, -0.9201291646299372)]\n",
            "\n",
            "\n",
            "[' am not a native speaker,']\n",
            "\n",
            "\n",
            "positive [(' am not a native speaker,', 0.28990522027015686), (' am not a native american,', 0.289904922246933, -1.0280022677730027e-06), (' am not a native tribe,', 0.289904922246933, -1.0280022677730027e-06), (' am not a native tongue,', 0.289904922246933, -1.0280022677730027e-06), (' am not a native language,', 0.289904922246933, -1.0280022677730027e-06), (' am not a native speaker?', 0.289904922246933, -1.0280022677730027e-06), (' am not a native speaker.', 0.289904922246933, -1.0280022677730027e-06), (' am not a native speaker…', 0.289904922246933, -1.0280022677730027e-06), (' am not a native speaker!', 0.289904922246933, -1.0280022677730027e-06)]\n",
            "negative [(' am not a good speaker,', 0.0008040671236813068, -0.9972264482752949), (' am not a passive speaker,', 0.0029820678755640984, -0.9897136454708019), (' am not a true speaker,', 0.0022088929545134306, -0.9923806375323114), (' am not a wise speaker,', 0.001080488902516663, -0.9962729581015831)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_3_912:\n",
        "  pruned_prompt = prune(model, \"blocks.3.mlp.hook_mid\", 912, snippet, window=2, proportion_threshold=-0.6)\n",
        "  print([pruned_prompt])\n",
        "  if pruned_prompt is None:\n",
        "    continue\n",
        "  print(\"\\n\")\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.3.mlp.hook_mid\", 912, pruned_prompt, augs, n=2, inclusion_threshold=-0.4, exclusion_threshold=-0.7)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg1fEczXuH3u",
        "outputId": "160e08eb-fd15-428d-c2d0-ee8a5a9850ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' was put on the IUCN Red List under']\n",
            "\n",
            "\n",
            "positive [(' was put on the IUCN Red List under', 0.7422054409980774), (' was placed on the IUCN Red List under', 0.6806845664978027, -0.0828892798435225), (' was listed on the IUCN Red List under', 0.7094075679779053, -0.04418975018031036)]\n",
            "negative [(' was put on the iaaf Red List under', 0.2163352519273758, -0.7085237590868911), (' was put on the nhl Red List under', 0.20250295102596283, -0.7271605140031743), (' was put on the IUCN threatened List under', 0.1870192289352417, -0.748022287894106), (' was put on the IUCN Red ##lists under', 0.046873610466718674, -0.9368455041185287)]\n",
            "\n",
            "\n",
            "[' It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [(' It was added to the National Register of', 0.5029271841049194), (' It was add to the National Register of', 0.40713173151016235, -0.19047578978107588), (' It was named to the National Register of', 0.33700138330459595, -0.3299201276932934), (' It was added to the National list of', 0.44478359818458557, -0.115610346304534)]\n",
            "negative [(' It was added to the state Register of', 0.12866057455539703, -0.7441765356462494), (' It was added to the National inventory of', 0.07945723831653595, -0.8420104523521644)]\n",
            "\n",
            "\n",
            "[' It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [(' It was added to the National Register of', 0.5029271841049194), (' It was add to the National Register of', 0.40713173151016235, -0.19047578978107588), (' It was named to the National Register of', 0.33700138330459595, -0.3299201276932934), (' It was added to the National list of', 0.44478359818458557, -0.115610346304534)]\n",
            "negative [(' It was added to the state Register of', 0.12866057455539703, -0.7441765356462494), (' It was added to the National inventory of', 0.07945723831653595, -0.8420104523521644)]\n",
            "\n",
            "\n",
            "[' It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [(' It was added to the National Register of', 0.5029271841049194), (' It was add to the National Register of', 0.40713173151016235, -0.19047578978107588), (' It was named to the National Register of', 0.33700138330459595, -0.3299201276932934), (' It was added to the National list of', 0.44478359818458557, -0.115610346304534)]\n",
            "negative [(' It was added to the state Register of', 0.12866057455539703, -0.7441765356462494), (' It was added to the National inventory of', 0.07945723831653595, -0.8420104523521644)]\n",
            "\n",
            "\n",
            "['It was added to the National Register of']\n",
            "\n",
            "\n",
            "positive [('It was added to the National Register of', 0.5010598301887512), ('It was add to the National Register of', 0.37060627341270447, -0.26035524884703765), ('It was named to the National Register of', 0.3329397737979889, -0.33552890545512465), ('It was added to the National list of', 0.37604820728302, -0.24949440241226048)]\n",
            "negative [('It was added to the state Register of', 0.11510276794433594, -0.7702813895478784), ('It was added to the National inventory of', 0.0676855742931366, -0.8649151853429576)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for snippet in snippets_4_912:\n",
        "  pruned_prompt = prune(model, \"blocks.4.mlp.hook_mid\", 912, snippet, window=5, proportion_threshold=-0.6)\n",
        "  print([pruned_prompt])\n",
        "  if pruned_prompt is None:\n",
        "    continue\n",
        "  print(\"\\n\")\n",
        "  positive_prompts, negative_prompts = augment(model, \"blocks.4.mlp.hook_mid\", 912, pruned_prompt, augs, n=2, inclusion_threshold=-0.4, exclusion_threshold=-0.7)\n",
        "  print(\"positive\", positive_prompts)\n",
        "  print(\"negative\", negative_prompts)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9265JwgS1T2t",
        "outputId": "40bc58eb-364e-41b5-c742-40dffd0688c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.](bjc201256f1){#fig1']\n",
            "\n",
            "\n",
            "positive [('.](bjc201256f1){#fig1', 2.904813289642334), ('.](bjc201256f1)fig1', 2.9048092365264893, -1.395310280071604e-06), ('.](bjc201256f1]fig1', 2.9048092365264893, -1.395310280071604e-06), ('.](bjc201256f1){#;', 2.9048092365264893, -1.395310280071604e-06), ('.](bjc201256f1){#}', 2.9048092365264893, -1.395310280071604e-06)]\n",
            "negative [('(bjc201256f1){#fig1', 0.0393795408308506, -0.9864433487097894), ('#bjc201256f1){#fig1', 0.04763226583600044, -0.9836022969166925), ('.](\\\\){#fig1', 0.025366371497511864, -0.9912674692077592), ('.](thumb){#fig1', 0.024784665554761887, -0.9914677250881713)]\n",
            "\n",
            "\n",
            "['.](bjc201156f1){#fig1']\n",
            "\n",
            "\n",
            "positive [('.](bjc201156f1){#fig1', 2.9738998413085938), ('.](bjc201156f1)fig1', 2.9739041328430176, 1.4430662271193834e-06), ('.](bjc201156f1]fig1', 2.9739041328430176, 1.4430662271193834e-06), ('.](bjc201156f1){#;', 2.9739041328430176, 1.4430662271193834e-06), ('.](bjc201156f1){#}', 2.9739041328430176, 1.4430662271193834e-06)]\n",
            "negative [('(bjc201156f1){#fig1', 0.04686376079916954, -0.9842416479034652), ('#bjc201156f1){#fig1', 0.046479541808366776, -0.9843708449212888), ('.](\\\\){#fig1', 0.025366371497511864, -0.9914703342913022), ('.](thumb){#fig1', 0.024784665554761887, -0.991665938035137)]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OUR ORIGINAL CODE CONTRIBUTION STARTS HERE\n",
        "\n",
        "#### THE ABOVE CODE IS FROM A PROJECT WE FOUND ELSEWHERE\n",
        "\n",
        "#### THE BELOW CODE IS OUR OWN ORIGINAL EXTENSIONS TO THE PROJECT :)"
      ],
      "metadata": {
        "id": "JS5KWQKEQO4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "class IterativeMultiTokenAugmenter:\n",
        "    def __init__(\n",
        "        self,\n",
        "        mlm_model,           # e.g. DistilBERT\n",
        "        mlm_tokenizer,\n",
        "        hooking_model,       # your interpretability model with .run_with_cache\n",
        "        layer_name: str,\n",
        "        neuron_index: int,\n",
        "        inclusion_threshold: float = -0.4,\n",
        "        exclusion_threshold: float = -0.7,\n",
        "        max_length: int = 1024\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Iterative multi-token augmentation:\n",
        "          - Replaces tokens one at a time using an MLM\n",
        "          - Measures neuron activation each time\n",
        "          - Classifies replacements as positive or negative based on proportion_drop\n",
        "\n",
        "        We make sure that if the top candidate is the same as the original token,\n",
        "        we try the next candidate, and so on, until we find a truly different token.\n",
        "        If none differ, we skip that token and move on to the next token in the text.\n",
        "        \"\"\"\n",
        "        self.mlm_model = mlm_model\n",
        "        self.mlm_tokenizer = mlm_tokenizer\n",
        "        self.hooking_model = hooking_model\n",
        "        self.layer_name = layer_name\n",
        "        self.neuron_index = neuron_index\n",
        "\n",
        "        self.inclusion_threshold = inclusion_threshold\n",
        "        self.exclusion_threshold = exclusion_threshold\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Simple word tokenizer pattern\n",
        "        self.word_tokenizer = re.compile(r\"\\b\")\n",
        "\n",
        "    def _measure_activation(self, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Measures the maximum activation of the target neuron for `text`.\n",
        "        \"\"\"\n",
        "        tokens = self.hooking_model.to_tokens(text, prepend_bos=True)\n",
        "        if len(tokens[0]) > self.max_length:\n",
        "            tokens = tokens[0, :self.max_length].unsqueeze(0)\n",
        "        _, cache = self.hooking_model.run_with_cache(tokens)\n",
        "        activations = cache[self.layer_name][0, :, self.neuron_index]\n",
        "        return float(torch.max(activations))\n",
        "\n",
        "    def _mask_and_replace(self, text: str, token_index: int, top_k: int = 10):\n",
        "        \"\"\"\n",
        "        Masks out the token at `token_index` in `text` and uses the MLM\n",
        "        to find top UNIQUE replacements. We then loop through them until we\n",
        "        find one that differs from the original token. If none differ, return None.\n",
        "\n",
        "        :param top_k: The number of unique tokens we want to consider.\n",
        "        :return: (replacement_str, original_token) or None if we cannot find any distinct replacement.\n",
        "        \"\"\"\n",
        "        tokens = self.word_tokenizer.split(text)\n",
        "        if token_index < 0 or token_index >= len(tokens):\n",
        "            return None\n",
        "\n",
        "        original_token = tokens[token_index]\n",
        "        # Temporarily replace with [MASK]\n",
        "        tokens[token_index] = \"[MASK]\"\n",
        "        masked_text = \"\".join(tokens)\n",
        "\n",
        "        # Run MLM\n",
        "        inputs = self.mlm_tokenizer(masked_text, return_tensors=\"np\")\n",
        "        outputs = self.mlm_model(**inputs)\n",
        "        logits = outputs.logits  # shape: (batch_size, seq_len, vocab_size)\n",
        "\n",
        "        mask_token_id = self.mlm_tokenizer.mask_token_id\n",
        "        mask_positions = np.argwhere(inputs[\"input_ids\"] == mask_token_id)\n",
        "        if len(mask_positions) == 0:\n",
        "            return None\n",
        "        row, col = mask_positions[0]\n",
        "\n",
        "        token_logits = logits[row, col, :]  # shape: (vocab_size,)\n",
        "        sorted_ids = np.argsort(-token_logits)  # descending logit order\n",
        "\n",
        "        # Collect top_k UNIQUE tokens\n",
        "        unique_candidates = []\n",
        "        for cand_id in sorted_ids:\n",
        "            cand_token = self.mlm_tokenizer.decode([cand_id]).strip()\n",
        "            # skip duplicates ignoring case\n",
        "            if cand_token.lower() not in [u.lower() for u in unique_candidates]:\n",
        "                unique_candidates.append(cand_token)\n",
        "            if len(unique_candidates) >= top_k:\n",
        "                break\n",
        "\n",
        "        if not unique_candidates:\n",
        "            return None  # extremely unlikely scenario\n",
        "\n",
        "        # Try each candidate, picking the FIRST that differs from original_token\n",
        "        orig_lower = original_token.strip().lower()\n",
        "        for cand in unique_candidates:\n",
        "            if cand.lower() != orig_lower:\n",
        "                # Found a new token that is truly different\n",
        "                return cand, original_token\n",
        "\n",
        "        # If we get here, all top_k are identical to the original => no difference => None\n",
        "        return None\n",
        "\n",
        "    def iterative_augment(\n",
        "        self, text: str, steps: int = 3, verbose: bool = False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Iteratively replace up to `steps` tokens (one at a time).\n",
        "        For each iteration:\n",
        "          1) Identify the next replacable token (not punctuation).\n",
        "          2) Use _mask_and_replace(...) with top_k=10 to find a different token.\n",
        "          3) If we cannot find a difference, we skip that token and move on.\n",
        "          4) If found a difference, measure new activation, compute proportion_drop,\n",
        "             classify as positive/negative, and proceed to the next iteration.\n",
        "\n",
        "        Return final `positive`, `negative` lists like the original approach:\n",
        "\n",
        "          positive = [ (text_str, activation_float, proportion_drop_float), ...]\n",
        "          negative = [ ...]\n",
        "\n",
        "        Also prints how many tokens have been replaced so far, if verbose=True.\n",
        "        \"\"\"\n",
        "        old_activation = self._measure_activation(text)\n",
        "        current_text = text[:]\n",
        "\n",
        "        # We'll store iteration outputs in \"positive\" or \"negative\" lists\n",
        "        # Also include an initial entry in \"positive\" with the original text if desired\n",
        "        positive = [(current_text, old_activation, 0.0)]\n",
        "        negative = []\n",
        "\n",
        "        replaced_count = 0\n",
        "\n",
        "        tokens = self.word_tokenizer.split(current_text)\n",
        "        token_idx = 0\n",
        "\n",
        "        def is_replacable(tok: str) -> bool:\n",
        "            stripped = tok.strip(\" .,!?;:'\\\"()[]{}-\").lower()\n",
        "            return bool(stripped)  # skip punctuation, empty tokens\n",
        "\n",
        "        for step in range(steps):\n",
        "            # 1) Skip non-replacable tokens\n",
        "            while token_idx < len(tokens) and not is_replacable(tokens[token_idx]):\n",
        "                token_idx += 1\n",
        "\n",
        "            if token_idx >= len(tokens):\n",
        "                if verbose:\n",
        "                    print(f\"[Iteration {step+1}] No more valid tokens to replace.\")\n",
        "                break\n",
        "\n",
        "            # 2) Attempt to replace the token with a new token\n",
        "            replacement_info = self._mask_and_replace(current_text, token_idx, top_k=10)\n",
        "            if not replacement_info:\n",
        "                # means we didn't find ANY distinct token => skip this token\n",
        "                if verbose:\n",
        "                    print(f\"[Iteration {step+1}] All top candidates identical for token '{tokens[token_idx]}'. Skipping.\")\n",
        "                token_idx += 1\n",
        "                continue\n",
        "\n",
        "            new_token, orig_token = replacement_info\n",
        "\n",
        "            # 3) Perform the actual replacement\n",
        "            splitted = self.word_tokenizer.split(current_text)\n",
        "            splitted[token_idx] = new_token\n",
        "            new_text = \"\".join(splitted)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\n[Iteration {step+1}] Replacing token '{orig_token}' -> '{new_token}' at index {token_idx}\")\n",
        "\n",
        "            # 4) Measure new activation\n",
        "            new_activation = self._measure_activation(new_text)\n",
        "            proportion_drop = (new_activation - old_activation) / (old_activation + 1e-10)\n",
        "\n",
        "            # classify as positive/negative\n",
        "            if proportion_drop > self.inclusion_threshold:\n",
        "                positive.append((new_text, new_activation, proportion_drop))\n",
        "            elif proportion_drop < self.exclusion_threshold:\n",
        "                negative.append((new_text, new_activation, proportion_drop))\n",
        "\n",
        "            replaced_count += 1\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"  #Tokens replaced so far: {replaced_count}\")\n",
        "                print(f\"  Old activation: {old_activation:.4f}\")\n",
        "                print(f\"  New activation: {new_activation:.4f}\")\n",
        "                print(f\"  Proportion drop: {proportion_drop:.4f}\")\n",
        "                print(f\"  Updated text: {new_text[:200]}...\")\n",
        "\n",
        "            # 5) Update for next iteration\n",
        "            current_text = new_text\n",
        "            tokens = self.word_tokenizer.split(current_text)  # refresh tokens\n",
        "            old_activation = new_activation\n",
        "            token_idx += 1\n",
        "\n",
        "        return positive, negative\n"
      ],
      "metadata": {
        "id": "spFjatfFMPUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_iterative_multi_token_on_snippets(\n",
        "    snippets_list,\n",
        "    hooking_model,\n",
        "    layer_name: str,\n",
        "    neuron_index: int,\n",
        "    mlm_model,\n",
        "    mlm_tokenizer,\n",
        "    steps: int = 3,\n",
        "    prune_first: bool = True,\n",
        "    proportion_threshold_prune: float = -0.5,\n",
        "    window: int = 4,\n",
        "    verbose: bool = False\n",
        "):\n",
        "    \"\"\"\n",
        "    For each snippet:\n",
        "    1) Optionally prune => get minimal activating example\n",
        "    2) Iteratively replace up to `steps` tokens\n",
        "    3) Print final positive and negative lists (like original approach).\n",
        "\n",
        "    :param snippets_list: e.g. snippets_3_1, ...\n",
        "    :param hooking_model: interpretability model with run_with_cache\n",
        "    :param layer_name: hooking layer name\n",
        "    :param neuron_index: target neuron index\n",
        "    :param mlm_model: masked LM for replacement\n",
        "    :param mlm_tokenizer: its tokenizer\n",
        "    :param steps: how many tokens to replace iteratively\n",
        "    :param prune_first: whether to prune snippet\n",
        "    :param proportion_threshold_prune: threshold for prune function\n",
        "    :param window: prune function param\n",
        "    :param verbose: print iteration details\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the iterative augmenter\n",
        "    iterative_augmenter = IterativeMultiTokenAugmenter(\n",
        "        mlm_model,\n",
        "        mlm_tokenizer,\n",
        "        hooking_model,\n",
        "        layer_name,\n",
        "        neuron_index,\n",
        "        inclusion_threshold=-0.4,  # same defaults as original\n",
        "        exclusion_threshold=-0.7\n",
        "    )\n",
        "\n",
        "    for snippet in snippets_list:\n",
        "        print(\"\\n==========================\")\n",
        "        #print(f\"Original Snippet:\\n{snippet}\")\n",
        "\n",
        "        # 1) Prune\n",
        "        if prune_first:\n",
        "            pruned_prompt = prune(\n",
        "                hooking_model,\n",
        "                layer_name,\n",
        "                neuron_index,\n",
        "                snippet,\n",
        "                max_length=1024,\n",
        "                proportion_threshold=proportion_threshold_prune,\n",
        "                window=window\n",
        "            )\n",
        "            print(f\"\\nPruned Prompt: {pruned_prompt!r}\")\n",
        "            if pruned_prompt is None:\n",
        "                print(\"No pruned prompt - skipping.\\n\")\n",
        "                continue\n",
        "        else:\n",
        "            pruned_prompt = snippet\n",
        "\n",
        "        # 2) Iteratively augment\n",
        "        positive_prompts, negative_prompts = iterative_augmenter.iterative_augment(\n",
        "            text=pruned_prompt, steps=steps, verbose=verbose\n",
        "        )\n",
        "\n",
        "        # 3) Print results in \"positive\" / \"negative\" format\n",
        "        print(\"\\n--- FINAL RESULTS ---\")\n",
        "        print(\"positive\", positive_prompts)\n",
        "        print(\"negative\", negative_prompts)\n",
        "        print(\"---------------------\\n\")\n"
      ],
      "metadata": {
        "id": "bQCGjgvfMP0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll run iterative replacement for up to 3 tokens\n",
        "run_iterative_multi_token_on_snippets(\n",
        "    snippets_list=snippets_3_1,\n",
        "    hooking_model=model,\n",
        "    layer_name=\"blocks.3.mlp.hook_mid\",\n",
        "    neuron_index=1,\n",
        "    mlm_model=aug_model,\n",
        "    mlm_tokenizer=aug_tokenizer,\n",
        "    steps=5,\n",
        "    prune_first=True,    # prune the snippet first\n",
        "    proportion_threshold_prune=-0.6,\n",
        "    window=3,\n",
        "    verbose=True         # show iteration details\n",
        ")\n",
        "\n",
        "\n",
        "run_iterative_multi_token_on_snippets(\n",
        "    snippets_list=snippets_3_2,\n",
        "    hooking_model=model,\n",
        "    layer_name=\"blocks.3.mlp.hook_mid\",\n",
        "    neuron_index=2,\n",
        "    mlm_model=aug_model,\n",
        "    mlm_tokenizer=aug_tokenizer,\n",
        "    steps=5,\n",
        "    prune_first=True,    # prune the snippet first\n",
        "    proportion_threshold_prune=-0.6,\n",
        "    window=3,\n",
        "    verbose=True         # show iteration details\n",
        ")\n",
        "\n",
        "run_iterative_multi_token_on_snippets(\n",
        "    snippets_list=snippets_3_912,\n",
        "    hooking_model=model,\n",
        "    layer_name=\"blocks.3.mlp.hook_mid\",\n",
        "    neuron_index=912,\n",
        "    mlm_model=aug_model,\n",
        "    mlm_tokenizer=aug_tokenizer,\n",
        "    steps=5,\n",
        "    prune_first=True,    # prune the snippet first\n",
        "    proportion_threshold_prune=-0.6,\n",
        "    window=2,\n",
        "    verbose=True         # show iteration details\n",
        ")\n",
        "\n",
        "run_iterative_multi_token_on_snippets(\n",
        "    snippets_list=snippets_4_912,\n",
        "    hooking_model=model,\n",
        "    layer_name=\"blocks.4.mlp.hook_mid\",\n",
        "    neuron_index=912,\n",
        "    mlm_model=aug_model,\n",
        "    mlm_tokenizer=aug_tokenizer,\n",
        "    steps=5,\n",
        "    prune_first=True,    # prune the snippet first\n",
        "    proportion_threshold_prune=-0.6,\n",
        "    window=5,\n",
        "    verbose=True         # show iteration details\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgGZy4uYMQLN",
        "outputId": "39d37e65-b215-4d22-c437-3caa1b5ebce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: \" thought didn't even cross my mind\"\n",
            "\n",
            "[Iteration 1] Replacing token 'thought' -> 'words' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.1918\n",
            "  New activation: 0.2829\n",
            "  Proportion drop: 0.4751\n",
            "  Updated text:  words didn't even cross my mind...\n",
            "\n",
            "[Iteration 2] Replacing token 'didn' -> 'don' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.2829\n",
            "  New activation: 0.1946\n",
            "  Proportion drop: -0.3123\n",
            "  Updated text:  words don't even cross my mind...\n",
            "\n",
            "[Iteration 3] Replacing token 't' -> 'n' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1946\n",
            "  New activation: 0.1795\n",
            "  Proportion drop: -0.0774\n",
            "  Updated text:  words don'n even cross my mind...\n",
            "\n",
            "[Iteration 4] Replacing token 'even' -> 'wanna' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.1795\n",
            "  New activation: 0.1013\n",
            "  Proportion drop: -0.4354\n",
            "  Updated text:  words don'n wanna cross my mind...\n",
            "\n",
            "[Iteration 5] Replacing token 'cross' -> 'change' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.1013\n",
            "  New activation: 0.0170\n",
            "  Proportion drop: -0.8326\n",
            "  Updated text:  words don'n wanna change my mind...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(\" thought didn't even cross my mind\", 0.1917964667081833, 0.0), (\" words didn't even cross my mind\", 0.28292062878608704, 0.47510865864404855), (\" words don't even cross my mind\", 0.19455298781394958, -0.31234074842848275), (\" words don'n even cross my mind\", 0.17948977649211884, -0.07742472363618069)]\n",
            "negative [(\" words don'n wanna change my mind\", 0.016963878646492958, -0.8326105597876047)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' a thought that would cross my mind'\n",
            "\n",
            "[Iteration 1] Replacing token 'a' -> 'i' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.3207\n",
            "  New activation: 0.1123\n",
            "  Proportion drop: -0.6499\n",
            "  Updated text:  i thought that would cross my mind...\n",
            "\n",
            "[Iteration 2] Replacing token 'thought' -> 'feared' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.1123\n",
            "  New activation: 0.1288\n",
            "  Proportion drop: 0.1474\n",
            "  Updated text:  i feared that would cross my mind...\n",
            "\n",
            "[Iteration 3] Replacing token 'that' -> 'something' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1288\n",
            "  New activation: 0.2011\n",
            "  Proportion drop: 0.5607\n",
            "  Updated text:  i feared something would cross my mind...\n",
            "\n",
            "[Iteration 4] Replacing token 'would' -> 'might' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.2011\n",
            "  New activation: 0.1802\n",
            "  Proportion drop: -0.1037\n",
            "  Updated text:  i feared something might cross my mind...\n",
            "\n",
            "[Iteration 5] Replacing token 'cross' -> 'change' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.1802\n",
            "  New activation: 0.0360\n",
            "  Proportion drop: -0.8005\n",
            "  Updated text:  i feared something might change my mind...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' a thought that would cross my mind', 0.3207255005836487, 0.0), (' i feared that would cross my mind', 0.1288491189479828, 0.14743810470283694), (' i feared something would cross my mind', 0.2010984569787979, 0.5607282266626116), (' i feared something might cross my mind', 0.18023885786533356, -0.10372829019414496)]\n",
            "negative [(' i feared something might change my mind', 0.035952601581811905, -0.800528021051227)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: \" thought of playing further probably didn't cross Hungry\"\n",
            "\n",
            "[Iteration 1] Replacing token 'thought' -> 'chances' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.1793\n",
            "  New activation: 0.1681\n",
            "  Proportion drop: -0.0621\n",
            "  Updated text:  chances of playing further probably didn't cross Hungry...\n",
            "\n",
            "[Iteration 2] Replacing token 'of' -> 'about' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.1681\n",
            "  New activation: 0.1770\n",
            "  Proportion drop: 0.0527\n",
            "  Updated text:  chances about playing further probably didn't cross Hungry...\n",
            "\n",
            "[Iteration 3] Replacing token 'playing' -> 'getting' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1770\n",
            "  New activation: 0.1436\n",
            "  Proportion drop: -0.1886\n",
            "  Updated text:  chances about getting further probably didn't cross Hungry...\n",
            "\n",
            "[Iteration 4] Replacing token 'further' -> 'married' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.1436\n",
            "  New activation: 0.1822\n",
            "  Proportion drop: 0.2690\n",
            "  Updated text:  chances about getting married probably didn't cross Hungry...\n",
            "\n",
            "[Iteration 5] Replacing token 'probably' -> 'but' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.1822\n",
            "  New activation: 0.0674\n",
            "  Proportion drop: -0.6302\n",
            "  Updated text:  chances about getting married but didn't cross Hungry...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(\" thought of playing further probably didn't cross Hungry\", 0.17926521599292755, 0.0), (\" chances of playing further probably didn't cross Hungry\", 0.16812780499458313, -0.06212812078708569), (\" chances about playing further probably didn't cross Hungry\", 0.1769801378250122, 0.05265240229270255), (\" chances about getting further probably didn't cross Hungry\", 0.14360353350639343, -0.1885895485783873), (\" chances about getting married probably didn't cross Hungry\", 0.18222695589065552, 0.2689587185934157)]\n",
            "negative []\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' The thought did briefly cross my mind'\n",
            "\n",
            "[Iteration 1] Replacing token 'The' -> 'that' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.3541\n",
            "  New activation: 0.1954\n",
            "  Proportion drop: -0.4482\n",
            "  Updated text:  that thought did briefly cross my mind...\n",
            "\n",
            "[Iteration 2] Replacing token 'thought' -> 'realization' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.1954\n",
            "  New activation: 0.1384\n",
            "  Proportion drop: -0.2917\n",
            "  Updated text:  that realization did briefly cross my mind...\n",
            "\n",
            "[Iteration 3] Replacing token 'did' -> 'would' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1384\n",
            "  New activation: 0.1416\n",
            "  Proportion drop: 0.0234\n",
            "  Updated text:  that realization would briefly cross my mind...\n",
            "\n",
            "[Iteration 4] Replacing token 'briefly' -> 'never' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.1416\n",
            "  New activation: 0.2179\n",
            "  Proportion drop: 0.5389\n",
            "  Updated text:  that realization would never cross my mind...\n",
            "\n",
            "[Iteration 5] Replacing token 'cross' -> 'enter' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.2179\n",
            "  New activation: 0.0854\n",
            "  Proportion drop: -0.6082\n",
            "  Updated text:  that realization would never enter my mind...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' The thought did briefly cross my mind', 0.35408151149749756, 0.0), (' that realization did briefly cross my mind', 0.138387992978096, -0.29169357326480577), (' that realization would briefly cross my mind', 0.14162011444568634, 0.023355505023953633), (' that realization would never cross my mind', 0.21793358027935028, 0.5388603594798349)]\n",
            "negative []\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' thought did briefly cross my mind'\n",
            "\n",
            "[Iteration 1] Replacing token 'thought' -> 'thoughts' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.1553\n",
            "  New activation: 0.2091\n",
            "  Proportion drop: 0.3464\n",
            "  Updated text:  thoughts did briefly cross my mind...\n",
            "\n",
            "[Iteration 2] Replacing token 'did' -> 'that' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.2091\n",
            "  New activation: 0.1886\n",
            "  Proportion drop: -0.0979\n",
            "  Updated text:  thoughts that briefly cross my mind...\n",
            "\n",
            "[Iteration 3] Replacing token 'briefly' -> 'constantly' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1886\n",
            "  New activation: 0.1310\n",
            "  Proportion drop: -0.3055\n",
            "  Updated text:  thoughts that constantly cross my mind...\n",
            "\n",
            "[Iteration 4] Replacing token 'cross' -> 'haunt' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.1310\n",
            "  New activation: 0.0222\n",
            "  Proportion drop: -0.8305\n",
            "  Updated text:  thoughts that constantly haunt my mind...\n",
            "\n",
            "[Iteration 5] Replacing token 'my' -> 'your' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0222\n",
            "  New activation: 0.0222\n",
            "  Proportion drop: 0.0000\n",
            "  Updated text:  thoughts that constantly haunt your mind...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' thought did briefly cross my mind', 0.15531548857688904, 0.0), (' thoughts did briefly cross my mind', 0.20911429822444916, 0.34638406063596533), (' thoughts that briefly cross my mind', 0.18864169716835022, -0.09790148842110682), (' thoughts that constantly cross my mind', 0.13102084398269653, -0.30545130806200155), (' thoughts that constantly haunt your mind', 0.02221446856856346, 0.0)]\n",
            "negative [(' thoughts that constantly haunt my mind', 0.02221446856856346, -0.8304508811243626)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' the bill finally pass.'\n",
            "\n",
            "[Iteration 1] Replacing token 'the' -> 'this' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.1483\n",
            "  New activation: 0.1579\n",
            "  Proportion drop: 0.0647\n",
            "  Updated text:  this bill finally pass....\n",
            "\n",
            "[Iteration 2] Replacing token 'bill' -> 'must' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.1579\n",
            "  New activation: 0.0316\n",
            "  Proportion drop: -0.8000\n",
            "  Updated text:  this must finally pass....\n",
            "\n",
            "[Iteration 3] Replacing token 'finally' -> 'never' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.0316\n",
            "  New activation: 0.0333\n",
            "  Proportion drop: 0.0542\n",
            "  Updated text:  this must never pass....\n",
            "\n",
            "[Iteration 4] Replacing token 'pass' -> 'happen' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0333\n",
            "  New activation: 0.0023\n",
            "  Proportion drop: -0.9314\n",
            "  Updated text:  this must never happen....\n",
            "[Iteration 5] No more valid tokens to replace.\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' the bill finally pass.', 0.14834657311439514, 0.0), (' this bill finally pass.', 0.15794692933559418, 0.06471572624279158), (' this must never pass.', 0.03329479694366455, 0.05422606141725196)]\n",
            "negative [(' this must finally pass.', 0.031582217663526535, -0.8000453831145556), (' this must never happen.', 0.0022846863139420748, -0.9313800768646879)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' am not a native English speaker'\n",
            "\n",
            "[Iteration 1] Replacing token 'am' -> '†' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.2899\n",
            "  New activation: 0.1536\n",
            "  Proportion drop: -0.4703\n",
            "  Updated text:  † not a native English speaker...\n",
            "\n",
            "[Iteration 2] Replacing token 'a' -> 'necessarily' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.1536\n",
            "  New activation: 0.1471\n",
            "  Proportion drop: -0.0421\n",
            "  Updated text:  † not necessarily native English speaker...\n",
            "\n",
            "[Iteration 3] Replacing token 'native' -> 'an' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1471\n",
            "  New activation: 0.0214\n",
            "  Proportion drop: -0.8547\n",
            "  Updated text:  † not necessarily an English speaker...\n",
            "\n",
            "[Iteration 4] Replacing token 'English' -> 'invited' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0214\n",
            "  New activation: 0.0006\n",
            "  Proportion drop: -0.9742\n",
            "  Updated text:  † not necessarily an invited speaker...\n",
            "\n",
            "[Iteration 5] Replacing token 'speaker' -> 'participant' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0006\n",
            "  New activation: 0.0006\n",
            "  Proportion drop: 0.0000\n",
            "  Updated text:  † not necessarily an invited participant...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' am not a native English speaker', 0.28990522027015686, 0.0), (' † not necessarily native English speaker', 0.14708498120307922, -0.04211807381464771), (' † not necessarily an invited participant', 0.0005506656016223133, 0.0)]\n",
            "negative [(' † not necessarily an English speaker', 0.021370945498347282, -0.8547034142506303), (' † not necessarily an invited speaker', 0.0005506656016223133, -0.9742329744330592)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' am not a native English speaker'\n",
            "\n",
            "[Iteration 1] Replacing token 'am' -> '†' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.2899\n",
            "  New activation: 0.1536\n",
            "  Proportion drop: -0.4703\n",
            "  Updated text:  † not a native English speaker...\n",
            "\n",
            "[Iteration 2] Replacing token 'a' -> 'necessarily' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.1536\n",
            "  New activation: 0.1471\n",
            "  Proportion drop: -0.0421\n",
            "  Updated text:  † not necessarily native English speaker...\n",
            "\n",
            "[Iteration 3] Replacing token 'native' -> 'an' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1471\n",
            "  New activation: 0.0214\n",
            "  Proportion drop: -0.8547\n",
            "  Updated text:  † not necessarily an English speaker...\n",
            "\n",
            "[Iteration 4] Replacing token 'English' -> 'invited' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0214\n",
            "  New activation: 0.0006\n",
            "  Proportion drop: -0.9742\n",
            "  Updated text:  † not necessarily an invited speaker...\n",
            "\n",
            "[Iteration 5] Replacing token 'speaker' -> 'participant' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0006\n",
            "  New activation: 0.0006\n",
            "  Proportion drop: 0.0000\n",
            "  Updated text:  † not necessarily an invited participant...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' am not a native English speaker', 0.28990522027015686, 0.0), (' † not necessarily native English speaker', 0.14708498120307922, -0.04211807381464771), (' † not necessarily an invited participant', 0.0005506656016223133, 0.0)]\n",
            "negative [(' † not necessarily an English speaker', 0.021370945498347282, -0.8547034142506303), (' † not necessarily an invited speaker', 0.0005506656016223133, -0.9742329744330592)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' am not a native English speaker'\n",
            "\n",
            "[Iteration 1] Replacing token 'am' -> '†' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.2899\n",
            "  New activation: 0.1536\n",
            "  Proportion drop: -0.4703\n",
            "  Updated text:  † not a native English speaker...\n",
            "\n",
            "[Iteration 2] Replacing token 'a' -> 'necessarily' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.1536\n",
            "  New activation: 0.1471\n",
            "  Proportion drop: -0.0421\n",
            "  Updated text:  † not necessarily native English speaker...\n",
            "\n",
            "[Iteration 3] Replacing token 'native' -> 'an' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.1471\n",
            "  New activation: 0.0214\n",
            "  Proportion drop: -0.8547\n",
            "  Updated text:  † not necessarily an English speaker...\n",
            "\n",
            "[Iteration 4] Replacing token 'English' -> 'invited' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0214\n",
            "  New activation: 0.0006\n",
            "  Proportion drop: -0.9742\n",
            "  Updated text:  † not necessarily an invited speaker...\n",
            "\n",
            "[Iteration 5] Replacing token 'speaker' -> 'participant' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0006\n",
            "  New activation: 0.0006\n",
            "  Proportion drop: 0.0000\n",
            "  Updated text:  † not necessarily an invited participant...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' am not a native English speaker', 0.28990522027015686, 0.0), (' † not necessarily native English speaker', 0.14708498120307922, -0.04211807381464771), (' † not necessarily an invited participant', 0.0005506656016223133, 0.0)]\n",
            "negative [(' † not necessarily an English speaker', 0.021370945498347282, -0.8547034142506303), (' † not necessarily an invited speaker', 0.0005506656016223133, -0.9742329744330592)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' am not a native speaker,'\n",
            "\n",
            "[Iteration 1] Replacing token 'am' -> 'certainly' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.2899\n",
            "  New activation: 0.2094\n",
            "  Proportion drop: -0.2778\n",
            "  Updated text:  certainly not a native speaker,...\n",
            "\n",
            "[Iteration 2] Replacing token 'not' -> 'being' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.2094\n",
            "  New activation: 0.2182\n",
            "  Proportion drop: 0.0423\n",
            "  Updated text:  certainly being a native speaker,...\n",
            "\n",
            "[Iteration 3] Replacing token 'a' -> 'the' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.2182\n",
            "  New activation: 0.1566\n",
            "  Proportion drop: -0.2826\n",
            "  Updated text:  certainly being the native speaker,...\n",
            "\n",
            "[Iteration 4] Replacing token 'native' -> 'correct' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.1566\n",
            "  New activation: 0.0003\n",
            "  Proportion drop: -0.9981\n",
            "  Updated text:  certainly being the correct speaker,...\n",
            "\n",
            "[Iteration 5] Replacing token 'speaker' -> 'answer' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0003\n",
            "  New activation: 0.0002\n",
            "  Proportion drop: -0.3714\n",
            "  Updated text:  certainly being the correct answer,...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' am not a native speaker,', 0.28990522027015686, 0.0), (' certainly not a native speaker,', 0.20936319231987, -0.27782193037934666), (' certainly being a native speaker,', 0.21821705996990204, 0.04228951396707758), (' certainly being the native speaker,', 0.15655550360679626, -0.28256982448280427), (' certainly being the correct answer,', 0.00018318188085686415, -0.37138748297753127)]\n",
            "negative [(' certainly being the correct speaker,', 0.00029140672995708883, -0.9981386356719668)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' was put on the IUCN Red List under'\n",
            "\n",
            "[Iteration 1] Replacing token 'was' -> 'species' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.7422\n",
            "  New activation: 0.7236\n",
            "  Proportion drop: -0.0251\n",
            "  Updated text:  species put on the IUCN Red List under...\n",
            "\n",
            "[Iteration 2] Replacing token 'put' -> 'listed' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.7236\n",
            "  New activation: 0.5818\n",
            "  Proportion drop: -0.1959\n",
            "  Updated text:  species listed on the IUCN Red List under...\n",
            "\n",
            "[Iteration 3] Replacing token 'on' -> 'in' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.5818\n",
            "  New activation: 0.5120\n",
            "  Proportion drop: -0.1200\n",
            "  Updated text:  species listed in the IUCN Red List under...\n",
            "\n",
            "[Iteration 4] Replacing token 'the' -> 'an' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.5120\n",
            "  New activation: 0.5004\n",
            "  Proportion drop: -0.0226\n",
            "  Updated text:  species listed in an IUCN Red List under...\n",
            "\n",
            "[Iteration 5] Replacing token 'IUCN' -> 'international' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.5004\n",
            "  New activation: 0.2816\n",
            "  Proportion drop: -0.4373\n",
            "  Updated text:  species listed in an international Red List under...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' was put on the IUCN Red List under', 0.7422054409980774, 0.0), (' species put on the IUCN Red List under', 0.7235724329948425, -0.025104919704802647), (' species listed on the IUCN Red List under', 0.5818095207214355, -0.1959208308518096), (' species listed in the IUCN Red List under', 0.5119678378105164, -0.12004217946160846), (' species listed in an IUCN Red List under', 0.50038743019104, -0.022619404505445487)]\n",
            "negative []\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' It was added to the National Register of'\n",
            "\n",
            "[Iteration 1] Replacing token 'It' -> 'this' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.5029\n",
            "  New activation: 0.4540\n",
            "  Proportion drop: -0.0973\n",
            "  Updated text:  this was added to the National Register of...\n",
            "\n",
            "[Iteration 2] Replacing token 'was' -> 'is' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.4540\n",
            "  New activation: 0.3821\n",
            "  Proportion drop: -0.1584\n",
            "  Updated text:  this is added to the National Register of...\n",
            "\n",
            "[Iteration 3] Replacing token 'added' -> 'according' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.3821\n",
            "  New activation: 0.0729\n",
            "  Proportion drop: -0.8091\n",
            "  Updated text:  this is according to the National Register of...\n",
            "\n",
            "[Iteration 4] Replacing token 'to' -> 'with' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0729\n",
            "  New activation: 0.0581\n",
            "  Proportion drop: -0.2040\n",
            "  Updated text:  this is according with the National Register of...\n",
            "\n",
            "[Iteration 5] Replacing token 'the' -> 'a' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0581\n",
            "  New activation: 0.0534\n",
            "  Proportion drop: -0.0807\n",
            "  Updated text:  this is according with a National Register of...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' It was added to the National Register of', 0.5029271841049194, 0.0), (' this was added to the National Register of', 0.4539719223976135, -0.09734065535689738), (' this is added to the National Register of', 0.3820685148239136, -0.15838734514264577), (' this is according with the National Register of', 0.058062292635440826, -0.20400022852079025), (' this is according with a National Register of', 0.05337890610098839, -0.08066141231783862)]\n",
            "negative [(' this is according to the National Register of', 0.07294259965419769, -0.809085028195208)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' It was added to the National Register of'\n",
            "\n",
            "[Iteration 1] Replacing token 'It' -> 'this' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.5029\n",
            "  New activation: 0.4540\n",
            "  Proportion drop: -0.0973\n",
            "  Updated text:  this was added to the National Register of...\n",
            "\n",
            "[Iteration 2] Replacing token 'was' -> 'is' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.4540\n",
            "  New activation: 0.3821\n",
            "  Proportion drop: -0.1584\n",
            "  Updated text:  this is added to the National Register of...\n",
            "\n",
            "[Iteration 3] Replacing token 'added' -> 'according' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.3821\n",
            "  New activation: 0.0729\n",
            "  Proportion drop: -0.8091\n",
            "  Updated text:  this is according to the National Register of...\n",
            "\n",
            "[Iteration 4] Replacing token 'to' -> 'with' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0729\n",
            "  New activation: 0.0581\n",
            "  Proportion drop: -0.2040\n",
            "  Updated text:  this is according with the National Register of...\n",
            "\n",
            "[Iteration 5] Replacing token 'the' -> 'a' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0581\n",
            "  New activation: 0.0534\n",
            "  Proportion drop: -0.0807\n",
            "  Updated text:  this is according with a National Register of...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' It was added to the National Register of', 0.5029271841049194, 0.0), (' this was added to the National Register of', 0.4539719223976135, -0.09734065535689738), (' this is added to the National Register of', 0.3820685148239136, -0.15838734514264577), (' this is according with the National Register of', 0.058062292635440826, -0.20400022852079025), (' this is according with a National Register of', 0.05337890610098839, -0.08066141231783862)]\n",
            "negative [(' this is according to the National Register of', 0.07294259965419769, -0.809085028195208)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: ' It was added to the National Register of'\n",
            "\n",
            "[Iteration 1] Replacing token 'It' -> 'this' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.5029\n",
            "  New activation: 0.4540\n",
            "  Proportion drop: -0.0973\n",
            "  Updated text:  this was added to the National Register of...\n",
            "\n",
            "[Iteration 2] Replacing token 'was' -> 'is' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.4540\n",
            "  New activation: 0.3821\n",
            "  Proportion drop: -0.1584\n",
            "  Updated text:  this is added to the National Register of...\n",
            "\n",
            "[Iteration 3] Replacing token 'added' -> 'according' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.3821\n",
            "  New activation: 0.0729\n",
            "  Proportion drop: -0.8091\n",
            "  Updated text:  this is according to the National Register of...\n",
            "\n",
            "[Iteration 4] Replacing token 'to' -> 'with' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0729\n",
            "  New activation: 0.0581\n",
            "  Proportion drop: -0.2040\n",
            "  Updated text:  this is according with the National Register of...\n",
            "\n",
            "[Iteration 5] Replacing token 'the' -> 'a' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0581\n",
            "  New activation: 0.0534\n",
            "  Proportion drop: -0.0807\n",
            "  Updated text:  this is according with a National Register of...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [(' It was added to the National Register of', 0.5029271841049194, 0.0), (' this was added to the National Register of', 0.4539719223976135, -0.09734065535689738), (' this is added to the National Register of', 0.3820685148239136, -0.15838734514264577), (' this is according with the National Register of', 0.058062292635440826, -0.20400022852079025), (' this is according with a National Register of', 0.05337890610098839, -0.08066141231783862)]\n",
            "negative [(' this is according to the National Register of', 0.07294259965419769, -0.809085028195208)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: 'It was added to the National Register of'\n",
            "\n",
            "[Iteration 1] Replacing token 'It' -> 'this' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 0.5011\n",
            "  New activation: 0.3852\n",
            "  Proportion drop: -0.2313\n",
            "  Updated text: this was added to the National Register of...\n",
            "\n",
            "[Iteration 2] Replacing token 'was' -> 'is' at index 3\n",
            "  #Tokens replaced so far: 2\n",
            "  Old activation: 0.3852\n",
            "  New activation: 0.2966\n",
            "  Proportion drop: -0.2301\n",
            "  Updated text: this is added to the National Register of...\n",
            "\n",
            "[Iteration 3] Replacing token 'added' -> 'according' at index 5\n",
            "  #Tokens replaced so far: 3\n",
            "  Old activation: 0.2966\n",
            "  New activation: 0.0758\n",
            "  Proportion drop: -0.7445\n",
            "  Updated text: this is according to the National Register of...\n",
            "\n",
            "[Iteration 4] Replacing token 'to' -> 'with' at index 7\n",
            "  #Tokens replaced so far: 4\n",
            "  Old activation: 0.0758\n",
            "  New activation: 0.0588\n",
            "  Proportion drop: -0.2239\n",
            "  Updated text: this is according with the National Register of...\n",
            "\n",
            "[Iteration 5] Replacing token 'the' -> 'a' at index 9\n",
            "  #Tokens replaced so far: 5\n",
            "  Old activation: 0.0588\n",
            "  New activation: 0.0555\n",
            "  Proportion drop: -0.0567\n",
            "  Updated text: this is according with a National Register of...\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [('It was added to the National Register of', 0.5010598301887512, 0.0), ('this was added to the National Register of', 0.3851628303527832, -0.231303714307289), ('this is added to the National Register of', 0.2965531349182129, -0.23005775331540695), ('this is according with the National Register of', 0.05881175398826599, -0.22392811750617828), ('this is according with a National Register of', 0.05547471344470978, -0.056741047691723466)]\n",
            "negative [('this is according to the National Register of', 0.07578132301568985, -0.7444595447927546)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: '.](bjc201256f1){#fig1'\n",
            "\n",
            "[Iteration 1] Replacing token 'bjc201256f1' -> '\\' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 2.9048\n",
            "  New activation: 0.0254\n",
            "  Proportion drop: -0.9913\n",
            "  Updated text: .](\\){#fig1...\n",
            "[Iteration 2] No more valid tokens to replace.\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [('.](bjc201256f1){#fig1', 2.904813289642334, 0.0)]\n",
            "negative [('.](\\\\){#fig1', 0.025366414338350296, -0.9912674544254098)]\n",
            "---------------------\n",
            "\n",
            "\n",
            "==========================\n",
            "\n",
            "Pruned Prompt: '.](bjc201156f1){#fig1'\n",
            "\n",
            "[Iteration 1] Replacing token 'bjc201156f1' -> '\\' at index 1\n",
            "  #Tokens replaced so far: 1\n",
            "  Old activation: 2.9739\n",
            "  New activation: 0.0254\n",
            "  Proportion drop: -0.9915\n",
            "  Updated text: .](\\){#fig1...\n",
            "[Iteration 2] No more valid tokens to replace.\n",
            "\n",
            "--- FINAL RESULTS ---\n",
            "positive [('.](bjc201156f1){#fig1', 2.9738998413085938, 0.0)]\n",
            "negative [('.](\\\\){#fig1', 0.025366414338350296, -0.991470319852354)]\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generative model approach from here\n",
        "\n",
        "# Hugging Face libraries\n",
        "from transformers import (\n",
        "    TFAutoModelForMaskedLM,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    GenerationConfig\n",
        ")\n",
        "\n",
        "# Replace \"google/gemma-2b\" with the actual model ID once published/available on HF.\n",
        "gen_model_name = \"google/gemma-2b\"\n",
        "\n",
        "# Tokenizer and model for rewriting (generative)\n",
        "generative_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
        "generative_model = AutoModelForCausalLM.from_pretrained(gen_model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "Leg9XeZlGJ6k",
        "outputId": "256e1de9-2a6d-4076-89cd-29d7a66d75ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b.\n401 Client Error. (Request ID: Root=1-678c4635-351610e46c7c2f533ccf53e4;c503c062-8f40-42b9-b9ee-3e4c7d89dc3b)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.\nAccess to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2b/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    422\u001b[0m             )\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-678c4635-351610e46c7c2f533ccf53e4;c503c062-8f40-42b9-b9ee-3e4c7d89dc3b)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.\nAccess to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c78ee911591b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Tokenizer and model for rewriting (generative)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgenerative_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mgenerative_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    876\u001b[0m                     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                     config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    879\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    650\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresolved_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_gated_repo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresolved_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to have access to it at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id}.\\n{str(e)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b.\n401 Client Error. (Request ID: Root=1-678c4635-351610e46c7c2f533ccf53e4;c503c062-8f40-42b9-b9ee-3e4c7d89dc3b)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.\nAccess to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generative_augment(\n",
        "    hooking_model,             # e.g. your EasyTransformer model\n",
        "    layer_name: str,           # e.g. \"blocks.3.mlp.hook_mid\"\n",
        "    neuron_index: int,         # target neuron\n",
        "    original_prompt: str,\n",
        "    n: int = 4,\n",
        "    inclusion_threshold: float = -0.5,\n",
        "    exclusion_threshold: float = -0.8,\n",
        "    max_length: int = 1024,\n",
        "    rewrite_prefix: str = \"Rewrite this text:\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates full-sentence rewrites of 'original_prompt' using the google/gemma-2b model,\n",
        "    measures neuron activation for each rewrite, and classifies them as positive/negative.\n",
        "\n",
        "    :param hooking_model: The model that has `to_tokens`, `run_with_cache`, etc. for neuron activation.\n",
        "    :param layer_name: The hooking layer name (e.g., \"blocks.3.mlp.hook_mid\").\n",
        "    :param neuron_index: Which neuron to measure in that layer.\n",
        "    :param original_prompt: The text to rewrite.\n",
        "    :param n: Number of rewrites to generate.\n",
        "    :param inclusion_threshold: If proportion_drop > inclusion_threshold => positive.\n",
        "    :param exclusion_threshold: If proportion_drop < exclusion_threshold => negative.\n",
        "    :param max_length: For hooking_model token length limit.\n",
        "    :param rewrite_prefix: How we prompt the generative model (a simple instruction).\n",
        "    :return: (positive_prompts, negative_prompts)\n",
        "             Each is a list of tuples: (rewrite_text, rewrite_activation, proportion_drop).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Measure activation of the original prompt as baseline\n",
        "    tokens = hooking_model.to_tokens(original_prompt, prepend_bos=True)\n",
        "    if len(tokens[0]) > max_length:\n",
        "        tokens = tokens[0, :max_length].unsqueeze(0)\n",
        "\n",
        "    # Run hooking_model\n",
        "    logits, cache = hooking_model.run_with_cache(tokens)\n",
        "    activations = cache[layer_name][0, :, neuron_index]\n",
        "    original_max = torch.max(activations).cpu().item()\n",
        "\n",
        "    # 2) Generate rewrites with google/gemma-2b\n",
        "    #    For each rewrite, measure the new activation\n",
        "    prompt_for_generation = f\"{rewrite_prefix}\\n{original_prompt}\\n\"\n",
        "\n",
        "    # You can adjust generation settings as needed\n",
        "    input_ids = generative_tokenizer.encode(prompt_for_generation, return_tensors=\"pt\")\n",
        "    # We'll sample 'n' distinct rewrites\n",
        "    generation_config = GenerationConfig(\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        temperature=0.7,\n",
        "        num_return_sequences=n,\n",
        "        max_new_tokens=50\n",
        "    )\n",
        "\n",
        "    gen_outputs = generative_model.generate(\n",
        "        input_ids=input_ids,\n",
        "        **generation_config.__dict__\n",
        "    )\n",
        "\n",
        "    # 3) Evaluate each rewrite's activation\n",
        "    positive_prompts = []\n",
        "    negative_prompts = []\n",
        "\n",
        "    for i, g_out in enumerate(gen_outputs):\n",
        "        rewrite_text = generative_tokenizer.decode(g_out, skip_special_tokens=True)\n",
        "\n",
        "        # We only want the \"rewritten\" portion.\n",
        "        # Since we used rewrite_prefix + original_prompt, the model might produce them as part of the text.\n",
        "        # Let's do a simple approach: strip the prefix for clarity:\n",
        "        # (You can refine this if the model produces extraneous text.)\n",
        "        if rewrite_prefix in rewrite_text:\n",
        "            rewrite_text = rewrite_text.split(rewrite_prefix)[-1].strip()\n",
        "\n",
        "        # 3a) Measure hooking activations on this rewrite\n",
        "        rewrite_tokens = hooking_model.to_tokens(rewrite_text, prepend_bos=True)\n",
        "        if len(rewrite_tokens[0]) > max_length:\n",
        "            rewrite_tokens = rewrite_tokens[0, :max_length].unsqueeze(0)\n",
        "\n",
        "        _, rewrite_cache = hooking_model.run_with_cache(rewrite_tokens)\n",
        "        rewrite_activations = rewrite_cache[layer_name][0, :, neuron_index]\n",
        "        rewrite_max = torch.max(rewrite_activations).cpu().item()\n",
        "\n",
        "        # 3b) Compare to original\n",
        "        proportion_drop = (rewrite_max - original_max) / (original_max + 1e-10)\n",
        "\n",
        "        # 3c) Classify as positive or negative, same logic as 'augment'\n",
        "        if proportion_drop > inclusion_threshold:\n",
        "            positive_prompts.append((rewrite_text, rewrite_max, proportion_drop))\n",
        "        elif proportion_drop < exclusion_threshold:\n",
        "            negative_prompts.append((rewrite_text, rewrite_max, proportion_drop))\n",
        "\n",
        "    return positive_prompts, negative_prompts\n"
      ],
      "metadata": {
        "id": "BxHYi8kqGKTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "layer_name = \"blocks.3.mlp.hook_mid\"\n",
        "neuron_index = 1\n",
        "max_length = 1024\n",
        "inclusion_threshold = 0.5\n",
        "exclusion_threshold = -0.8\n",
        "\n",
        "for snippet in snippets_3_1:\n",
        "    print(\"\\nOriginal Snippet:\")\n",
        "    print(snippet)\n",
        "\n",
        "    # 1) Prune\n",
        "    pruned_prompt = prune(\n",
        "        model, layer_name, neuron_index,\n",
        "        snippet,\n",
        "        max_length=max_length,\n",
        "        proportion_threshold=-0.5,\n",
        "        window=3\n",
        "    )\n",
        "    print(\"\\nPruned Prompt:\", [pruned_prompt])\n",
        "\n",
        "    if pruned_prompt is None:\n",
        "        # If pruning fails to produce a prompt that meets threshold, skip\n",
        "        continue\n",
        "\n",
        "    # 2) Generative rewriting\n",
        "    positive_prompts, negative_prompts = generative_augment(\n",
        "        model,\n",
        "        layer_name,\n",
        "        neuron_index,\n",
        "        pruned_prompt,\n",
        "        n=4,\n",
        "        inclusion_threshold=inclusion_threshold,\n",
        "        exclusion_threshold=exclusion_threshold,\n",
        "        max_length=max_length,\n",
        "        rewrite_prefix=\"Rewrite this text:\"\n",
        "    )\n",
        "\n",
        "    # 3) Print in the same format\n",
        "    print(\"\\npositive\", positive_prompts)\n",
        "    print(\"negative\", negative_prompts)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "pC9bBX4eGKt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2K-D5KdGLKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tkzvbkHTDR77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njxp5kZShUOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oeRnoWwnQAiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers huggingface_hub"
      ],
      "metadata": {
        "id": "_jFwd4LZB3SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "id": "bI2GzVenB_cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class IterativeMultiTokenAugmenter:\n",
        "    def __init__(self, mlm_model, mlm_tokenizer, hooking_model, layer_name, neuron_index):\n",
        "        \"\"\"\n",
        "        :param mlm_model: A masked language model (e.g., DistilBERT) for single-token replacements.\n",
        "        :param mlm_tokenizer: The tokenizer matching 'mlm_model'.\n",
        "        :param hooking_model: Your interpretability model that supports .to_tokens() and .run_with_cache().\n",
        "        :param layer_name: The layer hook name where neuron activation is measured (e.g. \"blocks.3.mlp.hook_mid\").\n",
        "        :param neuron_index: The neuron index in that layer whose activation we track.\n",
        "        \"\"\"\n",
        "        self.mlm_model = mlm_model\n",
        "        self.mlm_tokenizer = mlm_tokenizer\n",
        "        self.hooking_model = hooking_model\n",
        "        self.layer_name = layer_name\n",
        "        self.neuron_index = neuron_index\n",
        "\n",
        "        # Simple word splitting regex\n",
        "        self.word_tokenizer = re.compile(r\"\\b\")\n",
        "\n",
        "    def measure_activation(self, text, max_length=1024):\n",
        "        \"\"\"\n",
        "        Measures the target neuron's maximum activation for 'text'\n",
        "        using the hooking_model at the specified layer/neuron.\n",
        "        \"\"\"\n",
        "        tokens = self.hooking_model.to_tokens(text, prepend_bos=True)\n",
        "        if len(tokens[0]) > max_length:\n",
        "            tokens = tokens[0, :max_length].unsqueeze(0)\n",
        "\n",
        "        # Run model with cache\n",
        "        logits, cache = self.hooking_model.run_with_cache(tokens)\n",
        "        activations = cache[self.layer_name][0, :, self.neuron_index]\n",
        "        max_act = torch.max(activations).item()\n",
        "        return max_act\n",
        "\n",
        "    def find_top_replacement(self, text, token_index, top_k=1):\n",
        "        \"\"\"\n",
        "        1) Mask out 'token_index' in 'text'\n",
        "        2) Use the MLM to get top replacements\n",
        "        3) Return the best replacement\n",
        "        \"\"\"\n",
        "        # 1) Split into tokens\n",
        "        tokens = self.word_tokenizer.split(text)\n",
        "        if token_index < 0 or token_index >= len(tokens):\n",
        "            return None  # Invalid index\n",
        "\n",
        "        # Save the original token\n",
        "        orig_token = tokens[token_index]\n",
        "\n",
        "        # Mask only that one token\n",
        "        masked_tokens = tokens[:]\n",
        "        masked_tokens[token_index] = \"[MASK]\"\n",
        "        masked_text = \"\".join(masked_tokens)\n",
        "\n",
        "        # 2) Run MLM\n",
        "        inputs = self.mlm_tokenizer(masked_text, return_tensors=\"np\")\n",
        "        output = self.mlm_model(**inputs)\n",
        "        logits = output.logits  # shape: (batch_size, seq_len, vocab_size)\n",
        "\n",
        "        # Find [MASK] position\n",
        "        mask_token_id = self.mlm_tokenizer.mask_token_id\n",
        "        mask_token_index = np.argwhere(inputs[\"input_ids\"] == mask_token_id)\n",
        "        if len(mask_token_index) == 0:\n",
        "            return None\n",
        "        # We only handle the first mask for simplicity\n",
        "        mask_row, mask_col = mask_token_index[0]\n",
        "\n",
        "        # Extract the top logits\n",
        "        token_logits = logits[mask_row, mask_col, :]\n",
        "        top_tokens = np.argsort(-token_logits)[:top_k]  # top_k IDs\n",
        "\n",
        "        # For simplicity, return the single best candidate\n",
        "        best_id = top_tokens[0]\n",
        "        best_token = self.mlm_tokenizer.decode([best_id])\n",
        "        return best_token, orig_token\n",
        "\n",
        "    def iterative_augment(self, text, steps=3, verbose=True):\n",
        "        \"\"\"\n",
        "        Iteratively replace tokens in 'text', up to 'steps' times.\n",
        "        After each replacement, the new text is used for the next iteration.\n",
        "\n",
        "        :param text: Original text to augment\n",
        "        :param steps: How many tokens to replace in sequence\n",
        "        :param verbose: If True, print details each iteration\n",
        "\n",
        "        :return: The final augmented text after 'steps' replacements\n",
        "        \"\"\"\n",
        "        current_text = text\n",
        "        current_activation = self.measure_activation(current_text)\n",
        "\n",
        "        # We'll keep track of which token index to replace next\n",
        "        # (Here, we do a naive approach: just sequentially look for the next non-empty token)\n",
        "        token_idx = 0\n",
        "\n",
        "        # Simple punctuation or whitespace check\n",
        "        def is_replacable(tok):\n",
        "            stripped = tok.strip(\" ,.?!;:\\\"'()[]{}-\").lower()\n",
        "            return bool(stripped)  # skip if empty after stripping\n",
        "\n",
        "        for step in range(steps):\n",
        "            # 1) Split text into tokens\n",
        "            tokens = self.word_tokenizer.split(current_text)\n",
        "\n",
        "            # Find the next replacable token from the current token_idx forward\n",
        "            while token_idx < len(tokens) and not is_replacable(tokens[token_idx]):\n",
        "                token_idx += 1\n",
        "\n",
        "            if token_idx >= len(tokens):\n",
        "                if verbose:\n",
        "                    print(f\"Iter {step+1}: No more tokens to replace.\")\n",
        "                break\n",
        "\n",
        "            # 2) Mask & find top replacement\n",
        "            replacement_info = self.find_top_replacement(current_text, token_idx, top_k=1)\n",
        "            if not replacement_info:\n",
        "                if verbose:\n",
        "                    print(f\"Iter {step+1}: Could not find a valid replacement for token index {token_idx}.\")\n",
        "                break\n",
        "\n",
        "            best_replacement, orig_token = replacement_info\n",
        "\n",
        "            # 3) Update text\n",
        "            tokens[token_idx] = best_replacement\n",
        "            new_text = \"\".join(tokens)\n",
        "\n",
        "            # 4) Measure new activation\n",
        "            new_activation = self.measure_activation(new_text)\n",
        "\n",
        "            # Print or store iteration results\n",
        "            if verbose:\n",
        "                print(f\"\\n[Iteration {step+1}]\")\n",
        "                print(f\"  Original Token: '{orig_token}' => New Token: '{best_replacement}'\")\n",
        "                print(f\"  Old Activation: {current_activation:.4f} => New Activation: {new_activation:.4f}\")\n",
        "                print(f\"  Updated Text: {new_text[:100]}...\")  # truncated for brevity\n",
        "\n",
        "            # Update for next iteration\n",
        "            current_text = new_text\n",
        "            current_activation = new_activation\n",
        "\n",
        "            # Move to next token index\n",
        "            token_idx += 1\n",
        "\n",
        "        return current_text\n"
      ],
      "metadata": {
        "id": "TurVXKBCwihz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}